---
title: "Análisis de Sólidos Suspendidos"
format: 
  html:
    number-sections: true
    toc: true 
    toc-location: right
    toc-depth: 3
    embed-resources: true
    crossrefs-hover: false
    lang: es
    bibliography: bibliografia/bibliografia.bib
    csl: bibliografia/ieee.csl
date: last-modified
author:
  - name: Ariadna Malena Seba
    orcid: 
    corresponding: true
    email: ariadna.mseba@ca.frre.utn.edu.ar
    affiliations:
      - name: GISTAQ (UTN-FRRe)
        url: https://www.instagram.com/gistaq.utn/
abstract: |
  Este sitio web aborda el análisis de sólidos suspendidos totales (SST) en cuerpos de agua mediante el uso de imágenes satelitales y técnicas de aprendizaje automático. Presenta una introducción teórica sobre la importancia de los SST como indicador ambiental y luego desarrolla una parte práctica con Python, donde se integran datos espectrales y mediciones reales para aplicar modelos de regresión. Se evalúa el desempeño de estos modelos y se exploran relaciones entre bandas espectrales y SST, proponiendo mejoras metodológicas para estudios futuros.
keywords:
  - GISTAQ
  - UTN
  - FRRe
  - Quarto
jupyter: python3
execute:
  echo: true
---

## Sólidos suspendidos totales<span style="font-weight:normal; font-size: 1rem">, por Vera Geneyer (https://github.com/VeraGeneyer)</span> {toc-text="Sólidos suspendidos totales"}

Los sólidos suspendidos totales (TSM): es la cantidad de materia en suspensión en el agua, que incluye plancton, minerales, arena, y microorganismos. Se determinan como el residuo no filtrable de una muestra de agua. Niveles altos (TSM) pueden reducir la transparencia del agua, limitar la luz y y transportar sustancias tóxicas, afectando la vida acuática y la calidad del agua.
Este parámetro, medido mediante sensores remotos, nos da información sobre el estado físico del cuerpo de agua y están relacionados con factores como la humedad, temperatura y entre otros, que es vital para detectar riesgos al ecosistema y cumplir con las normas ambientales.

### Métodos tradicionales

:::: {.content-visible when-format="html"}

::: {.column-screen-right}

| Ecuación | Bandas (nm) | Métricas | Aguas | Plataforma | Referencia |
|:-:|:--|:--|:--|:--|:-:|
| $-229.34 \left( \frac{B03}{B08} \right)^{3}+1001.65 \left( \frac{B03}{B08} \right)^{2}-1422.7 \left( \frac{B03}{B08} \right)+665.17$ | B03, B08 | $R^{2}$ | Embalse^[Aguas lénticas.] | Landsat-8 | @Ramirez2017 |
| $-244.83+40.21 \cdot B01-3.67 \cdot NDWI$ | B01, NDWI (B03, B08) | $R^{2}$, RMSE, d | Río^[d = prueba estadística de <b>Durbin-Watson</b>.] | GeoEye | @Gomez2014 |

: Características principales de algoritmos tradicionales para la estimación de sólidos suspendidos. {#tbl-solsus-trad .striped .hover tbl-colwidths="[50,10,10,10,10]"}

:::

::::

:::: {.content-visible when-format="typst"}

| Ecuación | Referencia |
|:--|:-:|
| $-229.34 \left( \frac{B03}{B08} \right)^{3}+1001.65 \left( \frac{B03}{B08} \right)^{2}-1422.7 \left( \frac{B03}{B08} \right)+665.17$ | [@Ramirez2017] |
| $-244.83+40.21 \cdot B01-3.67 \cdot NDWI$ | [@Gomez2014] |

: Características principales de algoritmos tradicionales para la estimación de sólidos suspendidos. {#tbl-solsus-trad .striped .hover tbl-colwidths="[80,20]"}

::: {.block stroke='rgb("#B86092")' inset="8pt" radius="4pt"}

[Ver tabla completa en la versión online &#x2197;](https://vhgauto.quarto.pub/gistaq-parana/#tbl-solsus-trad)

:::

::::

De acuerdo a un estudio que analizó 48 cuerpos de agua, la estimación de TSM se hizo en su mayoría por modelos lineales, siendo la banda B8A la más frecuente [@Cruz2023].

### Métodos de aprendizaje automático

El **aprendizaje automático (ML)**  es una rama de la inteligencia artificial cuyo objetivo es desarrollar algoritmos capaces de resolver problemas mediante el análisis de datos y la creación de funciones que describen el comportamiento de fenómenos monitoreados [@Carpio2021]. Los modelos de aprendizaje automático más utilizados y mencionados por los investigadores para predecir la concentración de SST son:

* **Bosque Aleatorio (RF) y Refuerzo Adaptativo (AdB)**, modelos que se destacan por su robustez ante datos complejos y ruidosos. Estos algoritmos construyen múltiples árboles de decisión que analizan las relaciones entre características como el uso del suelo o el volumen de escorrentía y los niveles de SST [@Moeini2021].

* **Redes Neuronales Artificiales (ANN)**, copian las redes neuronales biológicas y aprenden patrones complejos en grandes volúmenes de datos, como los niveles de SST en distintas condiciones ambientales [@Moeini2021],

* **k-Nearest Neighbors (kNN)**, en sus variantes de ponderación uniforme y variable, que estima el SST en función de la cercanía en características de nuevos puntos de muestreo con datos históricos [@Moeini2021].

El aprendizaje automático es esencial para mejorar la precisión y rapidez en el análisis de la calidad del agua, proporcionando un monitoreo más eficiente y menos costoso en comparación con los métodos tradicionales, especialmente en áreas de difícil acceso o con datos limitados.

:::: {.content-visible when-format="html"}

::: {.column-screen-right}

| **Modelo de machine learning** | **Software** | **Agua** | **Datos** | **Métricas** | **Referencias** |
|:--|:--|:--|:--|:--|:-:|
|Bagging y Random Forest|Programa R|Bahía|Muestreo|Prueba de normalidad multivalente Mardia-tests y Royston|@Carpio2021|
|Regresión lineal, LASSO, regresión de vectores de soporte (SVR), K vecinos más cercanos (KNN), bosque aleatorio (RF) y redes neuronales artificiales (ANN).|-|Lago y embalse|Sentinel-2 y UAV|$R^{2}$| @Silveira2020|
|Regresión lineal, regresión de vectores de soporte (SVR), K vecinos más cercanos (KNN), bosque aleatorio (RF) y redes neuronales artificiales (ANN).|Programa Python|Lagos|Estación de monitoreo (Sensores para cada parámetro)|$R^{2}$, NSE y RMSE| @Moeini2021|

: Características principales de algoritmos de aprendizaje automático para la estimación de sólidos suspendidos. {#tbl-solsus-machine .striped .hover tbl-colwidths="[40,12,12,13,13,10]"}

:::

::::

:::: {.content-visible when-format="typst"}

| Modelo de machine learning | Referencias |
|:--|:-:|
|Bagging y Random Forest| [@Carpio2021] |
|Regresión lineal, LASSO, regresión de vectores de soporte (SVR), K vecinos más cercanos (KNN), bosque aleatorio (RF) y redes neuronales artificiales (ANN).| [@Silveira2020] |
|Regresión lineal, regresión de vectores de soporte (SVR), K vecinos más cercanos (KNN), bosque aleatorio (RF) y redes neuronales artificiales (ANN).| [@Moeini2021] |

: Características principales de algoritmos de aprendizaje automático para la estimación de sólidos suspendidos. {#tbl-solsus-machine .striped .hover tbl-colwidths="[80,20]"}

::: {.block stroke='rgb("#B86092")' inset="8pt" radius="4pt"}

[Ver tabla completa en la versión online &#x2197;](https://vhgauto.quarto.pub/gistaq-parana/#tbl-solsus-machine)

:::

::::



## Desarrollo del modelo con **Python**


### Procesamiento de datos (Sen2Cor)

Se detalla el procedimiento técnico que implementé para procesar información ambiental georreferenciada con el objetivo de analizar el comportamiento del parámetro **sólidos suspendidos (sol_sus)** en una región específica (pixel `3x3`). Para esto, utilicé el lenguaje Python y la biblioteca `pandas`, que resulta particularmente eficiente para el manejo de estructuras tabulares. 

#### Carga de datos

Primero importo la biblioteca `pandas`, una herramienta en Python que se utiliza para manejar datos en formato tabular (como hojas de cálculo o CSVs). Se le da el alias `pd` por convención, para simplificar el código.

Luego cargo dos archivos CSV con la función `pd.read_csv()`, la cual convierte dichos archivos en objetos del tipo `DataFrame`, que representan tablas en memoria, que son estructuras de datos similares a tablas (parecida a una hoja de Excel). Los conjuntos de datos cargados fueron:

- `gis_df`: contiene información geográfica (latitud, longitud, pixel, etc.).
- `lab_df`: contiene datos de laboratorio, incluyendo el parámetro de interés `sol_sus`.

 Verifico la carga correcta mostrando las primeras filas con la función `.head()`. Es útil para ver rápidamente cómo es la estructura del archivo: qué columnas hay, qué tipo de datos, si se cargó bien.

```{python}
import pandas as pd  # pandas es la biblioteca para manejar datos tabulares

# Cargar los archivos de datos
gis_df = pd.read_csv('datos/base_de_datos_gis.csv')
lab_df = pd.read_csv('datos/base_de_datos_lab.csv')

# Ver las primeras filas para asegurarse de que se cargaron bien
gis_df.head(), lab_df.head()

print("Primeras filas de gis_df:")
display(gis_df.head())

print("\nPrimeras filas de lab_df:")
display(lab_df.head())
```

::: {.dropdown}
<details>
<summary>📄 Nota técnica</summary>

- `pd.read_csv()` carga los archivos en estructuras llamadas *dataframes*, que funcionan como tablas.  
- `head()` te muestra las primeras 5 filas para ver cómo están los datos.
- `display()` permite mostrar las tablas con formato más visual (en HTML).

</details>

:::

#### Filtrar el parámetro 'sol_sus'

En el conjunto de datos del laboratorio `lab_df`, hay múltiples parámetros medidos (como pH, turbidez, etc.). En este caso, me interesa trabajar solamente con los datos de **sólidos suspendidos**, identificado como `"sol_sus"` en la columna `param`. Este filtrado selectivo lo realicé para limitar el análisis al fenómeno físico-químico de interés.

Filtré el DataFrame para quedarme solo con esas filas, y renombré la columna `valor` como `sol_sus` para que sea más claro en los siguientes pasos.

```{python}
# Filtrar solo las filas donde el parámetro es 'sol_sus'
sol_sus_df = lab_df[lab_df["param"] == "sol_sus"]

# Renombrar la columna 'valor' a 'sol_sus' para que tenga sentido en el merge
sol_sus_df = sol_sus_df.rename(columns={"valor": "sol_sus"})

# Mostrar para confirmar
sol_sus_df.head()
print("Primeras filas de sol_sus_df:")
display(sol_sus_df.head())
```

::: {.dropdown}
<details>
<summary>📄 Nota técnica</summary>

- `lab_df[lab_df["param"] == "sol_sus"]` filtra las filas cuyo valor en la columna `"param"` sea `"sol_sus"`.  
- `.rename(columns={"valor": "sol_sus"})` cambia el nombre de la columna `"valor"` a `"sol_sus"`.

</details>

:::


#### Transformar la columna banda en columnas individuales

En este paso, convierto los valores únicos de la columna `banda` (como `B01`, `B02`, etc.) en nombres de columnas. Cada nueva columna contendrá los valores del parámetro `reflect` correspondientes a esa banda en particular. Esta operación se realiza antes de unir con los valores de `sol_sus`, ya que el valor de reflectancia depende de la banda, mientras que `sol_sus` es un dato independiente que se asignará luego por punto, fecha y ubicación.

```{python}
# Pivotear la tabla para que cada banda sea una columna
gis_pivot = gis_df.pivot_table(
    index=['fecha', 'punto', 'pixel', 'latitud', 'longitud'],
    columns='banda',
    values='reflect'
).reset_index()

# Eliminar el nombre del índice de columnas generado por el pivot
gis_pivot.columns.name = None

print("Primeras filas de gis_pivot:")
display(gis_pivot.head())
```

::: {.dropdown}
<details> 
<summary>📄 Nota técnica</summary>

- `pivot_table()` reorganiza el DataFrame convirtiendo los valores de una columna (`banda`) en columnas individuales.
- `index=[...]` define las columnas que se mantendrán como claves (se repetirán por fila).
- `columns='banda'` indica qué columna queremos transformar en nombres de columnas.
- `values='reflect'` especifica qué valor colocar en cada celda de la nueva tabla.
- `reset_index()` convierte los índices jerárquicos en columnas normales para facilitar el análisis.
- `columns.name = None` quita la etiqueta "banda" que se agregaría al encabezado por defecto.

</details> 

:::


#### Combinar datos geoespaciales y de laboratorio

Una vez que las bandas han sido transformadas en columnas, combino esta tabla con los valores de sólidos suspendidos (`sol_sus`) provenientes del laboratorio. La combinación se hace usando las columnas `fecha`, `latitud` y `longitud`, que permiten identificar los datos correspondientes a un mismo punto geográfico y temporal.

```{python}
# Realizar el merge por ubicación y fecha
df_merged = pd.merge(
    gis_pivot,
    sol_sus_df[['fecha', 'latitud', 'longitud', 'sol_sus']],
    on=['fecha', 'latitud', 'longitud'],
    how='inner'
)

print("Primeras filas del DataFrame combinado:")
display(df_merged.head())
```

::: {.dropdown}
<details>
<summary>📄 Nota técnica</summary>

- `pd.merge()` permite combinar dos DataFrames en uno nuevo, uniendo filas que coincidan en las columnas especificadas.  
- `on=["latitud", "longitud"]` indica que la combinación debe hacerse usando esas columnas como claves.  
- `how="inner"` especifica el tipo de combinación:  
  - `"inner"`: solo conserva las filas donde hay coincidencia en ambos DataFrames.  
  - Otras opciones:  
    - `"left"`: conserva todas las filas del primer DataFrame.  
    - `"right"`: conserva todas las filas del segundo.  
    - `"outer"`: conserva todo, incluso si no hay coincidencia.

</details>

:::


#### Filtrado espacial por pixel

Luego de combinar los datos, aplico un filtrado adicional al DataFrame sobre la columna `pixel` para conservar únicamente las filas correspondientes al área geográfica designada como `"3x3"`. Este paso reduce el dominio de análisis y permite concentrarse en una región de estudio concreta.

```{python}
# Filtrar solo los datos del pixel 3x3
df_pixel_3x3 = df_merged[df_merged["pixel"] == "3x3"]

print("Primeras filas del pixel 3x3:")
display(df_pixel_3x3.head())
```

::: {.dropdown}
<details>
<summary>📄 Nota técnica</summary>

- Usa filtrado booleano (`DataFrame[condición]`), que es la forma estándar en pandas para seleccionar subconjuntos de datos. 
- `df_pixel_3x3 = df_combinado[df_combinado["pixel"] == "3x3"]` selecciona ese subconjunto. Filtra las filas cuyo valor en la columna `"pixel"` es igual a `"3x3"`.

</details>

:::


#### Guardar el archivo final

Finalmente, guardo el resultado como un nuevo archivo .csv dentro de la carpeta datos. 

Por último, exporto el resultado a un nuevo archivo en formato `.csv`, mediante la función `to_csv()` de pandas, con el parámetro `index=False` para evitar que la columna de índice se incluya en el archivo de salida que pandas crea por defecto.
Esto me permite utilizarlo después para visualización o análisis posterior.

```{python}
# Guardar el archivo CSV dentro de la carpeta "datos"
df_pixel_3x3.to_csv('datos/datos_sol_sus_pixel_3x3.csv', index=False)
```

::: {.dropdown}
<details>
<summary>📄 Nota técnica</summary>

- `to_csv()`  guarda los datos en formato CSV.  
- `index=False` evita que se guarde el índice numérico del DataFrame como una columna adicional en el CSV.

</details>

:::



### Procesamiento de datos (ACOLITE)

A continuación teniendo la misma lógica de procesamiento que aplique antes, pero usando el nuevo archivo `base_de_datos_gis_acolite.csv`.

```{python}
import pandas as pd

# 1. Cargar archivos CSV 
gis_acol_df = pd.read_csv('datos/base_de_datos_gis_acolite.csv')
lab_df = pd.read_csv('datos/base_de_datos_lab.csv')

# 2. Filtrar solo el parámetro 'sol_sus' 
sol_sus_df = lab_df[lab_df["param"] == "sol_sus"]
sol_sus_df = sol_sus_df.rename(columns={"valor": "sol_sus"})

#  3. Pivotear bandas en columnas 
gis_pivot = gis_acol_df.pivot_table(
    index=['fecha', 'punto', 'latitud', 'longitud'],
    columns='banda',
    values='reflect'
).reset_index()

gis_pivot.columns.name = None  # Quitar la etiqueta 'banda'

# 4. Combinar reflectancias con sol_sus 
df_merged = pd.merge(
    gis_pivot,
    sol_sus_df[['fecha', 'latitud', 'longitud', 'sol_sus']],
    on=['fecha', 'latitud', 'longitud'],
    how='inner'
)

# 5. Guardar resultado final
df_merged.to_csv('datos/datos_sol_sus_acolite.csv', index=False)

```



### Análisis de Regresión Lineal

En este análisis aplico un modelo de regresión lineal simple para estudiar la relación entre la **reflectancia** y los **sólidos suspendidos**, utilizando datos experimentales. La regresión lineal es una técnica fundamental del aprendizaje automático supervisado que nos permite predecir un valor continuo basado en una o más variables independientes. A lo largo de este documento, se explican paso a paso las acciones realizadas y los conceptos clave para comprender y replicar este análisis.


#### Importar librerías

En este paso, cargo las bibliotecas necesarias para procesar datos, ajustar modelos de regresión, evaluar su desempeño y visualizar los resultados. 

```{python}
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
```

::: {.dropdown}
<details>
<summary>📄 Nota técnica</summary>

> `pandas` se utiliza para manejar datos en forma de tablas (DataFrames), especialmente útiles al trabajar con archivos `.csv`.

> `train_test_split` permite dividir los datos en subconjuntos de entrenamiento y prueba, lo cual es esencial para evaluar el desempeño de un modelo sin sobreajustarlo.

> `LinearRegression` representa un modelo lineal que se ajusta a los datos minimizando el error cuadrático entre las predicciones y los valores reales.

> `mean_squared_error` y `r2_score` son métricas de evaluación: el primero mide el promedio de los errores al cuadrado, mientras que el segundo indica qué tan bien el modelo explica la variabilidad de los datos.

> `matplotlib.pyplot` se utiliza para crear gráficos. Permite visualizar los datos y los resultados del modelo.
 
</details>

:::

#### Cargar datos desde un CSV

Importo el archivo `.csv` con los datos experimentales. Se visualizan las primeras filas para verificar que los datos se han cargado correctamente.

```{python}
# Cargar el CSV
datos = pd.read_csv('datos/datos_sol_sus_acolite.csv')

# Mostrar las primeras filas para verificar
datos.head()
print("Primeras filas de datos:")
display(datos.head())
```

::: {.dropdown}
<details>
<summary>📄 Nota técnica</summary>

> `pd.read_csv` carga datos desde un archivo `.csv` y los convierte en un DataFrame de Pandas. Esta estructura tabular permite filtrar, seleccionar y transformar fácilmente los datos.

> `datos.head()` permite ver las primeras 5 filas del DataFrame para tener una vista preliminar de los datos cargados.

</details>

:::

#### Seleccionar variables y dividir en conjuntos

Selecciono las variables relevantes: `B01` como variable independiente y `sol_sus` como variable dependiente. Luego divido el conjunto en dos subconjuntos: uno para entrenar el modelo y otro para probarlo, lo cual sirve para evaluar su capacidad de generalización.

```{python}
# Selección de variables
X = datos[["B01"]]
y = datos["sol_sus"]

# División en entrenamiento y validación
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)
```

::: {.dropdown}
<details>
<summary>📄 Nota técnica</summary>

> Se selecciona una columna como variable independiente (X) y otra como variable dependiente (y). Es importante usar doble corchete al seleccionar una sola columna como X para mantener la estructura de tabla.

> `train_test_split` divide el conjunto de datos en entrenamiento y prueba. Esto permite entrenar el modelo en un subconjunto y evaluar su capacidad de generalización con otro.

> El parámetro `test_size=0.2` indica que el 20% de los datos se usan para prueba. `shuffle=False` mantiene el orden original de los datos, útil cuando los datos están organizados temporalmente o espacialmente.

</details>

:::


#### Entrenar modelo de regresión lineal

En este paso se entrena un modelo de regresión lineal usando los datos de entrenamiento. El modelo aprende la relación matemática entre la reflectancia y los sólidos suspendidos.

```{python}
regressor = LinearRegression().fit(X_train, y_train)
```

::: {.dropdown}
<details>
<summary>📄 Nota técnica</summary>

> `LinearRegression().fit()` ajusta un modelo lineal a los datos de entrenamiento. Internamente calcula la pendiente e intercepto que minimizan la diferencia entre las predicciones y los valores reales.

</details>

:::


#### Evaluar desempeño del modelo

Una vez entrenado el modelo, evaluo su desempeño usando métricas estadísticas. Estas nos permiten cuantificar qué tan bien el modelo predice los valores de sólidos suspendidos a partir de la reflectancia en los datos de prueba.

```{python}
y_pred = regressor.predict(X_test)
p_rmse = mean_squared_error(y_test, y_pred)
p_r2 = r2_score(y_test, y_pred)

```

::: {.callout-note title="Métricas de desempeño"}

```{python}
#| echo: false

print("El error cuadrático medio es:", round(p_rmse, 3))
print("El coeficiente de determinación (R²) es:", round(p_r2, 3))
```
:::

::: {.dropdown}
<details>
<summary>📄 Nota técnica</summary>

> `predict()` genera predicciones del modelo usando los datos de prueba. Estas predicciones se comparan con los valores reales para evaluar el desempeño.

> `mean_squared_error` calcula el promedio de los errores al cuadrado. Cuanto menor sea este valor, mejor se ajusta el modelo.

> `r2_score` mide qué proporción de la variabilidad en los datos es explicada por el modelo. Un valor cercano a 1 indica una buena predicción.

</details>

:::

#### Visualizar el modelo

Finalmente, se visualiza gráficamente la relación entre reflectancia y sólidos suspendidos, tanto en el conjunto de entrenamiento como en el de prueba. Esto ayuda a interpretar de forma visual cómo se ajusta el modelo a los datos reales.

```{python}
fig, ax = plt.subplots(ncols=2, figsize=(10, 5), sharex=True, sharey=True)

# Gráfico entrenamiento
ax[0].plot(X_train, regressor.predict(X_train), linewidth=3, color="#17A77E", label="Modelo")
ax[0].scatter(X_train, y_train, label="Entrenamiento", color="#9D50A6", alpha=0.6)
ax[0].set(xlabel="Reflectancia", ylabel="Sol_Sus", title="Conjunto de entrenamiento")
ax[0].legend()

# Gráfico validación
ax[1].plot(X_test, y_pred, linewidth=3, color="#17A77E", label="Modelo")
ax[1].scatter(X_test, y_test, label="Validación", color="#9D50A6", alpha=0.6)
ax[1].set(xlabel="Reflectancia", ylabel="Sol_Sus", title="Conjunto de validación")
ax[1].legend()

fig.suptitle("Regresión lineal")

plt.show()
```

::: {.dropdown}
<details>
<summary>📄 Nota técnica</summary>

> `plt.subplots` crea una figura con uno o más ejes para dibujar. Permite organizar varios gráficos en una misma figura.

> `plot()` traza una línea continua. Se usa para mostrar la línea de regresión generada por el modelo.

> `scatter()` traza puntos individuales. Se usa para mostrar los datos reales y compararlos con la línea del modelo.

> `set()` configura etiquetas de ejes y títulos de los subgráficos.

> `legend()` muestra una leyenda que identifica cada elemento del gráfico.

> `fig.suptitle()` agrega un título general a la figura completa.

> `plt.show()` es necesario para visualizar los gráficos al renderizar el documento.

</details>

:::


### Análisis de regresión por banda

Con el objetivo de profundizar el análisis, se evalúa la relación entre los sólidos suspendidos y cada una de las bandas espectrales disponibles de forma individual. Para ello, se entrena un modelo de regresión lineal simple por cada banda, utilizando los mismos datos experimentales. Este enfoque permite comparar el desempeño predictivo de cada banda por separado mediante métricas como el coeficiente de determinación R², su versión ajustada y el error cuadrático medio (RMSE).

```{python}
#|code-fold: true
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt
import math

# Cargar datos
datos = pd.read_csv('datos/datos_sol_sus_acolite.csv')

# Detectar columnas de bandas
bandas = [col for col in datos.columns if col.startswith("B")]

# Lista para guardar resultados
resultados = []

# Parámetros para organización de gráficos
n_bandas = len(bandas)
ncols = 3  # Número de columnas de la grilla
nrows = math.ceil(n_bandas / ncols)  # Calculamos cuántas filas se necesitan

# Crear figura
fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(12, 4 * nrows))
axs = axs.flatten()  # Asegura que podamos indexarlos como una lista

for i, banda in enumerate(bandas):
    # Variables
    X = datos[[banda]]
    y = datos["sol_sus"]

    # División entrenamiento/prueba
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

    # Ajuste del modelo
    modelo = LinearRegression().fit(X_train, y_train)
    y_train_pred = modelo.predict(X_train)

    # Métricas
    r2 = modelo.score(X_train, y_train)
    n = len(y_train)
    p = X_train.shape[1]
    r2_adj = 1 - (1 - r2) * (n - 1) / (n - p - 1)
    rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))

    resultados.append({
        "Banda": banda,
        "R2": round(r2, 4),
        "R2_ajustado": round(r2_adj, 4),
        "RMSE": round(rmse, 4)
    })

    # Gráfico de entrenamiento
    ax = axs[i]
    ax.scatter(X_train, y_train, alpha=0.6, color="#9D50A6", label="Entrenamiento")
    ax.plot(X_train, y_train_pred, color="#17A77E", linewidth=1.8, label="Modelo")
    ax.set_title(f'{banda}\nR²={r2:.2f}', fontsize=10)
    ax.set_xlabel('Reflectancia', fontsize=8)
    ax.set_ylabel('Sol_Sus', fontsize=8)
    ax.tick_params(axis='both', which='major', labelsize=8)
    ax.legend(fontsize=7)
    ax.grid(True)

# Eliminar ejes sobrantes
for j in range(i + 1, len(axs)):
    fig.delaxes(axs[j])

plt.suptitle("Regresiones lineales por banda (entrenamiento)", fontsize=14)
plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()

# Tabla resumen
df_resultados = pd.DataFrame(resultados).sort_values("R2", ascending=False).reset_index(drop=True)
print("Tabla resumen de métricas por banda:")
display(df_resultados.style.hide(axis="index"))

```


::: {.callout-note title="Conclusiones del análisis por banda"}

Los resultados muestran que, aunque algunas bandas como **B08**, **B07**, **B05** y **B06** presentan un desempeño ligeramente superior al resto, los valores de **R² siguen siendo bajos (< 0.20)**, lo que indica que **ninguna banda individual explica adecuadamente la variabilidad de los sólidos suspendidos**. El **R² ajustado** es similar a R² en las bandas más destacadas, pero se vuelve negativo en aquellas con menor correlación (como B01, B02, B03, B11, B12), lo que sugiere que un modelo basado solo en la media de los datos sería más eficaz que aplicar una regresión lineal simple en esos casos.

En cuanto al error de predicción, el **RMSE se mantiene en torno a 25 unidades** para las bandas con mejor ajuste, y alcanza valores cercanos a 27.5 en las de menor desempeño, lo que implica que el modelo apenas mejora con respecto a una predicción constante.

Estas observaciones reflejan las limitaciones del enfoque univariable y motivan avanzar hacia estrategias más robustas. Entonces, analizo como siguiente paso explorar:

  1. **Regresión multivariable**  
    Combinar las bandas mejor correlacionadas (por ejemplo, B08, B07, B05, B06) en un único modelo para evaluar si en conjunto mejoran R² y reducen RMSE.

  2. **Modelos no lineales**  
    Probar algoritmos como **Random Forest**, **SVM** o **Redes Neuronales** para capturar relaciones no lineales o interacciones espectrales.

  3. **Ingeniería de variables**  
    Calcular **índices espectrales** (NDVI, índices de turbidez) como combinaciones de bandas.  
    Aplicar transformaciones (logaritmos, potencias) a las reflectancias o a `sol_sus` para estabilizar la varianza.

  4. **Validación cruzada**  
      Implementar **k‑fold cross‑validation** para obtener métricas más robustas y evitar sobreajuste.

:::



### Análisis de regresión por banda aplicando logaritmo a las variables

En esta etapa del análisis, aplico una transformación logarítmica natural a las variables de reflectancia y sólidos suspendidos antes de ajustar los modelos de regresión lineal. Esta transformación es útil para:

- Estabilizar la varianza y reducir la heterocedasticidad.

- Linealizar relaciones no lineales entre variables.

- Evitar que valores extremos influyan excesivamente en el modelo.

El procedimiento es similar al análisis anterior, pero antes de entrenar el modelo se aplica `log(x)` a las columnas correspondientes. Para evitar problemas con ceros en los datos, estos se reemplazan por `NaN` y se eliminan del análisis.


```{python}
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import math

# 1. Cargar datos 
datos = pd.read_csv("datos/datos_sol_sus_acolite.csv")
bandas = [c for c in datos.columns if c.startswith("B")]

# 2.  Filtrar positivos (requisito para log) 
mask_pos = (datos["sol_sus"] > 0) & (datos[bandas] > 0).all(axis=1)
datos_log = datos.loc[mask_pos].copy()

# 3.Transformar a log-natural (para entrenar) 
datos_log["log_sol_sus"] = np.log(datos_log["sol_sus"])
for b in bandas:
    datos_log[f"log_{b}"] = np.log(datos_log[b])

log_bandas = [f"log_{b}" for b in bandas]

# 4. Split train / test (test se descarta aquí) 
X_total = datos_log[log_bandas]
y_total = datos_log["log_sol_sus"]
X_train, _, y_train, _ = train_test_split(
    X_total, y_total, test_size=0.2, shuffle=False
)

# 5. Funciones de métricas 
def metrics_log(model, X, y):
    """Métricas sobre los datos en log (las que ya tenías)."""
    y_pred = model.predict(X)
    rmse = np.sqrt(mean_squared_error(y, y_pred))
    r2   = r2_score(y, y_pred)
    n, p = X.shape
    r2_adj = 1 - ((1 - r2) * (n - 1)) / (n - p - 1)
    return rmse, r2, r2_adj

def metrics_original(model, X, y):
    """
    Idem, pero después de volver a la escala original:
       sol_sus_pred  = exp(ŷ_log)
       sol_sus_true  = exp(y_log)
    """
    y_pred_log  = model.predict(X).ravel()
    y_pred_orig = np.exp(y_pred_log)
    y_true_orig = np.exp(y.values)
    rmse = np.sqrt(mean_squared_error(y_true_orig, y_pred_orig))
    r2   = r2_score(y_true_orig, y_pred_orig)
    n, p = X.shape
    r2_adj = 1 - ((1 - r2) * (n - 1)) / (n - p - 1)
    return rmse, r2, r2_adj

# 6.  Entrenar un modelo por banda y registrar métricas 
resultados = []           # para log
resultados_nolog = []     # para escala original
lineas_log = {}           # (x, ŷ_log) para graficar en log-log
lineas_nolog = {}         # (x_original, ŷ_original) para graficar sin log

for b, lb in zip(bandas, log_bandas):
    Xtr = X_train[[lb]]
    reg = LinearRegression().fit(Xtr, y_train)

    # ── Métricas en log
    rmse_l, r2_l, r2a_l = metrics_log(reg, Xtr, y_train)
    resultados.append({"Banda": b, "RMSE_log": rmse_l,
                       "R²_log": r2_l, "R²aj_log": r2a_l})

    # ── Métricas en original
    rmse_o, r2_o, r2a_o = metrics_original(reg, Xtr, y_train)
    resultados_nolog.append({"Banda": b, "RMSE": rmse_o,
                             "R²": r2_o, "R²aj": r2a_o})

    # ── Recta ordenada para ambas escalas
    order = np.argsort(Xtr.values.ravel())
    x_log_ord   = Xtr.values.ravel()[order]             # log(B)
    y_pred_log  = reg.predict(Xtr).ravel()[order]       # log(sol_suŝ)
    lineas_log[b] = (x_log_ord, y_pred_log)

    # Para volver a la escala original:
    x_orig_ord  = np.exp(x_log_ord)                     # B
    y_pred_orig = np.exp(y_pred_log)                    # sol_suŝ
    lineas_nolog[b] = (x_orig_ord, y_pred_orig)

# 7. DataFrames con métricas
res_df_log    = (pd.DataFrame(resultados)
                   .round(3)
                   .sort_values("RMSE_log")
                   .reset_index(drop=True))

res_df_nolog  = (pd.DataFrame(resultados_nolog)
                   .round(3)
                   .sort_values("RMSE")
                   .reset_index(drop=True))

# 8.Gráficos *sin* log (escala original)
n_cols = 3
n_rows = math.ceil(len(bandas) / n_cols)
fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 4 * n_rows))
axes = axes.flatten()

for idx, b in enumerate(bandas):
    ax = axes[idx]
    # Datos originales de entrenamiento (sin log):
    x_orig = np.exp(X_train[f"log_{b}"])
    y_orig = np.exp(y_train)
    ax.scatter(x_orig, y_orig, alpha=0.6, color="#9D50A6", label="Entrenamiento")
    # Curva modelo en original:
    ax.plot(*lineas_nolog[b], lw=3, color="#17A77E", label="Modelo")
    ax.set(xlabel=b, ylabel="sol_sus", title=f"Banda {b} (escala original)")
    ax.legend()
    ax.grid(True)

# Si sobran ejes, quitarlos
for j in range(len(bandas), len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()

# 9.  Mostrar tablas de métricas
print("\nMétricas en **escala log-log** (ordenadas por RMSE_log):\n")
print(res_df_log.to_string(index=False))

print("\nMétricas en **escala original** (ordenadas por RMSE):\n")
print(res_df_nolog.to_string(index=False))

```

::: {.dropdown}
<details> 
<summary>📄 Nota técnica</summary>

>La transformación `log(x)` se usa frecuentemente cuando la relación entre variables es multiplicativa o cuando hay asimetría en la distribución.

>Es fundamental reemplazar ceros por NaN antes de aplicar el logaritmo, ya que `log(0)` no está definido.

>Las métricas obtenidas (`R²` y `RMSE`) se interpretan en la **escala logarítmica y no son directamente** comparables con las obtenidas en la escala original.

>El `R² ajustado` penaliza la complejidad del modelo y ayuda a evaluar si el ajuste mejora más allá de lo que se esperaría por azar.

</details> 

:::


::: {.callout-note title="Comparación entre regresión lineal simple y regresión logarítmica"}

Al aplicar una regresión lineal sobre las variables transformadas logarítmicamente, se observa una mejora clara en el ajuste del modelo para las bandas más relevantes. En particular, las bandas B05, B07, B08 y B06 alcanzan valores de R² entre 0.25 y 0.26, lo que representa un aumento significativo respecto a los valores originales, que estaban en torno a 0.16–0.17. Esta mejora también se refleja en el RMSE, que desciende a aproximadamente 0.236 en la escala logarítmica, en contraste con un RMSE promedio cercano a 25 en la escala original.

La transformación log-log parece capturar de manera más adecuada la relación entre la reflectancia y los sólidos suspendidos, sugiriendo que esta relación es más multiplicativa que estrictamente lineal. Además, el hecho de que el R² ajustado se mantenga cercano al R² simple indica que la mejora en el ajuste no es resultado de una sobreparametrización, sino de una relación más coherente entre las variables.

El orden de relevancia de las bandas se mantiene prácticamente igual al obtenido en el análisis sin logaritmos: B05 lidera con el mejor ajuste, seguida por B07, B08 y B06. Por otro lado, las bandas B11, B12, B01 y B02 continúan mostrando un desempeño muy pobre, con valores de R² prácticamente nulos o negativos, lo que confirma su escaso aporte predictivo en un modelo univariado.

En resumen, la regresión sobre datos transformados mejora el desempeño predictivo, pero los niveles de R² siguen siendo relativamente bajos. Esto indica que es necesario avanzar hacia modelos más complejos, como una regresión multivariable que combine varias bandas, o incluso explorar enfoques no lineales. También será importante considerar índices espectrales derivados y aplicar validación cruzada para asegurar la robustez de los resultados.

:::



### Selección de bandas con AIC y desempeño individual

Para evaluar qué bandas individuales son más relevantes para predecir los sólidos suspendidos, se ajustó un modelo de regresión lineal simple en escala logarítmica para cada banda. Además de calcular el coeficiente de determinación (R²) y el error cuadrático medio (RMSE), se calcula ahora el **AIC (Criterio de Información de Akaike)**, que penaliza la complejidad del modelo. Esto ayuda a decidir si la incorporación de una banda es realmente valiosa o si se está agregando complejidad innecesaria al modelo.

```{python}
#|code-fold: true
import pandas as pd
import numpy as np
import statsmodels.api as sm
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# Cargar datos
datos = pd.read_csv('datos/datos_sol_sus_acolite.csv')

# Detectar columnas de bandas
bandas = [col for col in datos.columns if col.startswith("B")]

# Lista para guardar resultados
resultados = []

for banda in bandas:
    # Log‑transform (evitando ceros)
    X = np.log(datos[[banda]].replace(0, np.nan)).dropna()
    y = np.log(datos.loc[X.index, "sol_sus"].replace(0, np.nan))
    
    # División en entrenamiento/prueba
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, shuffle=False
    )

    # Ajuste de OLS para obtener AIC, R² y R² ajustado
    Xc = sm.add_constant(X_train)           # añade intercepto
    modelo = sm.OLS(y_train, Xc).fit()

    # Predicciones de entrenamiento para RMSE
    y_train_pred = modelo.predict(Xc)

    # Métricas
    r2     = modelo.rsquared
    r2_adj = modelo.rsquared_adj
    mse    = mean_squared_error(y_train, y_train_pred)
    rmse   = np.sqrt(mse)
    aic    = modelo.aic

    resultados.append({
        "Banda":        banda,
        "R2":       round(r2,     4),
        "R2_ajustado":  round(r2_adj, 4),
        "RMSE":     round(rmse,   4),
        "AIC":          round(aic,    2)
    })

# Convertir a DataFrame y ordenar por R2_log
df_resultados = (
    pd.DataFrame(resultados)
      .sort_values("R2", ascending=False)
      .reset_index(drop=True)
)

# Mostrar tabla de resultados
print("Tabla de regresión log–log por banda con AIC (statsmodels):")
display(df_resultados.style.hide(axis="index"))
```


::: {.callout-note title="Evaluación individual de bandas con AIC"}

En este contexto, las bandas **B05**, **B07**, **B08** y **B06** no solo muestran los mayores valores de R² logarítmico (entre 0.248 y 0.259), sino que también presentan los **valores más bajos de AIC**, lo que confirma que son candidatas sólidas para construir modelos multivariables. A su vez, los valores de **RMSE en escala logarítmica** siguen siendo consistentes con los obtenidos previamente, en el orden de **0.236 a 0.238**.

Estos resultados refuerzan lo observado en los análisis anteriores: **ninguna banda aislada logra un ajuste sobresaliente**, pero estas cuatro se destacan claramente del resto tanto por su capacidad explicativa como por su eficiencia según el criterio de información (AIC). El AIC penaliza modelos más complejos, por lo que su bajo valor indica que estos modelos log-log simples son adecuados sin incurrir en sobreajuste.

En cambio, las bandas **B11**, **B12**, **B01** y **B02** presentan **R² cercanos o iguales a cero**, junto con **AIC altos (≥ 13)**, lo que confirma su escasa utilidad en modelos univariantes, incluso tras transformación logarítmica.

Este análisis refuerza la idea de que, aunque la relación entre reflectancia y sólidos suspendidos no sea linealmente fuerte en ninguna banda aislada, es posible que una combinación de varias de ellas explique mejor la variabilidad del fenómeno observado. El siguiente paso será construir un modelo multivariado que combine estas bandas con buen desempeño individual y evaluar si, en conjunto, se logra un ajuste más robusto.

:::



