---
title: "An谩lisis de S贸lidos Suspendidos"
format: 
  html:
    number-sections: true
    toc: true 
    toc-location: right
    toc-depth: 3
    embed-resources: true
    crossrefs-hover: false
    lang: es
    bibliography: bibliografia/bibliografia.bib
    csl: bibliografia/ieee.csl
date: last-modified
author:
  - name: V铆ctor Gauto
    orcid: 0000-0001-9960-8558
    corresponding: true
    email: victor.gauto@ca.frre.utn.edu.ar
    affiliations:
      - name: GISTAQ (UTN-FRRe)
        url: https://www.instagram.com/gistaq.utn/
abstract: |
  Este sitio web contiene cuestiones etc
keywords:
  - GISTAQ
  - UTN
  - FRRe
  - Quarto
jupyter: python3
execute:
  echo: true
---

## S贸lidos suspendidos totales<span style="font-weight:normal; font-size: 1rem">, por Vera Geneyer (https://github.com/VeraGeneyer)</span> {toc-text="S贸lidos suspendidos totales"}

Los s贸lidos suspendidos totales (TSM): es la cantidad de materia en suspensi贸n en el agua, que incluye plancton, minerales, arena, y microorganismos. Se determinan como el residuo no filtrable de una muestra de agua. Niveles altos (TSM) pueden reducir la transparencia del agua, limitar la luz y y transportar sustancias t贸xicas, afectando la vida acu谩tica y la calidad del agua.
Este par谩metro, medido mediante sensores remotos, nos da informaci贸n sobre el estado f铆sico del cuerpo de agua y est谩n relacionados con factores como la humedad, temperatura y entre otros, que es vital para detectar riesgos al ecosistema y cumplir con las normas ambientales.

### M茅todos tradicionales

:::: {.content-visible when-format="html"}

::: {.column-screen-right}

| Ecuaci贸n | Bandas (nm) | M茅tricas | Aguas | Plataforma | Referencia |
|:-:|:--|:--|:--|:--|:-:|
| $-229.34 \left( \frac{B03}{B08} \right)^{3}+1001.65 \left( \frac{B03}{B08} \right)^{2}-1422.7 \left( \frac{B03}{B08} \right)+665.17$ | B03, B08 | $R^{2}$ | Embalse^[Aguas l茅nticas.] | Landsat-8 | @Ramirez2017 |
| $-244.83+40.21 \cdot B01-3.67 \cdot NDWI$ | B01, NDWI (B03, B08) | $R^{2}$, RMSE, d | R铆o^[d = prueba estad铆stica de <b>Durbin-Watson</b>.] | GeoEye | @Gomez2014 |

: Caracter铆sticas principales de algoritmos tradicionales para la estimaci贸n de s贸lidos suspendidos. {#tbl-solsus-trad .striped .hover tbl-colwidths="[50,10,10,10,10]"}

:::

::::

:::: {.content-visible when-format="typst"}

| Ecuaci贸n | Referencia |
|:--|:-:|
| $-229.34 \left( \frac{B03}{B08} \right)^{3}+1001.65 \left( \frac{B03}{B08} \right)^{2}-1422.7 \left( \frac{B03}{B08} \right)+665.17$ | [@Ramirez2017] |
| $-244.83+40.21 \cdot B01-3.67 \cdot NDWI$ | [@Gomez2014] |

: Caracter铆sticas principales de algoritmos tradicionales para la estimaci贸n de s贸lidos suspendidos. {#tbl-solsus-trad .striped .hover tbl-colwidths="[80,20]"}

::: {.block stroke='rgb("#B86092")' inset="8pt" radius="4pt"}

[Ver tabla completa en la versi贸n online &#x2197;](https://vhgauto.quarto.pub/gistaq-parana/#tbl-solsus-trad)

:::

::::

De acuerdo a un estudio que analiz贸 48 cuerpos de agua, la estimaci贸n de TSM se hizo en su mayor铆a por modelos lineales, siendo la banda B8A la m谩s frecuente [@Cruz2023].

### M茅todos de aprendizaje autom谩tico

El **aprendizaje autom谩tico (ML)**  es una rama de la inteligencia artificial cuyo objetivo es desarrollar algoritmos capaces de resolver problemas mediante el an谩lisis de datos y la creaci贸n de funciones que describen el comportamiento de fen贸menos monitoreados [@Carpio2021]. Los modelos de aprendizaje autom谩tico m谩s utilizados y mencionados por los investigadores para predecir la concentraci贸n de SST son:

* **Bosque Aleatorio (RF) y Refuerzo Adaptativo (AdB)**, modelos que se destacan por su robustez ante datos complejos y ruidosos. Estos algoritmos construyen m煤ltiples 谩rboles de decisi贸n que analizan las relaciones entre caracter铆sticas como el uso del suelo o el volumen de escorrent铆a y los niveles de SST [@Moeini2021].

* **Redes Neuronales Artificiales (ANN)**, copian las redes neuronales biol贸gicas y aprenden patrones complejos en grandes vol煤menes de datos, como los niveles de SST en distintas condiciones ambientales [@Moeini2021],

* **k-Nearest Neighbors (kNN)**, en sus variantes de ponderaci贸n uniforme y variable, que estima el SST en funci贸n de la cercan铆a en caracter铆sticas de nuevos puntos de muestreo con datos hist贸ricos [@Moeini2021].

El aprendizaje autom谩tico es esencial para mejorar la precisi贸n y rapidez en el an谩lisis de la calidad del agua, proporcionando un monitoreo m谩s eficiente y menos costoso en comparaci贸n con los m茅todos tradicionales, especialmente en 谩reas de dif铆cil acceso o con datos limitados.

:::: {.content-visible when-format="html"}

::: {.column-screen-right}

| **Modelo de machine learning** | **Software** | **Agua** | **Datos** | **M茅tricas** | **Referencias** |
|:--|:--|:--|:--|:--|:-:|
|Bagging y Random Forest|Programa R|Bah铆a|Muestreo|Prueba de normalidad multivalente Mardia-tests y Royston|@Carpio2021|
|Regresi贸n lineal, LASSO, regresi贸n de vectores de soporte (SVR), K vecinos m谩s cercanos (KNN), bosque aleatorio (RF) y redes neuronales artificiales (ANN).|-|Lago y embalse|Sentinel-2 y UAV|$R^{2}$| @Silveira2020|
|Regresi贸n lineal, regresi贸n de vectores de soporte (SVR), K vecinos m谩s cercanos (KNN), bosque aleatorio (RF) y redes neuronales artificiales (ANN).|Programa Python|Lagos|Estaci贸n de monitoreo (Sensores para cada par谩metro)|$R^{2}$, NSE y RMSE| @Moeini2021|

: Caracter铆sticas principales de algoritmos de aprendizaje autom谩tico para la estimaci贸n de s贸lidos suspendidos. {#tbl-solsus-machine .striped .hover tbl-colwidths="[40,12,12,13,13,10]"}

:::

::::

:::: {.content-visible when-format="typst"}

| Modelo de machine learning | Referencias |
|:--|:-:|
|Bagging y Random Forest| [@Carpio2021] |
|Regresi贸n lineal, LASSO, regresi贸n de vectores de soporte (SVR), K vecinos m谩s cercanos (KNN), bosque aleatorio (RF) y redes neuronales artificiales (ANN).| [@Silveira2020] |
|Regresi贸n lineal, regresi贸n de vectores de soporte (SVR), K vecinos m谩s cercanos (KNN), bosque aleatorio (RF) y redes neuronales artificiales (ANN).| [@Moeini2021] |

: Caracter铆sticas principales de algoritmos de aprendizaje autom谩tico para la estimaci贸n de s贸lidos suspendidos. {#tbl-solsus-machine .striped .hover tbl-colwidths="[80,20]"}

::: {.block stroke='rgb("#B86092")' inset="8pt" radius="4pt"}

[Ver tabla completa en la versi贸n online &#x2197;](https://vhgauto.quarto.pub/gistaq-parana/#tbl-solsus-machine)

:::

::::


Diferentes metodolog铆as para la resoluci贸n de una regresi贸n simple por el m茅todo de m铆nimos cuadrados.

## **Python**, con `sklearn`

Se muestra a continuaci贸n el tutorial mostrado en para el modelo [M铆nimos cuadrados ordinarios](https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html#ordinary-least-squares-example).

Importo la librer铆a `sklearn`, funciones de inter茅s y para generar figuras.

```{python}
from sklearn.datasets import load_diabetes
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
```

Cargo los datos de inter茅s y divido en entrenamiento y validaci贸n.

```{python}
X, y = load_diabetes(return_X_y=True)
X = X[:, [2]]  # Use only one feature
X_train, X_test, y_train, y_test = train_test_split(
  X, y, test_size=20, shuffle=False
)
```

Creo un modelo de regresi贸n y ajusto utilizando los datos de entrenamiento.

```{python}
regressor = LinearRegression().fit(X_train, y_train)
```

Eval煤o el modelo generado a partir de las **m茅tricas de desempe帽o**.

```{python}
y_pred = regressor.predict(X_test)
p_rmse = mean_squared_error(y_test, y_pred)
p_r2 = r2_score(y_test, y_pred)
```

::: {.callout-note icon="false" title="M茅tricas de desempe帽o"}
El error cuadr谩tico medio es: `{r} round(py$p_rmse, 3)`.

El coeficiente de determinaci贸n (R<sup>2</sup>) es: `{r} round(py$p_r2, 3)`.

:::

Visualizo los resultados comparando el conjunto de entrenamiento y validaci贸n.

::: {.column-body-outset}

```{python}
fig, ax = plt.subplots(ncols=2, figsize=(10, 5), sharex=True, sharey=True)

ax[0].plot(
    X_train,
    regressor.predict(X_train),
    linewidth=3,
    color="#17A77E",
    label="Modelo",
)
ax[0].scatter(X_train, y_train, label="Entrenamiento", color = "#9D50A6", alpha = .6)
ax[0].set(xlabel="Caracter铆stica", ylabel="Objetivo", title="Conjunto de entrenamiento")
ax[0].legend()

ax[1].plot(X_test, y_pred, linewidth=3, color="#17A77E", label="Modelo")
ax[1].scatter(X_test, y_test, label="Validaci贸n", color = "#9D50A6", alpha = .6)
ax[1].set(xlabel="Caracter铆stica", ylabel="Objetivo", title="Conjunto de validaci贸n")
ax[1].legend()

fig.suptitle("Regresi贸n lineal")

plt.show()
```

:::


### Procesamiento de datos con Python

Se detalla el procedimiento t茅cnico que implement茅 para procesar informaci贸n ambiental georreferenciada con el objetivo de analizar el comportamiento del par谩metro **s贸lidos suspendidos (sol_sus)** en una regi贸n espec铆fica (pixel `3x3`). Para esto, utilic茅 el lenguaje Python y la biblioteca `pandas`, que resulta particularmente eficiente para el manejo de estructuras tabulares. 

#### Carga de datos

Primero importo la biblioteca `pandas`, una herramienta en Python que se utiliza para manejar datos en formato tabular (como hojas de c谩lculo o CSVs). Se le da el alias `pd` por convenci贸n, para simplificar el c贸digo.

Luego cargo dos archivos CSV con la funci贸n `pd.read_csv()`, la cual convierte dichos archivos en objetos del tipo `DataFrame`, que representan tablas en memoria, que son estructuras de datos similares a tablas (parecida a una hoja de Excel). Los conjuntos de datos cargados fueron:

- `gis_df`: contiene informaci贸n geogr谩fica (latitud, longitud, pixel, etc.).
- `lab_df`: contiene datos de laboratorio, incluyendo el par谩metro de inter茅s `sol_sus`.

 Verifico la carga correcta mostrando las primeras filas con la funci贸n `.head()`. Es 煤til para ver r谩pidamente c贸mo es la estructura del archivo: qu茅 columnas hay, qu茅 tipo de datos, si se carg贸 bien.

```{python}
import pandas as pd  # pandas es la biblioteca para manejar datos tabulares

# Cargar los archivos de datos
gis_df = pd.read_csv('datos/base_de_datos_gis.csv')
lab_df = pd.read_csv('datos/base_de_datos_lab.csv')

# Ver las primeras filas para asegurarse de que se cargaron bien
gis_df.head(), lab_df.head()

print("Primeras filas de gis_df:")
display(gis_df.head())

print("\nPrimeras filas de lab_df:")
display(lab_df.head())
```

::: {.dropdown}
<details>
<summary> Nota t茅cnica</summary>

- `pd.read_csv()` carga los archivos en estructuras llamadas *dataframes*, que funcionan como tablas.  
- `head()` te muestra las primeras 5 filas para ver c贸mo est谩n los datos.
- `display()` permite mostrar las tablas con formato m谩s visual (en HTML).

</details>

:::

#### Filtrar el par谩metro 'sol_sus'

En el conjunto de datos del laboratorio `lab_df`, hay m煤ltiples par谩metros medidos (como pH, turbidez, etc.). En este caso, me interesa trabajar solamente con los datos de **s贸lidos suspendidos**, identificado como `"sol_sus"` en la columna `param`. Este filtrado selectivo lo realic茅 para limitar el an谩lisis al fen贸meno f铆sico-qu铆mico de inter茅s.

Filtr茅 el DataFrame para quedarme solo con esas filas, y renombr茅 la columna `valor` como `sol_sus` para que sea m谩s claro en los siguientes pasos.

```{python}
# Filtramos solo las filas donde el par谩metro es 'sol_sus'
sol_sus_df = lab_df[lab_df["param"] == "sol_sus"]

# Renombramos la columna 'valor' a 'sol_sus' para que tenga sentido en el merge
sol_sus_df = sol_sus_df.rename(columns={"valor": "sol_sus"})

# Mostramos para confirmar
sol_sus_df.head()

print("Primeras filas de sol_sus_df:")
display(sol_sus_df.head())
```

::: {.dropdown}
<details>
<summary> Nota t茅cnica</summary>

- `lab_df[lab_df["param"] == "sol_sus"]` filtra las filas cuyo valor en la columna `"param"` sea `"sol_sus"`.  
- `.rename(columns={"valor": "sol_sus"})` cambia el nombre de la columna `"valor"` a `"sol_sus"`.

</details>

:::

#### Combinar datos geoespaciales y de laboratorio

Ahora quiero unir los datos de ubicaci贸n (latitud, longitud) con los valores de sol_sus. Para eso un铆 ambos conjuntos de datos usando `pd.merge()`, que combina tablas usando columnas comunes.
En este caso, us茅 las columnas `latitud` y `longitud` para juntar las filas que corresponden a la misma ubicaci贸n.
La uni贸n fue de tipo `"inner"`, que mantiene solo las filas que aparecen en ambas tablas, asegurando que solo trabajemos con datos coincidentes.

```{python}
# Unimos por latitud y longitud
df_combinado = pd.merge(
    gis_df,
    sol_sus_df[["latitud", "longitud", "sol_sus"]],
    on=["latitud", "longitud"],
    how="inner"
)

df_combinado.head()
print("Primeras filas de df_combinado:")
display(df_combinado.head())
```

::: {.dropdown}
<details>
<summary> Nota t茅cnica</summary>

- `pd.merge()` permite combinar dos DataFrames en uno nuevo, uniendo filas que coincidan en las columnas especificadas.  
- `on=["latitud", "longitud"]` indica que la combinaci贸n debe hacerse usando esas columnas como claves.  
- `how="inner"` especifica el tipo de combinaci贸n:  
  - `"inner"`: solo conserva las filas donde hay coincidencia en ambos DataFrames.  
  - Otras opciones:  
    - `"left"`: conserva todas las filas del primer DataFrame.  
    - `"right"`: conserva todas las filas del segundo.  
    - `"outer"`: conserva todo, incluso si no hay coincidencia.

</details>

:::

#### Filtrado espacial por pixel

Luego de combinar los datos, aplico un filtrado adicional al DataFrame sobre la columna `pixel` para conservar 煤nicamente las filas correspondientes al 谩rea geogr谩fica designada como `"3x3"`. Este paso reduce el dominio de an谩lisis y permite concentrarse en una regi贸n de estudio concreta.

```{python}
# Filtramos solo los datos del pixel 3x3
df_pixel_3x3 = df_combinado[df_combinado["pixel"] == "3x3"]

df_pixel_3x3.head()
print("Primeras filas de df_pixel_3x3:")
display(df_pixel_3x3.head())
```

::: {.dropdown}
<details>
<summary> Nota t茅cnica</summary>

- Usa filtrado booleano (`DataFrame[condici贸n]`), que es la forma est谩ndar en pandas para seleccionar subconjuntos de datos. 
- `df_pixel_3x3 = df_combinado[df_combinado["pixel"] == "3x3"]` selecciona ese subconjunto. Filtra las filas cuyo valor en la columna `"pixel"` es igual a `"3x3"`.

</details>

:::

#### Reordenamiento de columnas

Para facilitar la lectura y el an谩lisis del `DataFrame` final, reorganic茅 las columnas de manera que las variables `fecha`, `longitud` y `latitud` figuren al comienzo. 

```{python}
# Reordenar las columnas
columnas_ordenadas = ['fecha', 'longitud', 'latitud'] + [col for col in df_pixel_3x3.columns if col not in ['fecha', 'longitud', 'latitud']]
df_reordenado = df_pixel_3x3[columnas_ordenadas]

# Mostramos las primeras filas para verificar
df_reordenado.head()
print("Primeras filas de df_reordenado:")
display(df_reordenado.head())
```

::: {.dropdown}
<details>
<summary> Nota t茅cnica</summary>

- `[col for col in df_pixel_3x3.columns if col not in [...]]` genera una lista con todas las columnas excepto las que se indican expl铆citamente. Esto permite personalizar el orden de las columnas de forma flexible.   
- `['fecha', 'longitud', 'latitud'] + [...]` reordena las columnas.  
- `df_pixel_3x3[columnas_ordenadas]` reordena efectivamente las columnas del DataFrame con base en la lista definida.

</details>

:::

#### Guardar el archivo final

Finalmente, guardo el resultado como un nuevo archivo .csv dentro de la carpeta datos. 

Por 煤ltimo, exporto el resultado a un nuevo archivo en formato `.csv`, mediante la funci贸n `to_csv()` de pandas, con el par谩metro `index=False` para evitar que la columna de 铆ndice se incluya en el archivo de salida que pandas crea por defecto.
Esto me permite utilizarlo despu茅s para visualizaci贸n o an谩lisis posterior.

```{python}
# Guardar el archivo CSV dentro de la carpeta "datos"
df_reordenado.to_csv('datos/datos_sol_sus_pixel_3x3.csv', index=False)
```

::: {.dropdown}
<details>
<summary> Nota t茅cnica</summary>

- `to_csv()`  guarda los datos en formato CSV.  
- `index=False` evita que se guarde el 铆ndice num茅rico del DataFrame como una columna adicional en el CSV.

</details>

:::


### An谩lisis de Regresi贸n Lineal

En este an谩lisis aplico un modelo de regresi贸n lineal simple para estudiar la relaci贸n entre la **reflectancia** y los **s贸lidos suspendidos**, utilizando datos experimentales. La regresi贸n lineal es una t茅cnica fundamental del aprendizaje autom谩tico supervisado que nos permite predecir un valor continuo basado en una o m谩s variables independientes. A lo largo de este documento, se explican paso a paso las acciones realizadas y los conceptos clave para comprender y replicar este an谩lisis.

#### Importar librer铆as

En este paso, cargo las bibliotecas necesarias para procesar datos, ajustar modelos de regresi贸n, evaluar su desempe帽o y visualizar los resultados. 

```{python}
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
```

::: {.dropdown}
<details>
<summary> Nota t茅cnica</summary>

> `pandas` se utiliza para manejar datos en forma de tablas (DataFrames), especialmente 煤tiles al trabajar con archivos `.csv`.

> `train_test_split` permite dividir los datos en subconjuntos de entrenamiento y prueba, lo cual es esencial para evaluar el desempe帽o de un modelo sin sobreajustarlo.

> `LinearRegression` representa un modelo lineal que se ajusta a los datos minimizando el error cuadr谩tico entre las predicciones y los valores reales.

> `mean_squared_error` y `r2_score` son m茅tricas de evaluaci贸n: el primero mide el promedio de los errores al cuadrado, mientras que el segundo indica qu茅 tan bien el modelo explica la variabilidad de los datos.

> `matplotlib.pyplot` se utiliza para crear gr谩ficos. Permite visualizar los datos y los resultados del modelo.
 
</details>

:::

#### Cargar datos desde un CSV

Importo el archivo `.csv` con los datos experimentales. Se visualizan las primeras filas para verificar que los datos se han cargado correctamente.

```{python}
# Cargamos el CSV
datos = pd.read_csv('datos/datos_sol_sus_pixel_3x3.csv')

# Mostramos las primeras filas para verificar
datos.head()
print("Primeras filas de datos:")
display(datos.head())
```

::: {.dropdown}
<details>
<summary> Nota t茅cnica</summary>

> `pd.read_csv` carga datos desde un archivo `.csv` y los convierte en un DataFrame de Pandas. Esta estructura tabular permite filtrar, seleccionar y transformar f谩cilmente los datos.

> `datos.head()` permite ver las primeras 5 filas del DataFrame para tener una vista preliminar de los datos cargados.

</details>

:::

#### Seleccionar variables y dividir en conjuntos

Selecciono las variables relevantes: `reflect` como variable independiente y `sol_sus` como variable dependiente. Luego divido el conjunto en dos subconjuntos: uno para entrenar el modelo y otro para probarlo, lo cual sirve para evaluar su capacidad de generalizaci贸n.

```{python}
# Selecci贸n de variables
X = datos[["reflect"]]
y = datos["sol_sus"]

# Divisi贸n en entrenamiento y validaci贸n
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)
```

::: {.dropdown}
<details>
<summary> Nota t茅cnica</summary>

> Se selecciona una columna como variable independiente (X) y otra como variable dependiente (y). Es importante usar doble corchete al seleccionar una sola columna como X para mantener la estructura de tabla.

> `train_test_split` divide el conjunto de datos en entrenamiento y prueba. Esto permite entrenar el modelo en un subconjunto y evaluar su capacidad de generalizaci贸n con otro.

> El par谩metro `test_size=0.2` indica que el 20% de los datos se usan para prueba. `shuffle=False` mantiene el orden original de los datos, 煤til cuando los datos est谩n organizados temporalmente o espacialmente.

</details>

:::

#### Entrenar modelo de regresi贸n lineal

En este paso se entrena un modelo de regresi贸n lineal usando los datos de entrenamiento. El modelo aprende la relaci贸n matem谩tica entre la reflectancia y los s贸lidos suspendidos.

```{python}
regressor = LinearRegression().fit(X_train, y_train)
```

::: {.dropdown}
<details>
<summary> Nota t茅cnica</summary>

> `LinearRegression().fit()` ajusta un modelo lineal a los datos de entrenamiento. Internamente calcula la pendiente e intercepto que minimizan la diferencia entre las predicciones y los valores reales.

</details>

:::

#### Evaluar desempe帽o del modelo

Una vez entrenado el modelo, evaluo su desempe帽o usando m茅tricas estad铆sticas. Estas nos permiten cuantificar qu茅 tan bien el modelo predice los valores de s贸lidos suspendidos a partir de la reflectancia en los datos de prueba.

```{python}
y_pred = regressor.predict(X_test)
p_rmse = mean_squared_error(y_test, y_pred)
p_r2 = r2_score(y_test, y_pred)

```

::: {.callout-note title="M茅tricas de desempe帽o"}

```{python}
#| echo: false

print("El error cuadr谩tico medio es:", round(p_rmse, 3))
print("El coeficiente de determinaci贸n (R虏) es:", round(p_r2, 3))
```
:::

::: {.dropdown}
<details>
<summary> Nota t茅cnica</summary>

> `predict()` genera predicciones del modelo usando los datos de prueba. Estas predicciones se comparan con los valores reales para evaluar el desempe帽o.

> `mean_squared_error` calcula el promedio de los errores al cuadrado. Cuanto menor sea este valor, mejor se ajusta el modelo.

> `r2_score` mide qu茅 proporci贸n de la variabilidad en los datos es explicada por el modelo. Un valor cercano a 1 indica una buena predicci贸n.

</details>

:::

#### Visualizar el modelo

Finalmente, se visualiza gr谩ficamente la relaci贸n entre reflectancia y s贸lidos suspendidos, tanto en el conjunto de entrenamiento como en el de prueba. Esto ayuda a interpretar de forma visual c贸mo se ajusta el modelo a los datos reales.

```{python}
fig, ax = plt.subplots(ncols=2, figsize=(10, 5), sharex=True, sharey=True)

# Gr谩fico entrenamiento
ax[0].plot(X_train, regressor.predict(X_train), linewidth=3, color="#17A77E", label="Modelo")
ax[0].scatter(X_train, y_train, label="Entrenamiento", color="#9D50A6", alpha=0.6)
ax[0].set(xlabel="Reflectancia", ylabel="Sol_Sus", title="Conjunto de entrenamiento")
ax[0].legend()

# Gr谩fico validaci贸n
ax[1].plot(X_test, y_pred, linewidth=3, color="#17A77E", label="Modelo")
ax[1].scatter(X_test, y_test, label="Validaci贸n", color="#9D50A6", alpha=0.6)
ax[1].set(xlabel="Reflectancia", ylabel="Sol_Sus", title="Conjunto de validaci贸n")
ax[1].legend()

fig.suptitle("Regresi贸n lineal")

plt.show()
```

::: {.dropdown}
<details>
<summary> Nota t茅cnica</summary>

> `plt.subplots` crea una figura con uno o m谩s ejes para dibujar. Permite organizar varios gr谩ficos en una misma figura.

> `plot()` traza una l铆nea continua. Se usa para mostrar la l铆nea de regresi贸n generada por el modelo.

> `scatter()` traza puntos individuales. Se usa para mostrar los datos reales y compararlos con la l铆nea del modelo.

> `set()` configura etiquetas de ejes y t铆tulos de los subgr谩ficos.

> `legend()` muestra una leyenda que identifica cada elemento del gr谩fico.

> `fig.suptitle()` agrega un t铆tulo general a la figura completa.

> `plt.show()` es necesario para visualizar los gr谩ficos al renderizar el documento.

</details>

:::



### Regresi贸n lineal simple usando una sola banda espectral (B01)

En este an谩lisis voy a construir un modelo de regresi贸n lineal simple para predecir la variable **sol_sus** a partir de una 煤nica variable independiente: la **banda espectral B01**. 

El objetivo es evaluar la capacidad de esta banda individual para explicar el comportamiento de la variable de inter茅s.

::: {.callout-tip title="驴Qu茅 cambi贸 respecto al ejemplo anterior?"}
En el ejemplo anterior, el conjunto de datos contiene reflectancia medida en distintas bandas espectrales, identificadas en la columna `banda` (como "B01", "B02", etc.).
Ahora, para el an谩lisis, selecciono solo las filas donde `banda` es `B01`, usando sus valores de reflectancia (`reflect`) como variable independiente `X` para predecir los s贸lidos suspendidos (`sol_sus`).

:::

#### Importaci贸n de librer铆as

```{python}
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
```

#### Carga de datos

```{python}
df = pd.read_csv('datos/datos_sol_sus_pixel_3x3.csv')
df.head()
```

#### Selecci贸n de variables y divisi贸n de datos

```{python}
df_B01 = df[df['banda'] == 'B01']

X = df_B01[['reflect']]  # Variable independiente: reflectancia para B01
y = df_B01['sol_sus']    # Variable dependiente

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, shuffle=False
)
```

::: {.dropdown}
<details>
<summary> Nota t茅cnica</summary>

> `df[df['banda'] == 'B01']` es un filtro en pandas para seleccionar solo las filas donde la columna "banda" tenga el valor "B01". El resultado es un nuevo DataFrame con solo esas filas.

</details>

:::

#### Entrenamiento del modelo

```{python}
regressor = LinearRegression().fit(X_train, y_train)
```

#### Evaluaci贸n del modelo

```{python}
y_pred = regressor.predict(X_test)
p_rmse = mean_squared_error(y_test, y_pred)
p_r2 = r2_score(y_test, y_pred)
```

::: {.callout-note title="M茅tricas de desempe帽o"}

```{python}
#| echo: false
print(f"Error cuadr谩tico medio (RMSE): {p_rmse:.3f}")
print(f"Coeficiente de determinaci贸n (R虏): {p_r2:.3f}")
```
:::

#### Visualizaci贸n de resultados

```{python}
fig, ax = plt.subplots(ncols=2, figsize=(10, 5), sharex=True, sharey=True)

# Conjunto de entrenamiento
ax[0].plot(X_train, regressor.predict(X_train), linewidth=3, color="#17A77E", label="Modelo")
ax[0].scatter(X_train, y_train, label="Entrenamiento", color="#9D50A6", alpha=0.6)
ax[0].set(xlabel="B01", ylabel="Sol_sus", title="Conjunto de entrenamiento")
ax[0].legend()

# Conjunto de validaci贸n
ax[1].plot(X_test, y_pred, linewidth=3, color="#17A77E", label="Modelo")
ax[1].scatter(X_test, y_test, label="Validaci贸n", color="#9D50A6", alpha=0.6)
ax[1].set(xlabel="B01", ylabel="Sol_sus", title="Conjunto de validaci贸n")
ax[1].legend()

fig.suptitle("Regresi贸n lineal - B01 vs Sol_sus")
plt.show()
```