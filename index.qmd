---
title: "AnÃ¡lisis de SÃ³lidos Suspendidos"
format: 
  html:
    number-sections: true
    toc: true 
    toc-location: right
    toc-depth: 3
    embed-resources: true
    crossrefs-hover: false
    lang: es
    bibliography: bibliografia/bibliografia.bib
    csl: bibliografia/ieee.csl
date: last-modified
author:
  - name: Ariadna Malena Seba
    orcid: 
    corresponding: true
    email: ariadna.mseba@ca.frre.utn.edu.ar
    affiliations:
      - name: GISTAQ (UTN-FRRe)
        url: https://www.instagram.com/gistaq.utn/
abstract: |
  Este sitio web aborda el anÃ¡lisis de sÃ³lidos suspendidos totales (SST) en cuerpos de agua mediante el uso de imÃ¡genes satelitales y tÃ©cnicas de aprendizaje automÃ¡tico. Presenta una introducciÃ³n teÃ³rica sobre la importancia de los SST como indicador ambiental y luego desarrolla una parte prÃ¡ctica con Python, donde se integran datos espectrales y mediciones reales para aplicar modelos de regresiÃ³n. Se evalÃºa el desempeÃ±o de estos modelos y se exploran relaciones entre bandas espectrales y SST, proponiendo mejoras metodolÃ³gicas para estudios futuros.
keywords:
  - GISTAQ
  - UTN
  - FRRe
  - Quarto
  - SÃ³lidos Suspendidos 
jupyter: python3
execute:
  echo: true
---

## SÃ³lidos suspendidos totales<span style="font-weight:normal; font-size: 1rem">, por Vera Geneyer (https://github.com/VeraGeneyer)</span> {toc-text="SÃ³lidos suspendidos totales"}

Los sÃ³lidos suspendidos totales (TSM) son la cantidad de materia en suspensiÃ³n en el agua, que incluye plancton, minerales, arena, y microorganismos. Se determinan como el residuo no filtrable de una muestra de agua. Niveles altos (TSM) pueden reducir la transparencia del agua, limitar la luz y y transportar sustancias tÃ³xicas, afectando la vida acuÃ¡tica y la calidad del agua.
Este parÃ¡metro, medido mediante sensores remotos, nos da informaciÃ³n sobre el estado fÃ­sico del cuerpo de agua y estÃ¡n relacionados con factores como la humedad, temperatura y entre otros, que es vital para detectar riesgos al ecosistema y cumplir con las normas ambientales.

### MÃ©todos tradicionales

:::: {.content-visible when-format="html"}

::: {.column-screen-right}

| EcuaciÃ³n | Bandas (nm) | MÃ©tricas | Aguas | Plataforma | Referencia |
|:-:|:--|:--|:--|:--|:-:|
| $-229.34 \left( \frac{B03}{B08} \right)^{3}+1001.65 \left( \frac{B03}{B08} \right)^{2}-1422.7 \left( \frac{B03}{B08} \right)+665.17$ | B03, B08 | $R^{2}$ | Embalse^[Aguas lÃ©nticas.] | Landsat-8 | @Ramirez2017 |
| $-244.83+40.21 \cdot B01-3.67 \cdot NDWI$ | B01, NDWI (B03, B08) | $R^{2}$, RMSE, d | RÃ­o^[d = prueba estadÃ­stica de <b>Durbin-Watson</b>.] | GeoEye | @Gomez2014 |

: CaracterÃ­sticas principales de algoritmos tradicionales para la estimaciÃ³n de sÃ³lidos suspendidos. {#tbl-solsus-trad .striped .hover tbl-colwidths="[50,10,10,10,10]"}

:::

::::

:::: {.content-visible when-format="typst"}

| EcuaciÃ³n | Referencia |
|:--|:-:|
| $-229.34 \left( \frac{B03}{B08} \right)^{3}+1001.65 \left( \frac{B03}{B08} \right)^{2}-1422.7 \left( \frac{B03}{B08} \right)+665.17$ | [@Ramirez2017] |
| $-244.83+40.21 \cdot B01-3.67 \cdot NDWI$ | [@Gomez2014] |

: CaracterÃ­sticas principales de algoritmos tradicionales para la estimaciÃ³n de sÃ³lidos suspendidos. {#tbl-solsus-trad .striped .hover tbl-colwidths="[80,20]"}

::: {.block stroke='rgb("#B86092")' inset="8pt" radius="4pt"}

[Ver tabla completa en la versiÃ³n online &#x2197;](https://vhgauto.quarto.pub/gistaq-parana/#tbl-solsus-trad)

:::

::::

De acuerdo a un estudio que analizÃ³ 48 cuerpos de agua, la estimaciÃ³n de TSM se hizo en su mayorÃ­a por modelos lineales, siendo la banda B8A la mÃ¡s frecuente [@Cruz2023].

### MÃ©todos de aprendizaje automÃ¡tico

El **aprendizaje automÃ¡tico (ML)**  es una rama de la inteligencia artificial cuyo objetivo es desarrollar algoritmos capaces de resolver problemas mediante el anÃ¡lisis de datos y la creaciÃ³n de funciones que describen el comportamiento de fenÃ³menos monitoreados [@Carpio2021]. Los modelos de aprendizaje automÃ¡tico mÃ¡s utilizados y mencionados por los investigadores para predecir la concentraciÃ³n de SST son:

* **Bosque Aleatorio (RF) y Refuerzo Adaptativo (AdB)**, modelos que se destacan por su robustez ante datos complejos y ruidosos. Estos algoritmos construyen mÃºltiples Ã¡rboles de decisiÃ³n que analizan las relaciones entre caracterÃ­sticas como el uso del suelo o el volumen de escorrentÃ­a y los niveles de SST [@Moeini2021].

* **Redes Neuronales Artificiales (ANN)**, copian las redes neuronales biolÃ³gicas y aprenden patrones complejos en grandes volÃºmenes de datos, como los niveles de SST en distintas condiciones ambientales [@Moeini2021],

* **k-Nearest Neighbors (kNN)**, en sus variantes de ponderaciÃ³n uniforme y variable, que estima el SST en funciÃ³n de la cercanÃ­a en caracterÃ­sticas de nuevos puntos de muestreo con datos histÃ³ricos [@Moeini2021].

El aprendizaje automÃ¡tico es esencial para mejorar la precisiÃ³n y rapidez en el anÃ¡lisis de la calidad del agua, proporcionando un monitoreo mÃ¡s eficiente y menos costoso en comparaciÃ³n con los mÃ©todos tradicionales, especialmente en Ã¡reas de difÃ­cil acceso o con datos limitados.

:::: {.content-visible when-format="html"}

::: {.column-screen-right}

| **Modelo de machine learning** | **Software** | **Agua** | **Datos** | **MÃ©tricas** | **Referencias** |
|:--|:--|:--|:--|:--|:-:|
|Bagging y Random Forest|Programa R|BahÃ­a|Muestreo|Prueba de normalidad multivalente Mardia-tests y Royston|@Carpio2021|
|RegresiÃ³n lineal, LASSO, regresiÃ³n de vectores de soporte (SVR), K vecinos mÃ¡s cercanos (KNN), bosque aleatorio (RF) y redes neuronales artificiales (ANN).|-|Lago y embalse|Sentinel-2 y UAV|$R^{2}$| @Silveira2020|
|RegresiÃ³n lineal, regresiÃ³n de vectores de soporte (SVR), K vecinos mÃ¡s cercanos (KNN), bosque aleatorio (RF) y redes neuronales artificiales (ANN).|Programa Python|Lagos|EstaciÃ³n de monitoreo (Sensores para cada parÃ¡metro)|$R^{2}$, NSE y RMSE| @Moeini2021|

: CaracterÃ­sticas principales de algoritmos de aprendizaje automÃ¡tico para la estimaciÃ³n de sÃ³lidos suspendidos. {#tbl-solsus-machine .striped .hover tbl-colwidths="[40,12,12,13,13,10]"}

:::

::::

:::: {.content-visible when-format="typst"}

| Modelo de machine learning | Referencias |
|:--|:-:|
|Bagging y Random Forest| [@Carpio2021] |
|RegresiÃ³n lineal, LASSO, regresiÃ³n de vectores de soporte (SVR), K vecinos mÃ¡s cercanos (KNN), bosque aleatorio (RF) y redes neuronales artificiales (ANN).| [@Silveira2020] |
|RegresiÃ³n lineal, regresiÃ³n de vectores de soporte (SVR), K vecinos mÃ¡s cercanos (KNN), bosque aleatorio (RF) y redes neuronales artificiales (ANN).| [@Moeini2021] |

: CaracterÃ­sticas principales de algoritmos de aprendizaje automÃ¡tico para la estimaciÃ³n de sÃ³lidos suspendidos. {#tbl-solsus-machine .striped .hover tbl-colwidths="[80,20]"}

::: {.block stroke='rgb("#B86092")' inset="8pt" radius="4pt"}

[Ver tabla completa en la versiÃ³n online &#x2197;](https://vhgauto.quarto.pub/gistaq-parana/#tbl-solsus-machine)

:::

::::



## Desarrollo integral del algoritmo

En esta secciÃ³n describo el proceso completo para crear un modelo que estima los sÃ³lidos suspendidos totales (SST) usando datos satelitales y de campo, desde la preparaciÃ³n de datos hasta la validaciÃ³n del algoritmo.



### Procesamiento inicial de datos con Sen2Cor

Se detalla el procedimiento tÃ©cnico que implementÃ© para procesar informaciÃ³n ambiental georreferenciada, con el objetivo de analizar el comportamiento del parÃ¡metro **sÃ³lidos suspendidos (sol_sus)** en una regiÃ³n especÃ­fica del estudio (pÃ­xel `3x3`). 

Para esto, utilicÃ© el lenguaje Python y la biblioteca `pandas`, que resulta particularmente eficiente para el manejo y transformaciÃ³n de datos en estructuras tabulares. Este paso fue fundamental para preparar los datos y asegurar su calidad antes del anÃ¡lisis.


#### Carga de datos

Primero importo la biblioteca `pandas`, una herramienta en Python que se utiliza para manejar datos en formato tabular (como hojas de cÃ¡lculo o CSVs). Se le da el alias `pd` por convenciÃ³n, para simplificar el cÃ³digo.

Luego cargo dos archivos CSV con la funciÃ³n `pd.read_csv()`, la cual convierte dichos archivos en objetos del tipo `DataFrame`, que representan tablas en memoria, que son estructuras de datos similares a tablas (parecida a una hoja de Excel). Los conjuntos de datos cargados fueron:

- `gis_df`: contiene informaciÃ³n geogrÃ¡fica (latitud, longitud, pixel, etc.).
- `lab_df`: contiene datos de laboratorio, incluyendo el parÃ¡metro de interÃ©s `sol_sus`.

 Verifico la carga correcta mostrando las primeras filas con la funciÃ³n `.head()`. Es Ãºtil para ver rÃ¡pidamente cÃ³mo es la estructura del archivo: quÃ© columnas hay, quÃ© tipo de datos, si se cargÃ³ bien.

```{python}
import pandas as pd  # pandas es la biblioteca para manejar datos tabulares

# Cargar los archivos de datos
gis_df = pd.read_csv('datos/base_de_datos_gis.csv')
lab_df = pd.read_csv('datos/base_de_datos_lab.csv')

# Ver las primeras filas para asegurarse de que se cargaron bien
gis_df.head(), lab_df.head()

print("Primeras filas de gis_df:")
display(gis_df.head())

print("\nPrimeras filas de lab_df:")
display(lab_df.head())
```

::: {.dropdown}
<details>
<summary>ğŸ“„ Nota tÃ©cnica</summary>

- `pd.read_csv()` carga los archivos en estructuras llamadas *dataframes*, que funcionan como tablas.  
- `head()` te muestra las primeras 5 filas para ver cÃ³mo estÃ¡n los datos.
- `display()` permite mostrar las tablas con formato mÃ¡s visual (en HTML).

</details>

:::

#### Filtrado del parÃ¡metro sÃ³lidos suspendidos ('sol_sus')

En el conjunto de datos del laboratorio `lab_df`, hay mÃºltiples parÃ¡metros medidos (como pH, turbidez, etc.). En este caso, me interesa trabajar solamente con los datos de **sÃ³lidos suspendidos**, identificado como `"sol_sus"` en la columna `param`. Este filtrado selectivo lo realicÃ© para limitar el anÃ¡lisis al fenÃ³meno fÃ­sico-quÃ­mico de interÃ©s.

FiltrÃ© el DataFrame para quedarme solo con esas filas, y renombrÃ© la columna `valor` como `sol_sus` para que sea mÃ¡s claro en los siguientes pasos.

```{python}
# Filtrar solo las filas donde el parÃ¡metro es 'sol_sus'
sol_sus_df = lab_df[lab_df["param"] == "sol_sus"]

# Renombrar la columna 'valor' a 'sol_sus' para que tenga sentido en el merge
sol_sus_df = sol_sus_df.rename(columns={"valor": "sol_sus"})

# Mostrar para confirmar
sol_sus_df.head()
print("Primeras filas de sol_sus_df:")
display(sol_sus_df.head())
```

::: {.dropdown}
<details>
<summary>ğŸ“„ Nota tÃ©cnica</summary>

- `lab_df[lab_df["param"] == "sol_sus"]` filtra las filas cuyo valor en la columna `"param"` sea `"sol_sus"`.  
- `.rename(columns={"valor": "sol_sus"})` cambia el nombre de la columna `"valor"` a `"sol_sus"`.

</details>

:::


#### ReorganizaciÃ³n de datos: pivotar bandas en columnas individuales

En este paso, convierto los valores Ãºnicos de la columna `banda` (como `B01`, `B02`, etc.) en nombres de columnas. Cada nueva columna contendrÃ¡ los valores del parÃ¡metro `reflect` correspondientes a esa banda en particular. Esta operaciÃ³n se realiza antes de unir con los valores de `sol_sus`, ya que el valor de reflectancia depende de la banda, mientras que `sol_sus` es un dato independiente que se asignarÃ¡ luego por punto, fecha y ubicaciÃ³n.

```{python}
# Pivotear la tabla para que cada banda sea una columna
gis_pivot = gis_df.pivot_table(
    index=['fecha', 'punto', 'pixel', 'latitud', 'longitud'],
    columns='banda',
    values='reflect'
).reset_index()

# Eliminar el nombre del Ã­ndice de columnas generado por el pivot
gis_pivot.columns.name = None

print("Primeras filas de gis_pivot:")
display(gis_pivot.head())
```

::: {.dropdown}
<details> 
<summary>ğŸ“„ Nota tÃ©cnica</summary>

- `pivot_table()` reorganiza el DataFrame convirtiendo los valores de una columna (`banda`) en columnas individuales.
- `index=[...]` define las columnas que se mantendrÃ¡n como claves (se repetirÃ¡n por fila).
- `columns='banda'` indica quÃ© columna queremos transformar en nombres de columnas.
- `values='reflect'` especifica quÃ© valor colocar en cada celda de la nueva tabla.
- `reset_index()` convierte los Ã­ndices jerÃ¡rquicos en columnas normales para facilitar el anÃ¡lisis.
- `columns.name = None` quita la etiqueta "banda" que se agregarÃ­a al encabezado por defecto.

</details> 

:::


#### UniÃ³n de datos geoespaciales con datos de laboratorio

Una vez que las bandas han sido transformadas en columnas, combino esta tabla con los valores de sÃ³lidos suspendidos (`sol_sus`) provenientes del laboratorio. La combinaciÃ³n se hace usando las columnas `fecha`, `latitud` y `longitud`, que permiten identificar los datos correspondientes a un mismo punto geogrÃ¡fico y temporal.

```{python}
# Realizar el merge por ubicaciÃ³n y fecha
df_merged = pd.merge(
    gis_pivot,
    sol_sus_df[['fecha', 'latitud', 'longitud', 'sol_sus']],
    on=['fecha', 'latitud', 'longitud'],
    how='inner'
)

print("Primeras filas del DataFrame combinado:")
display(df_merged.head())
```

::: {.dropdown}
<details>
<summary>ğŸ“„ Nota tÃ©cnica</summary>

- `pd.merge()` permite combinar dos DataFrames en uno nuevo, uniendo filas que coincidan en las columnas especificadas.  
- `on=["latitud", "longitud"]` indica que la combinaciÃ³n debe hacerse usando esas columnas como claves.  
- `how="inner"` especifica el tipo de combinaciÃ³n:  
  - `"inner"`: solo conserva las filas donde hay coincidencia en ambos DataFrames.  
  - Otras opciones:  
    - `"left"`: conserva todas las filas del primer DataFrame.  
    - `"right"`: conserva todas las filas del segundo.  
    - `"outer"`: conserva todo, incluso si no hay coincidencia.

</details>

:::


#### Filtrado espacial por pÃ­xel de interÃ©s (3x3)

Luego de combinar los datos, aplico un filtrado adicional al DataFrame sobre la columna `pixel` para conservar Ãºnicamente las filas correspondientes al Ã¡rea geogrÃ¡fica designada como `"3x3"`. Este paso reduce el dominio de anÃ¡lisis y permite concentrarse en una regiÃ³n de estudio concreta.

```{python}
# Filtrar solo los datos del pixel 3x3
df_pixel_3x3 = df_merged[df_merged["pixel"] == "3x3"]

print("Primeras filas del pixel 3x3:")
display(df_pixel_3x3.head())
```

::: {.dropdown}
<details>
<summary>ğŸ“„ Nota tÃ©cnica</summary>

- Usa filtrado booleano (`DataFrame[condiciÃ³n]`), que es la forma estÃ¡ndar en pandas para seleccionar subconjuntos de datos. 
- `df_pixel_3x3 = df_combinado[df_combinado["pixel"] == "3x3"]` selecciona ese subconjunto. Filtra las filas cuyo valor en la columna `"pixel"` es igual a `"3x3"`.

</details>

:::


#### ExportaciÃ³n de datos procesados

Finalmente, guardo el resultado como un nuevo archivo .csv dentro de la carpeta datos. 

Por Ãºltimo, exporto el resultado a un nuevo archivo en formato `.csv`, mediante la funciÃ³n `to_csv()` de pandas, con el parÃ¡metro `index=False` para evitar que la columna de Ã­ndice se incluya en el archivo de salida que pandas crea por defecto.
Esto me permite utilizarlo despuÃ©s para visualizaciÃ³n o anÃ¡lisis posterior.

```{python}
# Guardar el archivo CSV dentro de la carpeta "datos"
df_pixel_3x3.to_csv('datos/datos_sol_sus_pixel_3x3.csv', index=False)
```

::: {.dropdown}
<details>
<summary>ğŸ“„ Nota tÃ©cnica</summary>

- `to_csv()`  guarda los datos en formato CSV.  
- `index=False` evita que se guarde el Ã­ndice numÃ©rico del DataFrame como una columna adicional en el CSV.

</details>

:::



### AplicaciÃ³n del procesamiento a datos ACOLITE

A continuaciÃ³n, repetÃ­ el mismo procedimiento de procesamiento aplicado anteriormente, esta vez utilizando el archivo `base_de_datos_gis_acolite.csv`, generado con el procesador atmosfÃ©rico **ACOLITE**.

ACOLITE es una herramienta diseÃ±ada especÃ­ficamente para corregir efectos atmosfÃ©ricos en ambientes acuÃ¡ticos, a partir de imÃ¡genes satelitales. Gracias a que la estructura del archivo es similar al utilizado anteriormente (Sen2Cor), fue posible aplicar la misma lÃ³gica de filtrado, transformaciÃ³n y combinaciÃ³n para preparar los datos de reflectancia.

```{python}
#|code-fold: true
import pandas as pd

# 1. Cargar archivos CSV 
gis_acol_df = pd.read_csv('datos/base_de_datos_gis_acolite.csv')
lab_df = pd.read_csv('datos/base_de_datos_lab.csv')

# 2. Filtrar solo el parÃ¡metro 'sol_sus' 
sol_sus_df = lab_df[lab_df["param"] == "sol_sus"]
sol_sus_df = sol_sus_df.rename(columns={"valor": "sol_sus"})

#  3. Pivotear bandas en columnas 
gis_pivot = gis_acol_df.pivot_table(
    index=['fecha', 'punto', 'latitud', 'longitud'],
    columns='banda',
    values='reflect'
).reset_index()

gis_pivot.columns.name = None  # Quitar la etiqueta 'banda'

# 4. Combinar reflectancias con sol_sus 
df_merged = pd.merge(
    gis_pivot,
    sol_sus_df[['fecha', 'latitud', 'longitud', 'sol_sus']],
    on=['fecha', 'latitud', 'longitud'],
    how='inner'
)

# 5. Guardar resultado final
df_merged.to_csv('datos/datos_sol_sus_acolite.csv', index=False)

# 6. Mostrar muestra del resultado
print("Primeras filas del DataFrame resultante:")
display(df_merged.head())

```



### Modelo baseÂ Â· RegresiÃ³n lineal simple

En este anÃ¡lisis aplico un modelo de **regresiÃ³n lineal simple** para estudiar la relaciÃ³n entre la **reflectancia** (banda `B01`) y la concentraciÃ³n de **sÃ³lidos suspendidos (sol_sus)**, utilizando datos experimentales. La regresiÃ³n lineal es una tÃ©cnica fundamental del aprendizaje automÃ¡tico supervisado que permite predecir un valor continuo a partir de una o mÃ¡s variables independientes, y suele emplearse como modelo base frente a enfoques mÃ¡s complejos. A lo largo de esta secciÃ³n, detallo paso a paso las acciones realizadas y explico los conceptos clave para comprender y replicar este anÃ¡lisis.

#### Importar librerÃ­as

En este paso, cargo las bibliotecas necesarias para procesar datos, ajustar modelos de regresiÃ³n, evaluar su desempeÃ±o y visualizar los resultados. 

```{python}
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
```

::: {.dropdown}
<details>
<summary>ğŸ“„ Nota tÃ©cnica</summary>

> `pandas` se utiliza para manejar datos en forma de tablas (DataFrames), especialmente Ãºtiles al trabajar con archivos `.csv`.

> `train_test_split` permite dividir los datos en subconjuntos de entrenamiento y prueba, lo cual es esencial para evaluar el desempeÃ±o de un modelo sin sobreajustarlo.

> `LinearRegression` representa un modelo lineal que se ajusta a los datos minimizando el error cuadrÃ¡tico entre las predicciones y los valores reales.

> `mean_squared_error` y `r2_score` son mÃ©tricas de evaluaciÃ³n: el primero mide el promedio de los errores al cuadrado, mientras que el segundo indica quÃ© tan bien el modelo explica la variabilidad de los datos.

> `matplotlib.pyplot` se utiliza para crear grÃ¡ficos. Permite visualizar los datos y los resultados del modelo.
 
</details>

:::

#### Cargar datos desde un CSV

Importo el archivo `.csv` con los datos experimentales. Se visualizan las primeras filas para verificar que los datos se han cargado correctamente.

```{python}
# Cargar el CSV
datos = pd.read_csv('datos/datos_sol_sus_acolite.csv')

# Mostrar las primeras filas para verificar
datos.head()
print("Primeras filas de datos:")
display(datos.head())
```

::: {.dropdown}
<details>
<summary>ğŸ“„ Nota tÃ©cnica</summary>

> `pd.read_csv` carga datos desde un archivo `.csv` y los convierte en un DataFrame de Pandas. Esta estructura tabular permite filtrar, seleccionar y transformar fÃ¡cilmente los datos.

> `datos.head()` permite ver las primeras 5 filas del DataFrame para tener una vista preliminar de los datos cargados.

</details>

:::

#### Definir variables y particionar el conjunto

Selecciono las variables relevantes: `B01` como variable independiente y `sol_sus` como variable dependiente. Luego divido el conjunto en dos subconjuntos: uno para entrenar el modelo y otro para probarlo, lo cual sirve para evaluar su capacidad de generalizaciÃ³n.

```{python}
# SelecciÃ³n de variables
X = datos[["B01"]]           # variable independiente
y = datos["sol_sus"]         # variable dependiente

# DivisiÃ³n en entrenamiento y validaciÃ³n
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)
```

::: {.dropdown}
<details>
<summary>ğŸ“„ Nota tÃ©cnica</summary>

> Se selecciona una columna como variable independiente (X) y otra como variable dependiente (y). Es importante usar doble corchete al seleccionar una sola columna como X para mantener la estructura de tabla.

> `train_test_split` divide el conjunto de datos en entrenamiento y prueba. Esto permite entrenar el modelo en un subconjunto y evaluar su capacidad de generalizaciÃ³n con otro.

> El parÃ¡metro `test_size=0.2` indica que el 20% de los datos se usan para prueba. `shuffle=False` mantiene el orden original de los datos, Ãºtil cuando los datos estÃ¡n organizados temporalmente o espacialmente.

</details>

:::


#### Entrenar modelo de regresiÃ³n lineal

En este paso se entrena un modelo de regresiÃ³n lineal usando los datos de entrenamiento. El modelo aprende la relaciÃ³n matemÃ¡tica entre la reflectancia y los sÃ³lidos suspendidos.

```{python}
regressor = LinearRegression().fit(X_train, y_train)
```

::: {.dropdown}
<details>
<summary>ğŸ“„ Nota tÃ©cnica</summary>

> `LinearRegression().fit()` ajusta un modelo lineal a los datos de entrenamiento. Internamente calcula la pendiente e intercepto que minimizan la diferencia entre las predicciones y los valores reales.

</details>

:::


#### Evaluar desempeÃ±o del modelo

Una vez entrenado el modelo, evaluo su desempeÃ±o usando mÃ©tricas estadÃ­sticas. Estas nos permiten cuantificar quÃ© tan bien el modelo predice los valores de sÃ³lidos suspendidos a partir de la reflectancia en los datos de prueba.

```{python}
y_pred = regressor.predict(X_test)
p_rmse = mean_squared_error(y_test, y_pred)
p_r2 = r2_score(y_test, y_pred)

```

::: {.callout-note title="MÃ©tricas de desempeÃ±o"}

```{python}
#| echo: false

print("El error cuadrÃ¡tico medio es:", round(p_rmse, 3))
print("El coeficiente de determinaciÃ³n (RÂ²) es:", round(p_r2, 3))
```
:::

::: {.dropdown}
<details>
<summary>ğŸ“„ Nota tÃ©cnica</summary>

> `predict()` genera predicciones del modelo usando los datos de prueba. Estas predicciones se comparan con los valores reales para evaluar el desempeÃ±o.

> `mean_squared_error` calcula el promedio de los errores al cuadrado. Cuanto menor sea este valor, mejor se ajusta el modelo.

> `r2_score` mide quÃ© proporciÃ³n de la variabilidad en los datos es explicada por el modelo. Un valor cercano a 1 indica una buena predicciÃ³n.

</details>

:::


#### Visualizar resultados

Finalmente, se visualiza grÃ¡ficamente la relaciÃ³n entre reflectancia y sÃ³lidos suspendidos, tanto en el conjunto de entrenamiento como en el de prueba. Esto ayuda a interpretar de forma visual cÃ³mo se ajusta el modelo a los datos reales.

```{python}
fig, ax = plt.subplots(ncols=2, figsize=(10, 5), sharex=True, sharey=True)

# GrÃ¡fico entrenamiento
ax[0].plot(X_train, regressor.predict(X_train), linewidth=3, color="#17A77E", label="Modelo")
ax[0].scatter(X_train, y_train, label="Entrenamiento", color="#9D50A6", alpha=0.6)
ax[0].set(xlabel="Reflectancia", ylabel="Sol_Sus", title="Conjunto de entrenamiento")
ax[0].legend()

# GrÃ¡fico validaciÃ³n
ax[1].plot(X_test, y_pred, linewidth=3, color="#17A77E", label="Modelo")
ax[1].scatter(X_test, y_test, label="ValidaciÃ³n", color="#9D50A6", alpha=0.6)
ax[1].set(xlabel="Reflectancia", ylabel="Sol_Sus", title="Conjunto de validaciÃ³n")
ax[1].legend()

fig.suptitle("RegresiÃ³n lineal")

plt.show()
```

::: {.dropdown}
<details>
<summary>ğŸ“„ Nota tÃ©cnica</summary>

> `plt.subplots` crea una figura con uno o mÃ¡s ejes para dibujar. Permite organizar varios grÃ¡ficos en una misma figura.

> `plot()` traza una lÃ­nea continua. Se usa para mostrar la lÃ­nea de regresiÃ³n generada por el modelo.

> `scatter()` traza puntos individuales. Se usa para mostrar los datos reales y compararlos con la lÃ­nea del modelo.

> `set()` configura etiquetas de ejes y tÃ­tulos de los subgrÃ¡ficos.

> `legend()` muestra una leyenda que identifica cada elemento del grÃ¡fico.

> `fig.suptitle()` agrega un tÃ­tulo general a la figura completa.

> `plt.show()` es necesario para visualizar los grÃ¡ficos al renderizar el documento.

</details>

:::



### RegresiÃ³n lineal individual por banda

Con el fin de profundizar el anÃ¡lisis, evaluÃ© la relaciÃ³n entre los **sÃ³lidos suspendidos (sol_sus)** y cada **banda espectral** por separado. Para esto, entrenÃ© un modelo de regresiÃ³n lineal simple usando los mismos datos experimentales para cada banda.  

Con este enfoque comparo la capacidad predictiva individual de cada banda mediante las mÃ©tricas `RÂ²`, `RÂ²` ajustado y el error cuadrÃ¡tico medio (`RMSE`). Este anÃ¡lisis me permite identificar quÃ© bandas tienen mejor relaciÃ³n lineal con los sÃ³lidos suspendidos y sentar la base para probar modelos mÃ¡s complejos.

```{python}
#|code-fold: true
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt
import math
from IPython.display import display

# Cargar datos
datos = pd.read_csv('datos/datos_sol_sus_acolite.csv')

# Detectar columnas de bandas
bandas = [col for col in datos.columns if col.startswith("B")]

# Lista para guardar resultados
resultados = []

# ParÃ¡metros para organizaciÃ³n de grÃ¡ficos
n_bandas = len(bandas)
ncols = 3  # NÃºmero de columnas de la grilla
nrows = math.ceil(n_bandas / ncols)  # Calculamos cuÃ¡ntas filas se necesitan

# Crear figura
fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(12, 4 * nrows))
axs = axs.flatten()  # Asegura que podamos indexarlos como una lista

for i, banda in enumerate(bandas):
    # Variables
    X = datos[[banda]]
    y = datos["sol_sus"]

    # DivisiÃ³n entrenamiento/prueba
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

    # Ajuste del modelo
    modelo = LinearRegression().fit(X_train, y_train)
    y_train_pred = modelo.predict(X_train)

    # MÃ©tricas
    r2 = modelo.score(X_train, y_train)
    n = len(y_train)
    p = X_train.shape[1]
    r2_adj = 1 - (1 - r2) * (n - 1) / (n - p - 1)
    rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))

    resultados.append({
        "Banda": banda,
        "RÂ²": round(r2, 4),
        "RÂ²_ajustado": round(r2_adj, 4),
        "RMSE": round(rmse, 4)
    })

    # GrÃ¡fico de entrenamiento
    ax = axs[i]
    ax.scatter(X_train, y_train, alpha=0.6, color="#9D50A6", label="Entrenamiento")
    ax.plot(X_train, y_train_pred, color="#17A77E", linewidth=1.8, label="Modelo")
    ax.set_title(f'{banda}\nRÂ²={r2:.2f}', fontsize=10)
    ax.set_xlabel('Reflectancia', fontsize=8)
    ax.set_ylabel('Sol_Sus', fontsize=8)
    ax.tick_params(axis='both', which='major', labelsize=8)
    ax.legend(fontsize=7)
    ax.grid(True)

# Eliminar ejes sobrantes
for j in range(i + 1, len(axs)):
    fig.delaxes(axs[j])

plt.suptitle("Regresiones lineales por banda (entrenamiento)", fontsize=14)
plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()

# Tabla resumen
df_resultados = (
    pd.DataFrame(resultados)
      .round(3)
      .sort_values("RÂ²", ascending=False)   # la mejor banda queda arriba
      .reset_index(drop=True)
)

def style_metrics(df: pd.DataFrame, caption: str):
    sty = (
        df.style
          .format(precision=3)
    )

    # Ocultar Ã­ndice segÃºn versiÃ³n de pandas
    if hasattr(sty, "hide"):
        sty = sty.hide(axis="index")
    else:
        sty = sty.hide_index()

    # Agregar tÃ­tulo y estilo del tÃ­tulo
    sty = sty.set_caption(caption)
    sty = sty.set_table_styles([{
        "selector": "caption",
        "props": [
            ("caption-side", "top"),
            ("font-weight",  "bold"),
            ("margin-bottom", "0.5em")
        ]
    }], overwrite=False)

    return sty

# Mostrar tabla  
display(style_metrics(df_resultados,
                      "Resumen de mÃ©tricas por banda (entrenamiento)"))

```


::: {.callout-note title="Conclusiones del anÃ¡lisis por banda"}

Los resultados muestran que ninguna banda espectral logra predecir con alta precisiÃ³n los sÃ³lidos suspendidos mediante un modelo lineal simple.  

Las bandas **B05**, **B06** y **B07** presentan los mejores valores de `RÂ²` (alrededor de 0.18), lo que indica que explican menos del 20â€¯% de la variabilidad en los datos. El resto de las bandas tienen un desempeÃ±o aÃºn menor, con errores (`RMSE`) relativamente altos en comparaciÃ³n con los valores observados.  

Esto sugiere que la relaciÃ³n entre reflectancia y sÃ³lidos suspendidos no es lineal en escala natural y que serÃ¡ necesario explorar modelos mÃ¡s complejos o transformaciones de datos para mejorar la predicciÃ³n.

:::



### AnÃ¡lisis de regresiÃ³n lineal con transformaciÃ³n logarÃ­tmica

En esta etapa aplico una transformaciÃ³n logarÃ­tmica natural a las variables de reflectancia y sÃ³lidos suspendidos antes de ajustar los modelos de regresiÃ³n lineal. Esta transformaciÃ³n permite estabilizar la varianza, linealizar relaciones no lineales y reducir el impacto de valores extremos. 

El procedimiento es similar al anÃ¡lisis anterior, pero antes de entrenar el modelo se aplica `log(x)` a las columnas correspondientes. Para evitar problemas con valores cero, estos se reemplazan por `NaN` y se excluyen del anÃ¡lisis. Posteriormente, entreno modelos de regresiÃ³n lineal simple por banda usando las variables transformadas.  

El desempeÃ±o de cada modelo se evalÃºa mediante mÃ©tricas en escala logarÃ­tmica (`RÂ²_log`, `RMSE_log`) y en escala original, facilitando la comparaciÃ³n y la interpretaciÃ³n de resultados.


```{python}
#| code-fold: true
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import math
import seaborn as sns
from IPython.display import display

# 1. â”€â”€ Cargar datos â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
datos = pd.read_csv("datos/datos_sol_sus_acolite.csv")
bandas = [c for c in datos.columns if c.startswith("B")]

# 2. â”€â”€ Filtrar positivos (requisito para log) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
mask_pos   = (datos["sol_sus"] > 0) & (datos[bandas] > 0).all(axis=1)
datos_log  = datos.loc[mask_pos].copy()

# 3. â”€â”€ Transformar a log-natural â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
datos_log["log_sol_sus"] = np.log(datos_log["sol_sus"])
for b in bandas:
    datos_log[f"log_{b}"] = np.log(datos_log[b])

log_bandas = [f"log_{b}" for b in bandas]

# 4. â”€â”€ Train / test split (descartamos test) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
X_total = datos_log[log_bandas]
y_total = datos_log["log_sol_sus"]
X_train, _, y_train, _ = train_test_split(
    X_total, y_total, test_size=0.2, shuffle=False)

# 5. â”€â”€ Funciones de mÃ©tricas â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def metrics_log(model, X, y):
    y_pred = model.predict(X)
    rmse   = np.sqrt(mean_squared_error(y, y_pred))
    r2     = r2_score(y, y_pred)
    n, p   = X.shape
    r2_adj = 1 - ((1 - r2) * (n - 1)) / (n - p - 1)
    return rmse, r2, r2_adj

def metrics_original(model, X, y):
    y_pred_log  = model.predict(X).ravel()
    y_pred_orig = np.exp(y_pred_log)
    y_true_orig = np.exp(y.values)
    rmse   = np.sqrt(mean_squared_error(y_true_orig, y_pred_orig))
    r2     = r2_score(y_true_orig, y_pred_orig)
    n, p   = X.shape
    r2_adj = 1 - ((1 - r2) * (n - 1)) / (n - p - 1)
    return rmse, r2, r2_adj

# 6. â”€â”€ Entrenar un modelo por banda â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
resultados, resultados_nolog = [], []
lineas_log, lineas_nolog     = {}, {}

for b, lb in zip(bandas, log_bandas):
    Xtr = X_train[[lb]]
    reg = LinearRegression().fit(Xtr, y_train)

    # MÃ©tricas en log
    rmse_l, r2_l, r2a_l = metrics_log(reg, Xtr, y_train)
    resultados.append({"Banda": b, "RÂ²_log": r2_l, 
                    "RÂ²aj_log": r2a_l, "RMSE_log": rmse_l})

    # MÃ©tricas en original
    rmse_o, r2_o, r2a_o = metrics_original(reg, Xtr, y_train)
    resultados_nolog.append({"Banda": b,
                             "RÂ²": r2_o, "RÂ²aj": r2a_o, "RMSE": rmse_o})

    # Rectas ordenadas
    order        = np.argsort(Xtr.values.ravel())
    x_log_ord    = Xtr.values.ravel()[order]
    y_pred_log   = reg.predict(Xtr).ravel()[order]
    lineas_log[b] = (x_log_ord, y_pred_log)

    x_orig_ord   = np.exp(x_log_ord)
    y_pred_orig  = np.exp(y_pred_log)
    lineas_nolog[b] = (x_orig_ord, y_pred_orig)

# 7. â”€â”€ DataFrames de mÃ©tricas â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
res_df_log   = (pd.DataFrame(resultados)
                  .round(3)
                  .sort_values("RMSE_log")
                  .reset_index(drop=True))

res_df_nolog = (pd.DataFrame(resultados_nolog)
                  .round(3)
                  .sort_values("RMSE")
                  .reset_index(drop=True))

# 8. â”€â”€ GrÃ¡ficos en escala original â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
n_cols, n_rows = 3, math.ceil(len(bandas) / 3)
fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 4 * n_rows))
axes = axes.flatten()

for idx, b in enumerate(bandas):
    ax = axes[idx]
    x_orig = np.exp(X_train[f"log_{b}"])
    y_orig = np.exp(y_train)
    ax.scatter(x_orig, y_orig, alpha=0.6, color="#9D50A6", label="Entrenamiento")
    ax.plot(*lineas_nolog[b], lw=3, color="#17A77E", label="Modelo")
    ax.set(xlabel=b, ylabel="sol_sus", title=f"Banda {b} (escala original)")
    ax.legend()
    ax.grid(True)

for j in range(len(bandas), len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()

# 9. â”€â”€ FunciÃ³n para estilo de tablas â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def style_metrics_sin_gradiente(df: pd.DataFrame, caption: str):
    sty = (df.style
             .format(precision=3)
             # .background_gradient(...) â† quitamos el gradiente
             .hide(axis="index")
             .set_caption(caption)
             .set_table_styles([{
                 "selector": "caption",
                 "props": [("caption-side", "top"),
                           ("font-weight",  "bold"),
                           ("margin-bottom","0.5em")]
             }], overwrite=False)
          )
    return sty


# 10 â”€â”€ Mostrar tablas con el nuevo estilo pastel â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
display(style_metrics_sin_gradiente(res_df_log,
        "MÃ©tricas en escala logâ€‘log (ordenadas por RMSE_log)"))

display(style_metrics_sin_gradiente(res_df_nolog,
        "MÃ©tricas en escala original (ordenadas por RMSE)"))

```

::: {.dropdown}
<details> 
<summary>ğŸ“„ Nota tÃ©cnica</summary>

>La transformaciÃ³n `log(x)` se usa frecuentemente cuando la relaciÃ³n entre variables es multiplicativa o cuando hay asimetrÃ­a en la distribuciÃ³n.

>Es fundamental reemplazar ceros por NaN antes de aplicar el logaritmo, ya que `log(0)` no estÃ¡ definido.

>Las mÃ©tricas obtenidas (`RÂ²` y `RMSE`) se interpretan en la **escala logarÃ­tmica y no son directamente** comparables con las obtenidas en la escala original.

>El `RÂ² ajustado` penaliza la complejidad del modelo y ayuda a evaluar si el ajuste mejora mÃ¡s allÃ¡ de lo que se esperarÃ­a por azar.

</details> 

:::


::: {.callout-note title="ConclusiÃ³n del ajuste logâ€“log por banda"}

Los resultados muestran que al aplicar la transformaciÃ³n logarÃ­tmica, las bandas **B06**, **B07** y **B05** obtienen los mejores ajustes, con valores de `RÂ²_log` cercanos a 0.30 y errores (`RMSE_log`) mÃ¡s bajos comparados con las demÃ¡s bandas. Esto indica una mejora en la capacidad predictiva respecto al anÃ¡lisis en escala natural.

Sin embargo, al evaluar las mÃ©tricas en escala original, el mejor desempeÃ±o alcanza un `RÂ²` mÃ¡ximo cercano a 0.20, lo que aÃºn refleja una capacidad limitada para explicar la variabilidad de los sÃ³lidos suspendidos utilizando bandas individuales.

Estos resultados sugieren que la transformaciÃ³n logarÃ­tmica mejora el modelo, pero que para obtener predicciones mÃ¡s precisas serÃ¡ necesario explorar combinaciones de bandas, Ã­ndices espectrales o modelos mÃ¡s complejos.

:::



### SelecciÃ³n de bandas mediante regresiÃ³n logarÃ­tmica y AIC

Para determinar cuÃ¡les bandas espectrales aportan mÃ¡s informaciÃ³n para predecir sÃ³lidos suspendidos, ajustÃ© modelos de regresiÃ³n lineal simple en escala logarÃ­tmica para cada banda individual. AdemÃ¡s de las mÃ©tricas habituales como el coeficiente de determinaciÃ³n (`RÂ²`) y el error cuadrÃ¡tico medio (`RMSE`), utilicÃ© el **Criterio de InformaciÃ³n de Akaike (AIC)**. 

El AIC es una medida que evalÃºa la calidad del modelo penalizando la complejidad: un valor menor indica un mejor equilibrio entre ajuste y simplicidad. Esto ayuda a evitar sobreajuste al no favorecer modelos que mejoran el ajuste sÃ³lo por aumentar el nÃºmero de parÃ¡metros sin aportar realmente informaciÃ³n Ãºtil. AsÃ­, el AIC es una herramienta clave para seleccionar las bandas que efectivamente mejoran la predicciÃ³n sin agregar complejidad innecesaria.

```{python}
#|code-fold: true
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import seaborn as sns
from IPython.display import display

# 1. Cargar datos y detectar bandas
datos = pd.read_csv("datos/datos_sol_sus_acolite.csv")
bandas = [c for c in datos.columns if c.startswith("B")]

# 2. Filtrar casos con valores positivos (requisito de log)
mask_pos = (datos["sol_sus"] > 0) & (datos[bandas] > 0).all(axis=1)
datos_log = datos.loc[mask_pos].copy()

# 3. Transformar a log-natural
datos_log["log_sol_sus"] = np.log(datos_log["sol_sus"])
for b in bandas:
    datos_log[f"log_{b}"] = np.log(datos_log[b])

log_bandas = [f"log_{b}" for b in bandas]

# 4. ParticiÃ³n entrenamiento / test 
X_total = datos_log[log_bandas]
y_total = datos_log["log_sol_sus"]

X_train, _, y_train, _ = train_test_split(
    X_total, y_total, test_size=0.20, shuffle=False
)

# 5. Funciones auxiliares (AIC + mÃ©tricas)
def aic_gauss(model, X, y):
    """
    AIC para regresiÃ³n lineal con ruido ~ N(0, ÏƒÂ²)
    AIC = n Â· ln(RSS/n) + 2k
    """
    n = len(y)
    k = X.shape[1] + 1  # predictores + intercepto
    rss = np.sum((y - model.predict(X)) ** 2)
    return n * np.log(rss / n) + 2 * k

def metrics_log(model, X, y):
    y_pred = model.predict(X)
    rmse = np.sqrt(mean_squared_error(y, y_pred))
    r2   = r2_score(y, y_pred)
    n, p = X.shape
    r2_adj = 1 - ((1 - r2) * (n - 1)) / (n - p - 1)
    return rmse, r2, r2_adj

# 6. Ajuste univariable banda-a-banda + AIC
resultados = []

for b in bandas:
    lb = f"log_{b}"
    Xtr = X_train[[lb]]
    reg = LinearRegression().fit(Xtr, y_train)

    rmse_log, r2_log, r2a_log = metrics_log(reg, Xtr, y_train)
    aic_val = aic_gauss(reg, Xtr, y_train)

    resultados.append({
        "Banda"    : b,
        "RÂ²_log"   : r2_log,
        "RÂ²aj_log" : r2a_log,
        "RMSE_log" : rmse_log,
        "AIC"      : aic_val
    })

# 7. Tabla ordenada por AIC
df_log  = (pd.DataFrame(resultados)
             .round(3)
             .sort_values("AIC")
             .reset_index(drop=True))

def style_metrics_sin_gradiente(df: pd.DataFrame, caption: str):
    sty = (df.style
             .format(precision=3)
             .hide(axis="index")  # oculta Ã­ndice
             .set_caption(caption)
             .set_table_styles([{
                 "selector": "caption",
                 "props": [("caption-side", "top"),
                           ("font-weight",  "bold"),
                           ("margin-bottom", "0.5em")]
             }], overwrite=False)
          )
    return sty

# 9 â”€â”€ Mostrar tabla con el nuevo estilo pastel AIC â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
display(style_metrics_sin_gradiente(
    df_log, "AIC y mÃ©tricas en escala logâ€‘log (ordenadas por AIC)"
))

```


::: {.callout-note title="ConclusiÃ³n sobre la selecciÃ³n de bandas con AIC"}

Los valores obtenidos muestran que las bandas **B06** y **B07** son las mÃ¡s relevantes para predecir los sÃ³lidos suspendidos, ya que presentan los valores mÃ¡s bajos de AIC (-69.24 y -69.19 respectivamente), indicando el mejor equilibrio entre calidad de ajuste y simplicidad del modelo.  
Estas bandas tambiÃ©n exhiben los mejores coeficientes de determinaciÃ³n (`RÂ²_log` alrededor de 0.30) y los menores errores (`RMSE_log` cerca de 0.32).  

El resto de las bandas tienen valores de AIC menos favorables, lo que sugiere que, individualmente, aportan menos informaciÃ³n Ãºtil y no justifican la complejidad del modelo. Esto refuerza la idea de que para mejorar las predicciones serÃ¡ necesario combinar varias bandas o explorar modelos mÃ¡s complejos.

:::



#### SelecciÃ³n de banda espectral con validaciÃ³n cruzada 

En esta secciÃ³n selecciono la banda espectral mÃ¡s adecuada para estimar los **sÃ³lidos suspendidos (sol_sus)** usando un modelo de regresiÃ³n lineal simple en escala logarÃ­tmica. A diferencia de anÃ¡lisis anteriores, ahora incorporo una validaciÃ³n cruzada que respeta la estructura temporal de los datos, para asegurar que el modelo sea confiable al aplicarse a nuevas campaÃ±as de muestreo.

**Â¿Por quÃ© validaciÃ³n Leave-One-Group-Out (LOGO)?**

Los datos provienen de campaÃ±as realizadas en diferentes fechas (`fecha`). Esto genera grupos independientes, ya que las condiciones del rÃ­o pueden variar entre campaÃ±as. Usar una validaciÃ³n cruzada tradicional como K-Fold o Shuffle Split mezclarÃ­a muestras de una misma campaÃ±a entre entrenamiento y prueba, lo que darÃ­a una estimaciÃ³n demasiado optimista del desempeÃ±o.

En cambio, `LeaveOneGroupOut` (LOGO) deja **una fecha completa afuera en cada iteraciÃ³n**, lo que permite evaluar si el modelo puede **generalizar a campaÃ±as no vistas**. Esta estrategia evita **filtraciones de informaciÃ³n** (_data leakage_) entre los datos de entrenamiento y validaciÃ³n, y resulta mucho mÃ¡s realista en contextos ambientales, donde el objetivo es predecir nuevas campaÃ±as a partir de mediciones anteriores.

**DescripciÃ³n del procedimiento:**

- **Preprocesamiento**: aplico `log()` a las bandas y a la variable objetivo (`sol_sus`) y elimino ceros, para linearizar y estabilizar la relaciÃ³n.

- **Modelado**: ajusto un modelo de regresiÃ³n lineal simple por cada banda, normalizando los datos con `StandardScaler` (pipeline). Para cada modelo calculo las mÃ©tricas de validaciÃ³n cruzada: `RMSE`, `RÂ²`, `RÂ² ajustado` y el `AIC`, que penaliza la complejidad del modelo.

- **SelecciÃ³n**: ordeno las bandas por AIC y RMSE, y elijo la mejor.

- **EvaluaciÃ³n final**: 

  - Estimo el desempeÃ±o real sobre la campaÃ±a mÃ¡s reciente (test).

  - Realizo un anÃ¡lisis **bootstrap** (500 rÃ©plicas) para obtener intervalos de confianza de los parÃ¡metros y mÃ©tricas.

  - Muestro grÃ¡ficos de predicho vs observado en escala log y original.

Este enfoque no solo me permite elegir la **banda mÃ¡s informativa**, sino que tambiÃ©n evalÃºa la **estabilidad** del modelo y su capacidad de **generalizar en el tiempo**, algo clave para el monitoreo operativo de calidad de agua.

```{python}
#|code-fold: true
# -------------------------------------------------------------
# 0 Â· LIBRERÃAS
import numpy as np
import pandas as pd
from pathlib import Path
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.model_selection import LeaveOneGroupOut
from sklearn.metrics import mean_squared_error, r2_score
from IPython.display import display, Markdown

# ----------  ESTÃ‰TICA TABLAS (sin gradiente) ------------------
def style_table(df, caption):
    return (df.style
              .format(precision=3)
              .hide(axis="index")
              .set_caption(caption)
              .set_table_styles([
                 {"selector": "caption",
                  "props": [("caption-side", "top"),
                            ("font-weight",  "bold"),
                            ("margin-bottom","0.5em"),
                            ("text-align","left")]},
                 {"selector": "th",
                  "props": [("text-align","center")]},
                 {"selector": "td",
                  "props": [("text-align","right"),
                            ("padding","0.25em 0.5em")]}
              ], overwrite=False))

# -------------------------------------------------------------
# 1 Â· CARGA Y PREPARACIÃ“N
csv_file = Path("datos/datos_sol_sus_acolite.csv")
df = pd.read_csv(csv_file).drop_duplicates()
df["fecha"] = pd.to_datetime(df["fecha"])

bandas = [c for c in df.columns if c.startswith("B")]
mask   = (df["sol_sus"]>0) & (df[bandas]>0).all(axis=1)
df     = df.loc[mask].copy()

df["log_sol_sus"] = np.log(df["sol_sus"])
for b in bandas: df[f"log_{b}"] = np.log(df[b])

log_cols = [f"log_{b}" for b in bandas]
X_total  = df[log_cols];     y_total = df["log_sol_sus"]

last_date   = df["fecha"].max()
mask_test   = df["fecha"]==last_date
mask_train  = ~mask_test
X_train,y_train = X_total[mask_train],y_total[mask_train]
X_test ,y_test  = X_total[mask_test ],y_total[mask_test ]
grupos_train    = df.loc[mask_train,"fecha"]

# -------------------------------------------------------------
# 2 Â· AUXILIARES
adj_r2 = lambda r2,n,p: np.nan if n-p-1<=0 else 1-(1-r2)*(n-1)/(n-p-1)
rmse   = lambda a,b: np.sqrt(mean_squared_error(a,b))
def aic_gauss(m,X,y):
    n,k=len(y),X.shape[1]+1
    rss=np.sum((y-m.predict(X))**2)
    return n*np.log(rss/n)+2*k

# -------------------------------------------------------------
# 3 Â· SELECCIÃ“N DE BANDA (AIC + LOGO)
cv = LeaveOneGroupOut()
res = []
for b in bandas:
    lb, Xb_tr = f"log_{b}", X_train[[f"log_{b}"]]
    pipe = Pipeline([("s",StandardScaler()),("m",LinearRegression())]).fit(Xb_tr,y_train)
    aic  = aic_gauss(pipe.named_steps["m"],pipe.named_steps["s"].transform(Xb_tr),y_train)
    rm,r2,ra = [],[],[]
    for tr,te in cv.split(Xb_tr,y_train,grupos_train):
        mdl = Pipeline([("s",StandardScaler()),("m",LinearRegression())]).fit(Xb_tr.iloc[tr],y_train.iloc[tr])
        pred = mdl.predict(Xb_tr.iloc[te])
        rm.append(rmse(y_train.iloc[te],pred))
        r2_ = r2_score(y_train.iloc[te],pred)
        r2.append(r2_); ra.append(adj_r2(r2_,len(te),1))
    res.append({"Banda":b,"AIC":aic,
                "RMSE_CV":np.mean(rm),"R2_CV":np.mean(r2),"AdjR2_CV":np.mean(ra)})

tbl = (pd.DataFrame(res).sort_values(["AIC","RMSE_CV"]).round(4).reset_index(drop=True))
display(style_table(tbl,"Ranking por AIC (TRAIN, log)"))

best_band = tbl.loc[0,"Banda"]
display(Markdown(f"**Mejor banda:** `{best_band}`"))

# -------------------------------------------------------------
# 4 Â· MODELO FINAL
lb_best   = f"log_{best_band}"
pipe_final= Pipeline([("s",StandardScaler()),("m",LinearRegression())]).fit(X_train[[lb_best]],y_train)
a,b_coef  = pipe_final.named_steps["m"].intercept_,pipe_final.named_steps["m"].coef_[0]
display(Markdown("**EcuaciÃ³n log:**"));  display(Markdown(f"`log(sol_sus) = {a:.4f} + {b_coef:.4f}Â·log({best_band})`"))
display(Markdown("**Escala real:**"));   display(Markdown(f"`sol_sus = {np.exp(a):.4f} Â· {best_band}^{b_coef:.4f}`"))

# -------------------------------------------------------------
# 5 Â· MÃ‰TRICAS TEST (tabla horizontal)
yhat_log  = pipe_final.predict(X_test[[lb_best]])
yhat_lin  = np.exp(yhat_log)
metrics_df = pd.DataFrame({
    "MÃ©trica":["RMSE","RÂ²","RÂ² ajustado"],
    "Log":[rmse(y_test,yhat_log), r2_score(y_test,yhat_log), adj_r2(r2_score(y_test,yhat_log),len(y_test),1)],
    "Real (mg/L)":[rmse(np.exp(y_test),yhat_lin), r2_score(np.exp(y_test),yhat_lin),
                   adj_r2(r2_score(np.exp(y_test),yhat_lin),len(y_test),1)]
})
metrics_df["Log"] = metrics_df["Log"].apply(lambda x:f"{x:.3f}")
metrics_df["Real (mg/L)"]=metrics_df["Real (mg/L)"].apply(lambda x:f"{x:.3f}" if abs(x)<10 else f"{x:.2f}")
display(style_table(metrics_df,"DesempeÃ±o en TEST"))

# -------------------------------------------------------------
# 6 Â· BOOTSTRAP (tabla horizontal)
np.random.seed(123); n_boot=500; fechas=grupos_train.unique()
ib,cb,rm_l,r2_l,ra_l,rm_r,r2_r,ra_r=[],[],[],[],[],[],[],[]
for _ in range(n_boot):
    idx = grupos_train.isin(np.random.choice(fechas,len(fechas),replace=True))
    Xb,yb = X_train[[lb_best]].loc[idx],y_train.loc[idx]
    mdl = Pipeline([("s",StandardScaler()),("m",LinearRegression())]).fit(Xb,yb)
    ib.append(mdl.named_steps["m"].intercept_)
    cb.append(mdl.named_steps["m"].coef_[0])
    pr_log = mdl.predict(X_train[[lb_best]])
    rm_l.append(rmse(y_train,pr_log)); r2_l_ = r2_score(y_train,pr_log); r2_l.append(r2_l_)
    ra_l.append(adj_r2(r2_l_,len(y_train),1))
    pr_lin = np.exp(pr_log)
    rm_r.append(rmse(np.exp(y_train),pr_lin)); r2_r_ = r2_score(np.exp(y_train),pr_lin); r2_r.append(r2_r_)
    ra_r.append(adj_r2(r2_r_,len(y_train),1))

pct = lambda arr: np.percentile(arr,[2.5,97.5])
ci = { "inter":pct(ib), "coef":pct(cb),
       "rm_l":pct(rm_l),"r2_l":pct(r2_l),"ra_l":pct(ra_l),
       "rm_r":pct(rm_r),"r2_r":pct(r2_r),"ra_r":pct(ra_r)}

bs_df = pd.DataFrame({
    "ParÃ¡metro / MÃ©trica":[
        "Intercepto",f"Coef {best_band}",
        "RMSE (log)","RÂ² (log)","RÂ² ajustado (log)",
        "RMSE (mg/L)","RÂ² (mg/L)","RÂ² ajustado (mg/L)"
    ],
    "Promedio":[np.mean(ib),np.mean(cb),
                np.mean(rm_l),np.mean(r2_l),np.mean(ra_l),
                np.mean(rm_r),np.mean(r2_r),np.mean(ra_r)],
    "IC 95% inf.":[ci["inter"][0],ci["coef"][0],
                   ci["rm_l"][0],ci["r2_l"][0],ci["ra_l"][0],
                   ci["rm_r"][0],ci["r2_r"][0],ci["ra_r"][0]],
    "IC 95% sup.":[ci["inter"][1],ci["coef"][1],
                   ci["rm_l"][1],ci["r2_l"][1],ci["ra_l"][1],
                   ci["rm_r"][1],ci["r2_r"][1],ci["ra_r"][1]]
})
for col in bs_df.columns[1:]:
    bs_df[col] = bs_df[col].apply(lambda x:f"{x:.4f}" if abs(float(x))<10 else f"{x:.2f}")
display(style_table(bs_df,"Bootstrap (500 rÃ©plicas) Â· IC 95%"))

# -------------------------------------------------------------
# 7 Â· GRÃFICO Predicho vs Observado  (Train + Test)
#     Izquierda â†’ escala log   Â·   Derecha â†’ escala original
plt.rcParams.update({"axes.titlesize":10, "axes.labelsize":8,
                     "xtick.labelsize":7, "ytick.labelsize":7})

TRAIN_CLR = "#9D50A6"   # violeta
TEST_CLR  = "#FFA24B"   # naranja
ID_CLR    = "#17A77E"   # lÃ­nea identidad

# --- predicciones ---
y_train_log_pred = pipe_final.predict(X_train[[lb_best]])
y_test_log_pred  = pipe_final.predict(X_test [[lb_best]])
y_train_orig, y_train_pred = np.exp(y_train), np.exp(y_train_log_pred)
y_test_orig , y_test_pred  = np.exp(y_test ), np.exp(y_test_log_pred)

fig, ax = plt.subplots(1, 2, figsize=(9, 4), sharex=False, sharey=False)

# â€„Escala log
ax[0].scatter(y_train, y_train_log_pred, alpha=0.6,
              color=TRAIN_CLR, edgecolor="k", label="Train (â—)")
ax[0].scatter(y_test , y_test_log_pred , alpha=0.6,
              color=TEST_CLR , marker="s", edgecolor="k", label="Test  (â– )")

lims = [min(y_train.min(), y_test.min()),
        max(y_train.max(), y_test.max())]
ax[0].plot(lims, lims, "--", color=ID_CLR, lw=2.5, label="y = x")
ax[0].set_xlabel("log(sol_sus) observado")
ax[0].set_ylabel("log(sol_sus) predicho")
ax[0].set_title("Escala log")
ax[0].legend(fontsize=7, frameon=False)
ax[0].grid(ls=":")

eq_log_txt = f"log(sol_sus) = {a:.3f} + {b_coef:.3f}Â·log({best_band})"
ax[0].text(0.04, 0.96, eq_log_txt, transform=ax[0].transAxes,
           fontsize=7, va="top",
           bbox=dict(boxstyle="round,pad=0.25", fc="white", ec="gray", lw=0.4))

# â€„Escala original
ax[1].scatter(y_train_orig, y_train_pred, alpha=0.6,
              color=TRAIN_CLR, edgecolor="k", label="Train (â—)")
ax[1].scatter(y_test_orig , y_test_pred , alpha=0.6,
              color=TEST_CLR , marker="s", edgecolor="k", label="Test  (â– )")

lims_o = [min(y_train_orig.min(), y_test_orig.min(),
              y_train_pred.min(), y_test_pred.min()),
          max(y_train_orig.max(), y_test_orig.max(),
              y_train_pred.max(), y_test_pred.max())]
ax[1].plot(lims_o, lims_o, "--", color=ID_CLR, lw=2.5, label="y = x")
ax[1].set_xlabel("sol_sus observado (mg/L)")
ax[1].set_ylabel("sol_sus predicho (mg/L)")
ax[1].set_title("Escala original")
ax[1].legend(fontsize=7, frameon=False)
ax[1].grid(ls=":")

eq_orig_txt = f"sol_sus = {np.exp(a):.4f} Ã— {best_band}^{b_coef:.4f}"
ax[1].text(0.04, 0.96, eq_orig_txt, transform=ax[1].transAxes,
           fontsize=7, va="top",
           bbox=dict(boxstyle="round,pad=0.25", fc="white", ec="gray", lw=0.4))

fig.suptitle(f"Predicho vs Observado Â· Banda {best_band}", fontsize=11, y=1.05)
fig.tight_layout(pad=1.2)
plt.show()

# (opcional) restaurar tamaÃ±os por si sigues graficando despuÃ©s
plt.rcParams.update({"axes.titlesize":11, "axes.labelsize":9,
                     "xtick.labelsize":8, "ytick.labelsize":8})

```

::: {.callout-note title="ConclusiÃ³n del modelo con validaciÃ³n cruzada"}

Selecciono la banda **B07** como la mejor candidata para estimar los sÃ³lidos suspendidos. Esta elecciÃ³n se basa en el valor mÃ¡s bajo del AIC y el menor error promedio en validaciÃ³n cruzada (`RMSE_CV`). El modelo resultante indica que, a mayor reflectancia en la banda B07, tiende a haber mayor concentraciÃ³n estimada de sÃ³lidos suspendidos.

Sin embargo, al evaluar el modelo con los datos mÃ¡s recientes (campaÃ±a de prueba), el desempeÃ±o cae considerablemente. El `RÂ²` es negativo, lo que significa que el modelo predice peor que una estimaciÃ³n promedio constante. En otras palabras, **el modelo no generaliza bien a nuevos datos**.

Para tener una idea mÃ¡s completa de su estabilidad, aplico la tÃ©cnica de **bootstrap** con 500 repeticiones. Esto muestra que si bien el coeficiente de la banda B07 es consistentemente positivo (lo que confirma una relaciÃ³n), el rendimiento general del modelo es bajo y muy variable.

Concluyo que, aunque B07 es la mejor banda individual, **no alcanza para predecir sÃ³lidos suspendidos con precisiÃ³n**. Para mejorar el modelo, es necesario combinar varias bandas, usar Ã­ndices espectrales o aplicar modelos mÃ¡s complejos.

:::



### SelecciÃ³n de bandas con Forward Selection basado en AIC

En esta secciÃ³n realizo la selecciÃ³n de un conjunto de bandas espectrales para predecir la concentraciÃ³n de **sÃ³lidos suspendidos (sol_sus)** mediante un modelo de regresiÃ³n lineal mÃºltiple en escala logarÃ­tmica. Utilizo el mÃ©todo de **Forward Selection** guiado por el **criterio de informaciÃ³n de Akaike (AIC)**, que permite incorporar progresivamente aquellas bandas cuya inclusiÃ³n mejora significativamente el ajuste del modelo sin incrementar de forma innecesaria su complejidad.


En esta secciÃ³n selecciono un conjunto de bandas espectrales para predecir los **sÃ³lidos suspendidos (sol_sus)** mediante regresiÃ³n lineal mÃºltiple en escala logarÃ­tmica. Utilizo el mÃ©todo de **Forward Selection**, que comienza con un modelo vacÃ­o e incorpora progresivamente las bandas que mÃ¡s reducen el **AIC**, siempre que la mejora sea significativa (Î”AIC â‰¥ 1).

Transformo todas las variables a escala logarÃ­tmica para linealizar relaciones y reducir la variabilidad. Reservo la Ãºltima fecha como conjunto de prueba, y entreno el modelo con el resto de los datos. Durante la selecciÃ³n, evalÃºo el desempeÃ±o con validaciÃ³n cruzada agrupada (`GroupKFold`), que respeta las campaÃ±as de muestreo y permite estimar la capacidad del modelo para generalizar a nuevas fechas.

Finalmente, ajusto el modelo con las bandas seleccionadas, calculo mÃ©tricas en train y test, y realizo un anÃ¡lisis bootstrap para obtener intervalos de confianza de los coeficientes. Esto me permite construir un modelo interpretable, robusto y ajustado a las condiciones reales del monitoreo ambiental.

```{python}
#|code-fold: true
import numpy as np
import pandas as pd
from pathlib import Path
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import GroupKFold
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
from IPython.display import display, Markdown

# -------------------------------------------------------------
# 1 Â· CONFIGURACIÃ“N
DATOS      = Path("datos/datos_sol_sus_acolite.csv")   
N_BOOT     = 2000
DELTA_AIC  = 1.0
RNG_SEED   = 42

# -------------------------------------------------------------
# 2 Â· ESTILO TABLAS (robusto a versiones pandas)
def style_table(df, caption):
    sty = df.style.format(precision=3)
    if hasattr(sty, "hide"):
        sty = sty.hide(axis="index")
    elif hasattr(sty, "hide_index"):
        sty = sty.hide_index()
    # caption + estilos de alineaciÃ³n
    sty = (sty.set_caption(caption)
              .set_table_styles([
                  {"selector":"caption","props":[("caption-side","top"),
                                                ("font-weight","bold"),
                                                ("margin-bottom","0.5em"),
                                                ("text-align","left")]},
                  {"selector":"th","props":[("text-align","center")]},
                  {"selector":"td","props":[("text-align","right"),
                                            ("padding","0.25em 0.5em")]}
              ], overwrite=False))
    return sty

# -------------------------------------------------------------
# 3 Â· FUNCIONES AUXILIARES
rmse = lambda a,b: np.sqrt(mean_squared_error(a,b))
aic_g = lambda rss,n,k: n*np.log(rss/n)+2*k
def fit_metrics(Xm, ym):
    m = LinearRegression().fit(Xm, ym)
    pred = m.predict(Xm)
    n,p = Xm.shape
    rss = np.sum((ym - pred)**2)
    return {"AIC":aic_g(rss,n,p+1),
            "RMSE":rmse(ym,pred),
            "RÂ²":r2_score(ym,pred),
            "RÂ²aj":1-(1-r2_score(ym,pred))*(n-1)/(n-p-1),
            "mod":m}

# -------------------------------------------------------------
# 4 Â· CARGA Y PREPARACIÃ“N
df = (pd.read_csv(DATOS)
        .sort_values("fecha")
        .reset_index(drop=True))
df["fecha"] = pd.to_datetime(df["fecha"])

bandas = [c for c in df.columns if c.startswith("B")]
mask   = (df["sol_sus"]>0) & (df[bandas]>0).all(axis=1)
df     = df.loc[mask].copy()

df["log_sol_sus"] = np.log(df["sol_sus"])
for b in bandas: df[f"log_{b}"] = np.log(df[b])

X = df[[f"log_{b}" for b in bandas]]; y = df["log_sol_sus"]

last_date = df["fecha"].max()
m_test    = df["fecha"]==last_date
m_train   = ~m_test

X_tr,y_tr = X[m_train],y[m_train]
X_te,y_te = X[m_test ],y[m_test ]
groups_tr = df.loc[m_train,"fecha"]

print(f"TRAIN campaÃ±as : {groups_tr.nunique()}")
print(f"TEST  campaÃ±a  : {last_date.date()} ({m_test.sum()} muestras)")

# -------------------------------------------------------------
# 5 Â· FORWARD SELECTION con tabla de candidatos
remaining, selected = list(X_tr.columns), []
rss_null  = np.sum((y_tr - y_tr.mean())**2)
best_aic  = aic_g(rss_null,len(y_tr),1)
hist=[]; paso=0

while remaining:
    cand=[]
    for b in remaining:
        mets = fit_metrics(X_tr[selected+[b]].values, y_tr.values)
        cand.append((mets["AIC"], b, mets))
    cand.sort()

    df_cand = pd.DataFrame({
        "Banda":[b.replace("log_","") for _,b,_ in cand],
        "AIC":[a for a,_,_ in cand]
    })
    df_cand["Î”AIC"] = best_aic - df_cand["AIC"]
    display(Markdown(f"**Paso {paso+1} - candidatos:**"))
    display(style_table(df_cand,""))

    new_aic,best_band,best_met = cand[0]
    if best_aic - new_aic >= DELTA_AIC:
        selected.append(best_band); remaining.remove(best_band)
        best_aic=new_aic; paso+=1
        hist.append({"Paso":paso,
                     "Bandas":", ".join(c.replace("log_","") for c in selected),
                     "AIC":best_aic,
                     "RMSE":best_met["RMSE"],
                     "RÂ²":best_met["RÂ²"],
                     "RÂ²aj":best_met["RÂ²aj"]})
    else:
        break

if not selected:
    selected=[cand[0][1]]; best_aic=cand[0][0]; best_met=cand[0][2]
    hist=[{"Paso":1,"Bandas":selected[0].replace("log_",""),
           "AIC":best_aic,"RMSE":best_met["RMSE"],
           "RÂ²":best_met["RÂ²"],"RÂ²aj":best_met["RÂ²aj"]}]

hist_df=pd.DataFrame(hist)[["Paso","Bandas","AIC","RMSE","RÂ²","RÂ²aj"]]
display(style_table(hist_df,"Historial forwardâ€‘AIC"))

sel_log=selected; sel=[c.replace("log_","") for c in sel_log]
display(Markdown(f"**Bandas finales:** {', '.join(sel)}"))

# -------------------------------------------------------------
# 6 Â· GroupKFold CV
gkf=GroupKFold(n_splits=min(5,groups_tr.nunique()))
rmse_cv=[rmse(y_tr.iloc[te],
              LinearRegression().fit(X_tr.iloc[tr][sel_log],y_tr.iloc[tr])
              .predict(X_tr.iloc[te][sel_log]))
         for tr,te in gkf.split(X_tr[sel_log],y_tr,groups_tr)]
display(Markdown(f"**GroupKFold CV (log) RMSE:** {np.mean(rmse_cv):.3f} Â± {np.std(rmse_cv):.3f}"))

# -------------------------------------------------------------
# 7 Â· MODELO FINAL + MÃ‰TRICAS
mod = LinearRegression().fit(X_tr[sel_log], y_tr)
pred_tr_log = mod.predict(X_tr[sel_log])
pred_te_log = mod.predict(X_te[sel_log])

y_tr_lin, y_te_lin = np.exp(y_tr), np.exp(y_te)
pred_tr_lin, pred_te_lin = np.exp(pred_tr_log), np.exp(pred_te_log)

metrics_df = pd.DataFrame({
    "MÃ©trica": ["RMSE", "RÂ²"],
    "Train log": [rmse(y_tr, pred_tr_log), r2_score(y_tr, pred_tr_log)],
    "Test log": [rmse(y_te, pred_te_log), r2_score(y_te, pred_te_log)],
    "Train orig": [rmse(y_tr_lin, pred_tr_lin), r2_score(y_tr_lin, pred_tr_lin)],
    "Test orig": [rmse(y_te_lin, pred_te_lin), r2_score(y_te_lin, pred_te_lin)]
})
for col in metrics_df.columns[1:]:
    metrics_df[col] = metrics_df[col].apply(lambda x: f"{x:.3f}")

display(style_table(metrics_df, "DesempeÃ±o en Train y Test"))

# -------------------------------------------------------------
# 8 Â· BOOTSTRAP coeficientes
rng = np.random.default_rng(RNG_SEED)
dates = groups_tr.unique()
coef_bs = []

for _ in range(N_BOOT):
    idx = groups_tr.isin(rng.choice(dates, len(dates), replace=True))
    coef_bs.append(LinearRegression().fit(X_tr.loc[idx, sel_log], y_tr.loc[idx]).coef_)

coef_bs = np.array(coef_bs)
mean = coef_bs.mean(axis=0)
lo, hi = np.percentile(coef_bs, [2.5, 97.5], axis=0)

bs_df = pd.DataFrame({"Banda": sel, "Media Î²": mean, "IC inf": lo, "IC sup": hi})
display(style_table(bs_df, "Bootstrap (coeficientes, 95â€¯%Â CI)"))

# -------------------------------------------------------------
# 9 Â· ECUACIONES Y BANDAS SELECCIONADAS
alpha = np.exp(mod.intercept_)
expr_log = " + ".join(f"{c:.4f}Â·log({b})" for c, b in zip(mod.coef_, sel))
expr_orig = " Â· ".join(f"{b}^{c:.4f}" for c, b in zip(mod.coef_, sel))

display(Markdown("**Bandas seleccionadas:**"))
display(Markdown(f"`{', '.join(sel)}`"))

display(Markdown("**EcuaciÃ³n en escala logarÃ­tmica:**"))
display(Markdown(f"`log(sol_sus) = {mod.intercept_:.4f} + {expr_log}`"))

display(Markdown("**EcuaciÃ³n en escala original:**"))
display(Markdown(f"`sol_sus = {alpha:.4f} Â· {expr_orig}`"))

# -------------------------------------------------------------
# 10 Â· GRÃFICO Predicho vs Observado (Train+Test)
plt.rcParams.update({"axes.titlesize":10,"axes.labelsize":8,
                     "xtick.labelsize":7,"ytick.labelsize":7})

TRAIN_CLR = "#9D50A6"
TEST_CLR = "#FFA24B"
ID_CLR = "#17A77E"

fig, ax = plt.subplots(1, 2, figsize=(9, 4))
# Escala log
ax[0].scatter(y_tr, pred_tr_log, alpha=0.6, color=TRAIN_CLR, edgecolor="k", label="Train (â—)")
ax[0].scatter(y_te, pred_te_log, alpha=0.6, color=TEST_CLR, marker="s", edgecolor="k", label="Test  (â– )")
lims = [min(y_tr.min(), y_te.min()), max(y_tr.max(), y_te.max())]
ax[0].plot(lims, lims, "--", color=ID_CLR, lw=2.5, label="y = x")
ax[0].set(xlabel="log(sol_sus) obs.", ylabel="log(sol_sus) pred.", title="Escala log")
ax[0].legend(fontsize=7, frameon=False)
ax[0].grid(ls=":")

# Escala original
ax[1].scatter(y_tr_lin, pred_tr_lin, alpha=0.6, color=TRAIN_CLR, edgecolor="k", label="Train (â—)")
ax[1].scatter(y_te_lin, pred_te_lin, alpha=0.6, color=TEST_CLR, marker="s", edgecolor="k", label="Test  (â– )")
lims_o = [min(y_tr_lin.min(), y_te_lin.min(), pred_tr_lin.min(), pred_te_lin.min()),
          max(y_tr_lin.max(), y_te_lin.max(), pred_tr_lin.max(), pred_te_lin.max())]
ax[1].plot(lims_o, lims_o, "--", color=ID_CLR, lw=2.5)
ax[1].set(xlabel="sol_sus obs. (mg/L)", ylabel="sol_sus pred. (mg/L)", title="Escala original")
ax[1].legend(fontsize=7, frameon=False)
ax[1].grid(ls=":")

fig.suptitle(f"Predicho vs Observado Â· Î”AIC â‰¥ {DELTA_AIC}", fontsize=11, y=1.05)
fig.tight_layout(pad=1.2)
plt.show()

# restaurar estilos si continuÃ¡s graficando
plt.rcParams.update({"axes.titlesize":11,"axes.labelsize":9,
                     "xtick.labelsize":8,"ytick.labelsize":8})
```


::: {.callout-note title="ConclusiÃ³n del modelo seleccionado"}

Selecciono las bandas **B07** y **B02** como las mejores para estimar los sÃ³lidos suspendidos, basÃ¡ndome en la reducciÃ³n significativa del `AIC` y la mejora en el error promedio de validaciÃ³n cruzada (`RMSE_CV`). El modelo indica que la reflectancia en B07 tiene un efecto positivo en la concentraciÃ³n estimada, mientras que B02 aporta un efecto negativo, lo que puede relacionarse con propiedades Ã³pticas del agua y sedimentos.

Al evaluar el modelo con datos nuevos (campaÃ±a de prueba), el desempeÃ±o es razonablemente bueno, con un `RÂ²` positivo que refleja una capacidad aceptable de generalizaciÃ³n. El anÃ¡lisis bootstrap confirma la estabilidad de los coeficientes y las mÃ©tricas, entregando confianza en la robustez del modelo.

En resumen, combinar estas dos bandas mejora sustancialmente la predicciÃ³n en comparaciÃ³n con usar una sola banda, pero para lograr mayor precisiÃ³n probablemente sea necesario explorar Ã­ndices espectrales o modelos mÃ¡s avanzados.

:::



### SelecciÃ³n de variables mediante Forward Selection con AIC usando razones simples de bandas

En esta etapa exploro combinaciones de variables formadas por razones simples entre bandas espectrales, todas en escala logarÃ­tmica, para mejorar la predicciÃ³n de los sÃ³lidos suspendidos (**sol_sus**). Aplico un mÃ©todo de **Forward Selection** guiado por el criterio de informaciÃ³n de Akaike (AIC), que me permite construir un modelo parsimonioso incorporando solo aquellas razones que aportan mejoras significativas en el ajuste.

El anÃ¡lisis se realiza sobre el conjunto de entrenamiento definido previamente, manteniendo la particiÃ³n temporal para test y respetando la estructura grupal en la validaciÃ³n cruzada. AdemÃ¡s, implemento un anÃ¡lisis bootstrap para estimar la incertidumbre en los coeficientes y evaluar la estabilidad del modelo.

Con este procedimiento busco identificar relaciones espectrales mÃ¡s complejas que mejor expliquen la variabilidad de sÃ³lidos suspendidos, maximizando la capacidad predictiva sin sobreajustar, para un monitoreo ambiental mÃ¡s preciso y confiable.

```{python}
#|code-fold: true
# 0 Â· LIBRERÃAS
import numpy as np
import pandas as pd
from pathlib import Path
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import GroupKFold
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
from IPython.display import display, Markdown

# -------------------------------------------------------------
# 1 Â· CONFIGURACIÃ“N
DATOS     = Path("datos/datos_sol_sus_acolite.csv")     # â† ajustÃ¡ si hace falta
DELTA_AIC = 2                                            # Î”AIC mÃ­nimo
N_BOOT    = 2000
RNG_SEED  = 42

# -------------------------------------------------------------
# 2 Â· FUNCIONES AUXILIARES
def aic_gauss(rss, n, k):           # k = nÂº coef + intercepto
    return n * np.log(rss / n) + 2 * k

def fit_metrics(X, y):
    """Ajusta LR y devuelve mÃ©tricas + modelo."""
    m    = LinearRegression().fit(X, y)
    pred = m.predict(X)
    rss  = np.sum((y - pred) ** 2)
    n, p = X.shape
    return {
        "AIC" : aic_gauss(rss, n, p + 1),
        "RMSE": np.sqrt(mean_squared_error(y, pred)),
        "RÂ²"  : r2_score(y, pred),
        "RÂ²aj": 1 - (1 - r2_score(y, pred)) * (n - 1) / (n - p - 1),
        "mod" : m
    }

def rmse(a, b): return np.sqrt(mean_squared_error(a, b))

# -------------------------------------------------------------
# 3 Â· CARGA Y PREPARACIÃ“N DE DATOS
df = pd.read_csv(DATOS)
df["fecha"] = pd.to_datetime(df["fecha"])

bandas = [c for c in df.columns if c.startswith("B")]
mask   = (df["sol_sus"] > 0) & (df[bandas] > 0).all(axis=1)
df     = df.loc[mask].copy()

# variable respuesta en log
df["log_sol_sus"] = np.log(df["sol_sus"])

# -------------------------------------------------------------
# 3.1 Â· GENERAR RAZONES SIMPLES DE BANDAS EN LOGARITMO
ratio_cols = []
for i, b1 in enumerate(bandas):
    for b2 in bandas[i+1:]:
        col = f"log({b1}/{b2})"
        df[col] = np.log(df[b1]) - np.log(df[b2])
        ratio_cols.append(col)

X = df[ratio_cols]                # predictores = razones simples en log
y = df["log_sol_sus"]

# -------------------------------------------------------------
# 3.2 Â· PARTICIÃ“N TEMPORAL
last_date = df["fecha"].max()
m_test    = df["fecha"] == last_date
m_train   = ~m_test

X_tr, y_tr = X.loc[m_train], y.loc[m_train]
X_te, y_te = X.loc[m_test] , y.loc[m_test]
groups_tr  = df.loc[m_train, "fecha"]

print(f"TRAIN campaÃ±as : {groups_tr.nunique()}")
print(f"TEST  campaÃ±a  : {last_date.date()} ({m_test.sum()} muestras)")

# -------------------------------------------------------------
# 4 Â· FORWARD SELECTION (razones simples logarÃ­tmicas) con AIC + Î”
remaining = ratio_cols.copy()
selected  = []

# modelo nulo
rss_null  = np.sum((y_tr - y_tr.mean())**2)
best_aic  = aic_gauss(rss_null, len(y_tr), k=1)

hist = []
paso = 0
while remaining:
    candidatos = []
    for col in remaining:
        cols = selected + [col]
        m    = fit_metrics(X_tr[cols].values, y_tr.values)
        candidatos.append((m["AIC"], col, m))
    candidatos.sort()

    new_aic, best_col, best_met = candidatos[0]
    if best_aic - new_aic >= DELTA_AIC:     # mejora â‰¥ Î”AIC
        selected.append(best_col)
        remaining.remove(best_col)
        best_aic = new_aic
        paso += 1
        hist.append({
            "Paso"  : paso,
            "Bandas": ", ".join(selected),
            "AIC"   : best_aic,
            "RMSE"  : best_met["RMSE"],
            "RÂ²"    : best_met["RÂ²"],
            "RÂ²aj"  : best_met["RÂ²aj"]
        })
    else:
        break

# fallback (si nada mejora)
if not selected:
    selected = [min(candidatos, key=lambda t: t[0])[1]]
    best_aic = min(candidatos)[0]
    best_met = min(candidatos)[2]
    hist.append({
        "Paso"  : 1,
        "Bandas": selected[0],
        "AIC"   : best_aic,
        "RMSE"  : best_met["RMSE"],
        "RÂ²"    : best_met["RÂ²"],
        "RÂ²aj"  : best_met["RÂ²aj"]
    })

hist_df = (pd.DataFrame(hist)
             .loc[:, ["Paso", "Bandas", "AIC", "RMSE", "RÂ²", "RÂ²aj"]])

# Mostrar tabla historial con caption y sin Ã­ndice
display(
    hist_df.style
    .format({"AIC": "{:.3f}", "RMSE": "{:.3f}", "RÂ²": "{:.3f}", "RÂ²aj": "{:.3f}"})
    .set_caption("Historial de selecciÃ³n")
    .hide(axis="index")
)

# Mostrar bandas seleccionadas en negrita Markdown
display(Markdown(f"**Bandas seleccionadas:**  `{', '.join(selected)}`"))

# -------------------------------------------------------------
# 5 Â· VALIDACIÃ“N GROUPâ€‘KFOLD
gkf = GroupKFold(n_splits=min(5, groups_tr.nunique()))
rmse_cv = []
for tr_idx, te_idx in gkf.split(X_tr[selected], y_tr, groups_tr):
    m    = LinearRegression().fit(X_tr.iloc[tr_idx][selected], y_tr.iloc[tr_idx])
    pred = m.predict(X_tr.iloc[te_idx][selected])
    rmse_cv.append(rmse(y_tr.iloc[te_idx], pred))

# Mostrar GroupKFold CV en negrita Markdown
display(Markdown(f"**GroupKFold CV (log) RMSE:** {np.mean(rmse_cv):.3f} Â± {np.std(rmse_cv):.3f}"))

# -------------------------------------------------------------
# 6 Â· MODELO FINAL Y MÃ‰TRICAS
mod = LinearRegression().fit(X_tr[selected], y_tr)

# TRAIN
pred_tr_log = mod.predict(X_tr[selected])
rmse_tr_log = rmse(y_tr, pred_tr_log)
r2_tr_log   = r2_score(y_tr, pred_tr_log)

# TEST
pred_te_log = mod.predict(X_te[selected])
rmse_te_log = rmse(y_te, pred_te_log)
r2_te_log   = r2_score(y_te, pred_te_log)

# escala original
y_tr_lin, y_te_lin = np.exp(y_tr), np.exp(y_te)
pred_tr_lin, pred_te_lin = np.exp(pred_tr_log), np.exp(pred_te_log)

rmse_tr_lin = rmse(y_tr_lin, pred_tr_lin)
r2_tr_lin   = r2_score(y_tr_lin, pred_tr_lin)
rmse_te_lin = rmse(y_te_lin, pred_te_lin)
r2_te_lin   = r2_score(y_te_lin, pred_te_lin)

metrics_df = pd.DataFrame({
    "MÃ©trica"    : ["RMSE", "RÂ²"],
    "Train log"  : [rmse_tr_log, r2_tr_log],
    "Test log"   : [rmse_te_log, r2_te_log],
    "Train orig" : [rmse_tr_lin, r2_tr_lin],
    "Test orig"  : [rmse_te_lin, r2_te_lin]
})

# Mostrar tabla mÃ©tricas con caption y sin Ã­ndice
display(
    metrics_df.style
    .format({
        "Train log": "{:.3f}", "Test log": "{:.3f}",
        "Train orig": "{:.3f}", "Test orig": "{:.3f}"
    })
    .set_caption("MÃ©tricas finales")
    .hide(axis="index")
)

# -------------------------------------------------------------
# 7 Â· BOOTSTRAP AGRUPADO (coef 95 % CI)
rng    = np.random.default_rng(RNG_SEED)
dates  = groups_tr.unique()
coef_bs = []

for _ in range(N_BOOT):
    samp = rng.choice(dates, len(dates), replace=True)
    idx  = groups_tr.isin(samp)
    m_bs = LinearRegression().fit(X_tr.loc[idx, selected], y_tr.loc[idx])
    coef_bs.append(m_bs.coef_)

coef_bs = np.array(coef_bs)
mean_bs = coef_bs.mean(axis=0)
ci_bs   = np.percentile(coef_bs, [2.5, 97.5], axis=0)

bs_df = pd.DataFrame({
    "Banda"       : selected,
    "Media Î²"     : mean_bs,
    "IC 95% inf." : ci_bs[0],
    "IC 95% sup." : ci_bs[1]
})

# Mostrar tabla bootstrap con caption y sin Ã­ndice
display(
    bs_df.style
    .format({
        "Media Î²": "{:.4f}",
        "IC 95% inf.": "{:.4f}",
        "IC 95% sup.": "{:.4f}"
    })
    .set_caption("Bootstrap (coeficientes, 95 % CI)")
    .hide(axis="index")
)

# -------------------------------------------------------------
# 8 Â· ECUACIONES
alpha      = np.exp(mod.intercept_)
expr_log   = " + ".join([f"{c:.4f}Â·{r}" for c, r in zip(mod.coef_, selected)])
expr_orig  = " Â· ".join([f"{r}^{c:.4f}" for c, r in zip(mod.coef_, selected)])

display(Markdown("EcuaciÃ³n (log)"))
display(Markdown(f"`log(sol_sus) = {mod.intercept_:.4f} + {expr_log}`"))

display(Markdown("EcuaciÃ³n (original)"))
display(Markdown(f"`sol_sus = {alpha:.4f} Â· {expr_orig}`"))

# -------------------------------------------------------------
# 9 Â· GRÃFICAS DE PARIDAD (TRAIN + TEST) - estilo especificado
plt.rcParams.update({"axes.titlesize":10,"axes.labelsize":8,
                     "xtick.labelsize":7,"ytick.labelsize":7})

TRAIN_CLR = "#9D50A6"
TEST_CLR = "#FFA24B"
ID_CLR = "#17A77E"

fig, ax = plt.subplots(1, 2, figsize=(9, 4))
# Escala log
ax[0].scatter(y_tr, pred_tr_log, alpha=0.6, color=TRAIN_CLR, edgecolor="k", label="Train (â—)")
ax[0].scatter(y_te, pred_te_log, alpha=0.6, color=TEST_CLR, marker="s", edgecolor="k", label="Test  (â– )")
lims = [min(y_tr.min(), y_te.min()), max(y_tr.max(), y_te.max())]
ax[0].plot(lims, lims, "--", color=ID_CLR, lw=2.5, label="y = x")
ax[0].set(xlabel="log(sol_sus) obs.", ylabel="log(sol_sus) pred.", title="Escala log")
ax[0].legend(fontsize=7, frameon=False)
ax[0].grid(ls=":")

# Escala original
ax[1].scatter(y_tr_lin, pred_tr_lin, alpha=0.6, color=TRAIN_CLR, edgecolor="k", label="Train (â—)")
ax[1].scatter(y_te_lin, pred_te_lin, alpha=0.6, color=TEST_CLR, marker="s", edgecolor="k", label="Test  (â– )")
lims_o = [min(y_tr_lin.min(), y_te_lin.min(), pred_tr_lin.min(), pred_te_lin.min()),
          max(y_tr_lin.max(), y_te_lin.max(), pred_tr_lin.max(), pred_te_lin.max())]
ax[1].plot(lims_o, lims_o, "--", color=ID_CLR, lw=2.5)
ax[1].set(xlabel="sol_sus obs. (mg/L)", ylabel="sol_sus pred. (mg/L)", title="Escala original")
ax[1].legend(fontsize=7, frameon=False)
ax[1].grid(ls=":")

fig.suptitle(f"Predicho vs Observado Â· Î”AIC â‰¥ {DELTA_AIC}", fontsize=11, y=1.05)
fig.tight_layout(pad=1.2)
plt.show()

# restaurar estilos si continuÃ¡s graficando
plt.rcParams.update({"axes.titlesize":11,"axes.labelsize":9,
                     "xtick.labelsize":8,"ytick.labelsize":8})

```

::: {.callout-note title="ConclusiÃ³n del modelo seleccionado"}

En esta etapa, al usar razones simples de bandas espectrales en lugar de bandas individuales, logro un modelo con mejor ajuste en entrenamiento, con un RÂ² de 0.784 frente a 0.766 del modelo previo. TambiÃ©n el error promedio en la validaciÃ³n cruzada mejora ligeramente (RMSE CV 0.119 vs. 0.125), lo que indica una selecciÃ³n mÃ¡s eficiente de variables.

Sin embargo, al evaluar con los datos de la campaÃ±a mÃ¡s reciente, el desempeÃ±o baja significativamente: el RÂ² cae a 0.212, mucho menor que el 0.484 obtenido anteriormente, y el RMSE aumenta, mostrando que la capacidad de generalizaciÃ³n sigue siendo limitada.

El anÃ¡lisis bootstrap confirma que la razÃ³n **log(B02/B07)** tiene un coeficiente negativo estable y significativo, mientras que **log(B05/B11)** aporta muy poco y su coeficiente incluye cero en el intervalo de confianza, indicando que su efecto es marginal.

Desde el punto de vista fÃ­sico, el modelo indica que a medida que aumenta la razÃ³n B02/B07, la concentraciÃ³n de sÃ³lidos suspendidos tiende a disminuir, mientras que la razÃ³n B05/B11 tiene un efecto muy dÃ©bil e incierto.

A pesar de que el uso de razones simples resulta en un modelo mÃ¡s compacto y con una mejora modesta en el ajuste, la capacidad para predecir sÃ³lidos suspendidos en campaÃ±as futuras continÃºa siendo limitada.

:::


#### Ajuste del umbral Î”AIC para selecciÃ³n de variables

Para evaluar la robustez y simplicidad del modelo, aumento el umbral mÃ­nimo de mejora en el criterio AIC (Î”AIC) de 2 a 4. Esto implica que la selecciÃ³n hacia adelante solo incorpora nuevas variables si la reducciÃ³n en AIC es al menos 4, promoviendo modelos mÃ¡s parsimoniosos y evitando incluir variables con mejoras marginales que podrÃ­an no generalizar bien.

Este ajuste busca balancear mejor el compromiso entre ajuste y complejidad, reduciendo el riesgo de sobreajuste, especialmente relevante al aplicar el modelo a campaÃ±as de muestreo futuras.

```{python}
#|code-fold: true
# 0 Â· LIBRERÃAS
import numpy as np
import pandas as pd
from pathlib import Path
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import GroupKFold
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
from IPython.display import display, Markdown

# -------------------------------------------------------------
# 1 Â· CONFIGURACIÃ“N
DATOS     = Path("datos/datos_sol_sus_acolite.csv")     # â† ajustÃ¡ si hace falta
DELTA_AIC = 4                                            # Î”AIC mÃ­nimo
N_BOOT    = 2000
RNG_SEED  = 42

# -------------------------------------------------------------
# 2 Â· FUNCIONES AUXILIARES
def aic_gauss(rss, n, k):           # k = nÂº coef + intercepto
    return n * np.log(rss / n) + 2 * k

def fit_metrics(X, y):
    """Ajusta LR y devuelve mÃ©tricas + modelo."""
    m    = LinearRegression().fit(X, y)
    pred = m.predict(X)
    rss  = np.sum((y - pred) ** 2)
    n, p = X.shape
    return {
        "AIC" : aic_gauss(rss, n, p + 1),
        "RMSE": np.sqrt(mean_squared_error(y, pred)),
        "RÂ²"  : r2_score(y, pred),
        "RÂ²aj": 1 - (1 - r2_score(y, pred)) * (n - 1) / (n - p - 1),
        "mod" : m
    }

def rmse(a, b): return np.sqrt(mean_squared_error(a, b))

# -------------------------------------------------------------
# 3 Â· CARGA Y PREPARACIÃ“N DE DATOS
df = pd.read_csv(DATOS)
df["fecha"] = pd.to_datetime(df["fecha"])

bandas = [c for c in df.columns if c.startswith("B")]
mask   = (df["sol_sus"] > 0) & (df[bandas] > 0).all(axis=1)
df     = df.loc[mask].copy()

# variable respuesta en log
df["log_sol_sus"] = np.log(df["sol_sus"])

# -------------------------------------------------------------
# 3.1 Â· GENERAR RAZONES SIMPLES DE BANDAS EN LOGARITMO
ratio_cols = []
for i, b1 in enumerate(bandas):
    for b2 in bandas[i+1:]:
        col = f"log({b1}/{b2})"
        df[col] = np.log(df[b1]) - np.log(df[b2])
        ratio_cols.append(col)

X = df[ratio_cols]                # predictores = razones simples en log
y = df["log_sol_sus"]

# -------------------------------------------------------------
# 3.2 Â· PARTICIÃ“N TEMPORAL
last_date = df["fecha"].max()
m_test    = df["fecha"] == last_date
m_train   = ~m_test

X_tr, y_tr = X.loc[m_train], y.loc[m_train]
X_te, y_te = X.loc[m_test] , y.loc[m_test]
groups_tr  = df.loc[m_train, "fecha"]

print(f"TRAIN campaÃ±as : {groups_tr.nunique()}")
print(f"TEST  campaÃ±a  : {last_date.date()} ({m_test.sum()} muestras)")

# -------------------------------------------------------------
# 4 Â· FORWARD SELECTION (razones simples logarÃ­tmicas) con AIC + Î”
remaining = ratio_cols.copy()
selected  = []

# modelo nulo
rss_null  = np.sum((y_tr - y_tr.mean())**2)
best_aic  = aic_gauss(rss_null, len(y_tr), k=1)

hist = []
paso = 0
while remaining:
    candidatos = []
    for col in remaining:
        cols = selected + [col]
        m    = fit_metrics(X_tr[cols].values, y_tr.values)
        candidatos.append((m["AIC"], col, m))
    candidatos.sort()

    new_aic, best_col, best_met = candidatos[0]
    if best_aic - new_aic >= DELTA_AIC:     # mejora â‰¥ Î”AIC
        selected.append(best_col)
        remaining.remove(best_col)
        best_aic = new_aic
        paso += 1
        hist.append({
            "Paso"  : paso,
            "Bandas": ", ".join(selected),
            "AIC"   : best_aic,
            "RMSE"  : best_met["RMSE"],
            "RÂ²"    : best_met["RÂ²"],
            "RÂ²aj"  : best_met["RÂ²aj"]
        })
    else:
        break

# fallback (si nada mejora)
if not selected:
    selected = [min(candidatos, key=lambda t: t[0])[1]]
    best_aic = min(candidatos)[0]
    best_met = min(candidatos)[2]
    hist.append({
        "Paso"  : 1,
        "Bandas": selected[0],
        "AIC"   : best_aic,
        "RMSE"  : best_met["RMSE"],
        "RÂ²"    : best_met["RÂ²"],
        "RÂ²aj"  : best_met["RÂ²aj"]
    })

hist_df = (pd.DataFrame(hist)
             .loc[:, ["Paso", "Bandas", "AIC", "RMSE", "RÂ²", "RÂ²aj"]])

# Mostrar tabla historial con caption y sin Ã­ndice
display(
    hist_df.style
    .format({"AIC": "{:.3f}", "RMSE": "{:.3f}", "RÂ²": "{:.3f}", "RÂ²aj": "{:.3f}"})
    .set_caption("Historial de selecciÃ³n")
    .hide(axis="index")
)

# Mostrar bandas seleccionadas en negrita Markdown
display(Markdown(f"**Bandas seleccionadas:**  `{', '.join(selected)}`"))

# -------------------------------------------------------------
# 5 Â· VALIDACIÃ“N GROUPâ€‘KFOLD
gkf = GroupKFold(n_splits=min(5, groups_tr.nunique()))
rmse_cv = []
for tr_idx, te_idx in gkf.split(X_tr[selected], y_tr, groups_tr):
    m    = LinearRegression().fit(X_tr.iloc[tr_idx][selected], y_tr.iloc[tr_idx])
    pred = m.predict(X_tr.iloc[te_idx][selected])
    rmse_cv.append(rmse(y_tr.iloc[te_idx], pred))

# Mostrar GroupKFold CV en negrita Markdown
display(Markdown(f"**GroupKFold CV (log) RMSE:** {np.mean(rmse_cv):.3f} Â± {np.std(rmse_cv):.3f}"))

# -------------------------------------------------------------
# 6 Â· MODELO FINAL Y MÃ‰TRICAS
mod = LinearRegression().fit(X_tr[selected], y_tr)

# TRAIN
pred_tr_log = mod.predict(X_tr[selected])
rmse_tr_log = rmse(y_tr, pred_tr_log)
r2_tr_log   = r2_score(y_tr, pred_tr_log)

# TEST
pred_te_log = mod.predict(X_te[selected])
rmse_te_log = rmse(y_te, pred_te_log)
r2_te_log   = r2_score(y_te, pred_te_log)

# escala original
y_tr_lin, y_te_lin = np.exp(y_tr), np.exp(y_te)
pred_tr_lin, pred_te_lin = np.exp(pred_tr_log), np.exp(pred_te_log)

rmse_tr_lin = rmse(y_tr_lin, pred_tr_lin)
r2_tr_lin   = r2_score(y_tr_lin, pred_tr_lin)
rmse_te_lin = rmse(y_te_lin, pred_te_lin)
r2_te_lin   = r2_score(y_te_lin, pred_te_lin)

metrics_df = pd.DataFrame({
    "MÃ©trica"    : ["RMSE", "RÂ²"],
    "Train log"  : [rmse_tr_log, r2_tr_log],
    "Test log"   : [rmse_te_log, r2_te_log],
    "Train orig" : [rmse_tr_lin, r2_tr_lin],
    "Test orig"  : [rmse_te_lin, r2_te_lin]
})

# Mostrar tabla mÃ©tricas con caption y sin Ã­ndice
display(
    metrics_df.style
    .format({
        "Train log": "{:.3f}", "Test log": "{:.3f}",
        "Train orig": "{:.3f}", "Test orig": "{:.3f}"
    })
    .set_caption("MÃ©tricas finales")
    .hide(axis="index")
)

# -------------------------------------------------------------
# 7 Â· BOOTSTRAP AGRUPADO (coef 95 % CI)
rng    = np.random.default_rng(RNG_SEED)
dates  = groups_tr.unique()
coef_bs = []

for _ in range(N_BOOT):
    samp = rng.choice(dates, len(dates), replace=True)
    idx  = groups_tr.isin(samp)
    m_bs = LinearRegression().fit(X_tr.loc[idx, selected], y_tr.loc[idx])
    coef_bs.append(m_bs.coef_)

coef_bs = np.array(coef_bs)
mean_bs = coef_bs.mean(axis=0)
ci_bs   = np.percentile(coef_bs, [2.5, 97.5], axis=0)

bs_df = pd.DataFrame({
    "Banda"       : selected,
    "Media Î²"     : mean_bs,
    "IC 95% inf." : ci_bs[0],
    "IC 95% sup." : ci_bs[1]
})

# Mostrar tabla bootstrap con caption y sin Ã­ndice
display(
    bs_df.style
    .format({
        "Media Î²": "{:.4f}",
        "IC 95% inf.": "{:.4f}",
        "IC 95% sup.": "{:.4f}"
    })
    .set_caption("Bootstrap (coeficientes, 95 % CI)")
    .hide(axis="index")
)

# -------------------------------------------------------------
# 8 Â· ECUACIONES
alpha      = np.exp(mod.intercept_)
expr_log   = " + ".join([f"{c:.4f}Â·{r}" for c, r in zip(mod.coef_, selected)])
expr_orig  = " Â· ".join([f"{r}^{c:.4f}" for c, r in zip(mod.coef_, selected)])

display(Markdown("EcuaciÃ³n (log)"))
display(Markdown(f"`log(sol_sus) = {mod.intercept_:.4f} + {expr_log}`"))

display(Markdown("EcuaciÃ³n (original)"))
display(Markdown(f"`sol_sus = {alpha:.4f} Â· {expr_orig}`"))

# -------------------------------------------------------------
# 9 Â· GRÃFICAS DE PARIDAD (TRAIN + TEST) - estilo especificado
plt.rcParams.update({"axes.titlesize":10,"axes.labelsize":8,
                     "xtick.labelsize":7,"ytick.labelsize":7})

TRAIN_CLR = "#9D50A6"
TEST_CLR = "#FFA24B"
ID_CLR = "#17A77E"

fig, ax = plt.subplots(1, 2, figsize=(9, 4))
# Escala log
ax[0].scatter(y_tr, pred_tr_log, alpha=0.6, color=TRAIN_CLR, edgecolor="k", label="Train (â—)")
ax[0].scatter(y_te, pred_te_log, alpha=0.6, color=TEST_CLR, marker="s", edgecolor="k", label="Test  (â– )")
lims = [min(y_tr.min(), y_te.min()), max(y_tr.max(), y_te.max())]
ax[0].plot(lims, lims, "--", color=ID_CLR, lw=2.5, label="y = x")
ax[0].set(xlabel="log(sol_sus) obs.", ylabel="log(sol_sus) pred.", title="Escala log")
ax[0].legend(fontsize=7, frameon=False)
ax[0].grid(ls=":")

# Escala original
ax[1].scatter(y_tr_lin, pred_tr_lin, alpha=0.6, color=TRAIN_CLR, edgecolor="k", label="Train (â—)")
ax[1].scatter(y_te_lin, pred_te_lin, alpha=0.6, color=TEST_CLR, marker="s", edgecolor="k", label="Test  (â– )")
lims_o = [min(y_tr_lin.min(), y_te_lin.min(), pred_tr_lin.min(), pred_te_lin.min()),
          max(y_tr_lin.max(), y_te_lin.max(), pred_tr_lin.max(), pred_te_lin.max())]
ax[1].plot(lims_o, lims_o, "--", color=ID_CLR, lw=2.5)
ax[1].set(xlabel="sol_sus obs. (mg/L)", ylabel="sol_sus pred. (mg/L)", title="Escala original")
ax[1].legend(fontsize=7, frameon=False)
ax[1].grid(ls=":")

fig.suptitle(f"Predicho vs Observado Â· Î”AIC â‰¥ {DELTA_AIC}", fontsize=11, y=1.05)
fig.tight_layout(pad=1.2)
plt.show()

# restaurar estilos si continuÃ¡s graficando
plt.rcParams.update({"axes.titlesize":11,"axes.labelsize":9,
                     "xtick.labelsize":8,"ytick.labelsize":8})

```


::: {.callout-note title="Impacto del aumento del umbral Î”AIC en la selecciÃ³n de variables"}

Al aumentar Î”AIC a 4, el modelo se simplifica seleccionando solo la razÃ³n **log(B02/B07)**, manteniendo un buen ajuste en entrenamiento (RÂ² = 0.739). Sin embargo, el desempeÃ±o en la campaÃ±a de prueba es bajo, con RÂ² cercano a cero, indicando poca capacidad de generalizaciÃ³n. El anÃ¡lisis bootstrap muestra estabilidad en el coeficiente seleccionado.

Por lo tanto, un mayor Î”AIC favorece modelos mÃ¡s simples, pero no mejora la predicciÃ³n en nuevas campaÃ±as, por lo que es necesario explorar modelos mÃ¡s complejos o incluir mÃ¡s variables.

:::



### SelecciÃ³n de bandas, razones y potencias para modelar sÃ³lidos suspendidos

En esta secciÃ³n amplÃ­o el conjunto de variables predictoras al incluir no solo logaritmos simples de bandas espectrales, sino tambiÃ©n sus potencias cuadrÃ¡ticas y cÃºbicas, asÃ­ como razones logarÃ­tmicas entre bandas. El objetivo es capturar relaciones no lineales y combinadas que podrÃ­an mejorar la capacidad predictiva del modelo.

Utilizo una estrategia de selecciÃ³n hacia adelante basada en el criterio AIC (`Î”AIC â‰¥ 4`), priorizando modelos mÃ¡s parsimoniosos pero informativos. La validaciÃ³n se realiza con particiÃ³n temporal (hold-out) y GroupKFold, y se evalÃºa la estabilidad del modelo mediante bootstrap de coeficientes (IC del 95â€¯%). Finalmente, se comparan las predicciones con observaciones en escalas logarÃ­tmica y original.

```{python}
#|code-fold: true
import numpy as np
import pandas as pd
from pathlib import Path
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import GroupKFold
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
from IPython.display import display, Markdown

# -------------------------------------------------------------
# 1 Â· CONFIGURACIÃ“N
DATOS     = Path("datos/datos_sol_sus_acolite.csv")
DELTA_AIC = 4                # umbral de mejora
N_BOOT    = 2000
RNG_SEED  = 42

# -------------------------------------------------------------
# 2 Â· FUNCIONES
def aic_gauss(rss, n, k):              # k = coef + intercepto
    return n*np.log(rss/n) + 2*k

def fit_metrics(X, y):
    m = LinearRegression().fit(X, y)
    pred = m.predict(X)
    rss  = np.sum((y-pred)**2)
    n,p  = X.shape
    return {
        "AIC" : aic_gauss(rss, n, p+1),
        "RMSE": np.sqrt(mean_squared_error(y, pred)),
        "RÂ²"  : r2_score(y, pred),
        "RÂ²aj": 1 - (1-r2_score(y,pred))*(n-1)/(n-p-1),
        "mod" : m
    }

rmse = lambda a,b: np.sqrt(mean_squared_error(a,b))

# -------------------------------------------------------------
# 3 Â· CARGA Y PREPARACIÃ“N
df = pd.read_csv(DATOS)
df["fecha"] = pd.to_datetime(df["fecha"])

bandas = [c for c in df.columns if c.startswith("B")]
df = df.loc[(df["sol_sus"]>0) & (df[bandas]>0).all(1)].copy()

df["log_sol_sus"] = np.log(df["sol_sus"])

# 3.1  log(Bx)  +  (log(Bx))Â²,(log(Bx))Â³
log_cols   = []
poly_cols  = []
for b in bandas:
    log_b = f"log_{b}"
    df[log_b] = np.log(df[b])
    df[f"{log_b}^2"] = df[log_b]**2
    df[f"{log_b}^3"] = df[log_b]**3
    log_cols.append(log_b)
    poly_cols.extend([f"{log_b}^2", f"{log_b}^3"])

# 3.2  razones en log: log(Bi/Bj) = logBi - logBj
ratio_cols = []
for i,b1 in enumerate(bandas):
    for b2 in bandas[i+1:]:
        col = f"log({b1}/{b2})"
        df[col] = df[f"log_{b1}"] - df[f"log_{b2}"]
        ratio_cols.append(col)

cand_cols = log_cols + poly_cols + ratio_cols
print(f"Total de variables candidatas: {len(cand_cols)}")

X = df[cand_cols]
y = df["log_sol_sus"]

# -------------------------------------------------------------
# 4 Â· HOLDâ€‘OUT TEMPORAL
last = df["fecha"].max()
m_te  = df["fecha"]==last
m_tr  = ~m_te
X_tr, y_tr = X[m_tr], y[m_tr]
X_te, y_te = X[m_te], y[m_te]
groups_tr  = df.loc[m_tr,"fecha"]

print(f"\nTRAIN campaÃ±as : {groups_tr.nunique()}")
print(f"TEST  campaÃ±a  : {last.date()}  ({m_te.sum()} muestras)")

# -------------------------------------------------------------
# 5 Â· FORWARDâ€‘AIC (Î” â‰¥ {DELTA_AIC})
remaining = cand_cols.copy()
selected  = []

rss0   = np.sum((y_tr - y_tr.mean())**2)
best_aic = aic_gauss(rss0, len(y_tr), 1)

hist=[]; step=0
while remaining:
    scores=[]
    for col in remaining:
        cols = selected + [col]
        mtr  = fit_metrics(X_tr[cols].values, y_tr.values)
        scores.append((mtr["AIC"], col, mtr))
    scores.sort()
    new_aic, best_col, m_info = scores[0]

    if best_aic - new_aic >= DELTA_AIC:
        selected.append(best_col)
        remaining.remove(best_col)
        best_aic = new_aic
        step += 1
        hist.append({
            "Paso":step, "Variables":", ".join(selected),
            "AIC":best_aic, "RMSE":m_info["RMSE"],
            "RÂ²":m_info["RÂ²"], "RÂ²aj":m_info["RÂ²aj"]
        })
    else:
        break

if not selected:
    best_col = min(scores, key=lambda t:t[0])[1]
    selected = [best_col]
    hist.append({"Paso":1,"Variables":best_col,
                 **{k:v for k,v in scores[0][2].items() if k!="mod"}})

hist_df = pd.DataFrame(hist)

# Mostrar tabla historial con caption y sin Ã­ndice
display(
    hist_df.style
    .format({"AIC": "{:.3f}", "RMSE": "{:.3f}", "RÂ²": "{:.3f}", "RÂ²aj": "{:.3f}"})
    .set_caption("Historial de selecciÃ³n")
    .hide(axis="index")
)

# Mostrar variables seleccionadas en negrita Markdown
display(Markdown(f"**Variables finales seleccionadas:** `{', '.join(selected)}`"))

# -------------------------------------------------------------
# 6 Â· VALIDACIÃ“N GROUPâ€‘KFOLD
gkf = GroupKFold(n_splits=min(5,groups_tr.nunique()))
rm = []
for tr_idx, te_idx in gkf.split(X_tr[selected], y_tr, groups_tr):
    m = LinearRegression().fit(X_tr.iloc[tr_idx][selected], y_tr.iloc[tr_idx])
    rm.append(rmse(y_tr.iloc[te_idx], m.predict(X_tr.iloc[te_idx][selected])))

display(Markdown(f"**GroupKFold CV (log) RMSE:** {np.mean(rm):.3f} Â± {np.std(rm):.3f}"))

# -------------------------------------------------------------
# 7 Â· MODELO FINAL Y MÃ‰TRICAS
mod = LinearRegression().fit(X_tr[selected], y_tr)

pred_tr = mod.predict(X_tr[selected])
pred_te = mod.predict(X_te[selected])

metrics_df = pd.DataFrame({
    "MÃ©trica"    : ["RMSE", "RÂ²"],
    "Train log"  : [rmse(y_tr,pred_tr), r2_score(y_tr,pred_tr)],
    "Test log"   : [rmse(y_te,pred_te), r2_score(y_te,pred_te)],
    "Train orig" : [rmse(np.exp(y_tr), np.exp(pred_tr)), r2_score(np.exp(y_tr), np.exp(pred_tr))],
    "Test orig"  : [rmse(np.exp(y_te), np.exp(pred_te)), r2_score(np.exp(y_te), np.exp(pred_te))]
})

# Mostrar tabla mÃ©tricas con caption y sin Ã­ndice
display(
    metrics_df.style
    .format({
        "Train log": "{:.3f}", "Test log": "{:.3f}",
        "Train orig": "{:.3f}", "Test orig": "{:.3f}"
    })
    .set_caption("MÃ©tricas finales")
    .hide(axis="index")
)

# -------------------------------------------------------------
# 8 Â· BOOTSTRAP AGRUPADO (IC 95â€¯%)
rng = np.random.default_rng(RNG_SEED)
dates = groups_tr.unique()
coef_bs=[]
for _ in range(N_BOOT):
    samp = rng.choice(dates, len(dates), replace=True)
    idx  = groups_tr.isin(samp)
    m_bs = LinearRegression().fit(X_tr.loc[idx,selected], y_tr.loc[idx])
    coef_bs.append(m_bs.coef_)
coef_bs = np.asarray(coef_bs)
ci_lo, ci_hi = np.percentile(coef_bs,[2.5,97.5],axis=0)

bs_df = pd.DataFrame({
    "Variable"    : selected,
    "Media Î²"     : coef_bs.mean(0),
    "IC 95% inf." : ci_lo,
    "IC 95% sup." : ci_hi
})

# Mostrar tabla bootstrap con caption y sin Ã­ndice
display(
    bs_df.style
    .format({
        "Media Î²": "{:.4f}",
        "IC 95% inf.": "{:.4f}",
        "IC 95% sup.": "{:.4f}"
    })
    .set_caption("Bootstrap (coeficientes, 95 % CI)")
    .hide(axis="index")
)

# -------------------------------------------------------------
# 9 Â· ECUACIÃ“N DEL MODELO
alpha = np.exp(mod.intercept_)
expr_log  = " + ".join([f"{c:.4f}Â·{v}" for c,v in zip(mod.coef_,selected)])
expr_orig = " Â· ".join([f"{v}^{c:.4f}" for c,v in zip(mod.coef_,selected)])

display(Markdown("EcuaciÃ³n (log)"))
display(Markdown(f"`log(sol_sus) = {mod.intercept_:.4f} + {expr_log}`"))

display(Markdown("EcuaciÃ³n (original)"))
display(Markdown(f"`sol_sus = {alpha:.4f} Â· {expr_orig}`"))

# -------------------------------------------------------------
# 10 Â· PARIDAD TRAIN + TEST (log y mg/L) con estilo de colores y leyenda

plt.rcParams.update({"axes.titlesize":10,"axes.labelsize":8,
                     "xtick.labelsize":7,"ytick.labelsize":7})

TRAIN_CLR = "#9D50A6"
TEST_CLR = "#FFA24B"
ID_CLR = "#17A77E"

fig, ax = plt.subplots(1, 2, figsize=(9, 4))
# Escala log
ax[0].scatter(y_tr, pred_tr, alpha=0.6, color=TRAIN_CLR, edgecolor="k", label="Train (â—)")
ax[0].scatter(y_te, pred_te, alpha=0.6, color=TEST_CLR, marker="s", edgecolor="k", label="Test  (â– )")
lims = [min(y_tr.min(), y_te.min()), max(y_tr.max(), y_te.max())]
ax[0].plot(lims, lims, "--", color=ID_CLR, lw=2.5, label="y = x")
ax[0].set(xlabel="log(sol_sus) obs.", ylabel="log(sol_sus) pred.", title="Escala log")
ax[0].legend(fontsize=7, frameon=False)
ax[0].grid(ls=":")

# Escala original
y_tr_lin, y_te_lin = np.exp(y_tr), np.exp(y_te)
pred_tr_lin, pred_te_lin = np.exp(pred_tr), np.exp(pred_te)

ax[1].scatter(y_tr_lin, pred_tr_lin, alpha=0.6, color=TRAIN_CLR, edgecolor="k", label="Train (â—)")
ax[1].scatter(y_te_lin, pred_te_lin, alpha=0.6, color=TEST_CLR, marker="s", edgecolor="k", label="Test  (â– )")
lims_o = [min(y_tr_lin.min(), y_te_lin.min(), pred_tr_lin.min(), pred_te_lin.min()),
          max(y_tr_lin.max(), y_te_lin.max(), pred_tr_lin.max(), pred_te_lin.max())]
ax[1].plot(lims_o, lims_o, "--", color=ID_CLR, lw=2.5)
ax[1].set(xlabel="sol_sus obs. (mg/L)", ylabel="sol_sus pred. (mg/L)", title="Escala original")
ax[1].legend(fontsize=7, frameon=False)
ax[1].grid(ls=":")

fig.suptitle(f"Predicho vs Observado Â· Î”AIC â‰¥ {DELTA_AIC}", fontsize=11, y=1.05)
fig.tight_layout(pad=1.2)
plt.show()

# Restaurar estilos para otras grÃ¡ficas
plt.rcParams.update({"axes.titlesize":11,"axes.labelsize":9,
                     "xtick.labelsize":8,"ytick.labelsize":8})

```

::: {.callout-note title="ConclusiÃ³n del modelo seleccionado"}

Este modelo combina la razÃ³n espectral **log(B02/B07)** con una transformaciÃ³n cÃºbica de la banda **B8A**, logrando el mejor desempeÃ±o hasta ahora: `RÂ² = 0.688` en la campaÃ±a de prueba, mucho mayor que en modelos anteriores (~0.2 o menos). TambiÃ©n mejora el ajuste (`RÂ² = 0.812` en entrenamiento) sin perder generalizaciÃ³n (`RMSE_CV = 0.123 Â± 0.034`).

El tÃ©rmino dominante sigue siendo **log(B02/B07)**, que ya aparecÃ­a en modelos previos y mantiene un efecto negativo claro. Esto indica que **una mayor reflectancia relativa en B02 frente a B07 se asocia a menos sÃ³lidos suspendidos**, lo que tiene sentido: B02 (azul) penetra mÃ¡s el agua, y si hay mÃ¡s sÃ³lidos en suspensiÃ³n, se dispersa o absorbe mÃ¡s rÃ¡pido que B07 (NIR).

El aporte de **log_B8AÂ³** es marginal: su coeficiente es pequeÃ±o y no significativo (el IC incluye cero), pero su inclusiÃ³n mejorÃ³ el AIC â‰¥â€¯4, lo que sugiere que ayuda a capturar alguna curvatura en los datos.

:::


#### EvaluaciÃ³n del aporte marginal de `log_B8AÂ³`

Para verificar si la variable **log_B8AÂ³** mejora efectivamente la predicciÃ³n, ajusto un modelo mÃ¡s simple utilizando solo `log(B02/B07)` y comparo su desempeÃ±o sobre la campaÃ±a de prueba. Esta comparaciÃ³n permite confirmar si el descenso en AIC justifica una mejora real o si el nuevo tÃ©rmino solo ajusta mejor los datos de entrenamiento.


```{python}
#|code-fold: true
selected_simple = ['log(B02/B07)']

# Entrena modelo simple
mod_simple = LinearRegression().fit(X_tr[selected_simple], y_tr)
pred_te_simple = mod_simple.predict(X_te[selected_simple])
rmse_te_simple = rmse(y_te, pred_te_simple)
r2_te_simple = r2_score(y_te, pred_te_simple)

print(f"Modelo simple TEST log RMSE = {rmse_te_simple:.3f} | RÂ² = {r2_te_simple:.3f}")

```


::: {.callout-note title="ConclusiÃ³n sobre el aporte de `log_B8AÂ³`"}

Al comparar el modelo completo con otro mÃ¡s simple que usa solo `log(B02/B07)`, se observa una mejora notable en el desempeÃ±o sobre la campaÃ±a de prueba: el `RMSE` disminuye de 0.391 a 0.244 y el `RÂ²` se incrementa de 0.20 a 0.69. Esto sugiere que `log_B8AÂ³` contribuye a mejorar la capacidad predictiva del modelo.

Sin embargo, el coeficiente estimado para `log_B8AÂ³` es pequeÃ±o, y su intervalo de confianza incluye el cero, lo que indica **incertidumbre sobre su efecto real**. Por lo tanto, aunque su inclusiÃ³n mejora el ajuste y la predicciÃ³n, el aporte es **marginal y debe interpretarse con cautela**.

:::





### Razones espectrales informadas (NIR/Blue, Red/Green, NDWI) para mejorar el modelo

En esta secciÃ³n incorporo **razones espectrales con base teÃ³rica o empÃ­rica** utilizadas comÃºnmente en teledetecciÃ³n para el anÃ¡lisis de calidad del agua. Estas incluyen cocientes como `NIR/Blue`, `Red/Green`, y el Ã­ndice `NDWI`, que podrÃ­an capturar caracterÃ­sticas Ã³pticas relevantes no reflejadas por combinaciones arbitrarias de bandas.

Estas nuevas variables se aÃ±aden a las transformaciones ya consideradas (logaritmos, potencias y razones logarÃ­tmicas) y se someten al mismo procedimiento de selecciÃ³n automÃ¡tica (`Forward AIC`) con un umbral de mejora Î”AICâ€¯â‰¥â€¯4. El objetivo es evaluar si estas razones â€œinformadasâ€ permiten mejorar el ajuste del modelo sin sacrificar interpretabilidad ni aumentar en exceso su complejidad.

El enfoque conserva la validaciÃ³n cruzada temporal (`GroupKFold`) y el anÃ¡lisis de incertidumbre mediante bootstrap, para mantener la robustez en la comparaciÃ³n con resultados anteriores.

```{python}
#|code-fold: true
# -------------------------------------------------------------
# 0 Â· LIBRERÃAS
import numpy as np
import pandas as pd
from pathlib import Path
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import GroupKFold
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
from IPython.display import display, Markdown

# -------------------------------------------------------------
# 1 Â· CONFIGURACIÃ“N
DATOS      = Path("datos/datos_sol_sus_acolite.csv")
DELTA_AIC  = 2.0            # âˆ†AIC mÃ­nimo
N_BOOT     = 2000
RNG_SEED   = 42

# -------------------------------------------------------------
# 2 Â· FUNCIONES AUXILIARES
def aic_gauss(rss, n, k):
    return n * np.log(rss / n) + 2 * k

def fit_metrics(X, y):
    m    = LinearRegression().fit(X, y)
    pred = m.predict(X)
    rss  = np.sum((y - pred) ** 2)
    n, p = X.shape
    r2   = r2_score(y, pred)
    return {
        "AIC" : aic_gauss(rss, n, p + 1),
        "RMSE": np.sqrt(mean_squared_error(y, pred)),
        "RÂ²"  : r2,
        "RÂ²aj": 1 - (1 - r2) * (n - 1) / (n - p - 1),
        "mod" : m
    }

rmse = lambda a, b: np.sqrt(mean_squared_error(a, b))

# -------------------------------------------------------------
# 3 Â· CARGA Y PREPARACIÃ“N
df = pd.read_csv(DATOS)
df["fecha"] = pd.to_datetime(df["fecha"])

bandas = [c for c in df.columns if c.startswith("B")]
df = df.loc[(df["sol_sus"] > 0) & (df[bandas] > 0).all(axis=1)].copy()

df["log_sol_sus"] = np.log(df["sol_sus"])

# 3.1 Â· logâ€‘bandas individuales
log_bands = []
for b in bandas:
    col = f"log_{b}"
    df[col] = np.log(df[b])
    log_bands.append(col)

# 3.2 Â· cocientes informados + NDWI
req = {"B02","B03","B04","B08"}
if not req.issubset(df.columns):
    raise ValueError(f"Faltan bandas necesarias: {req - set(df.columns)}")

df["NIR_Blue"]  = df["B08"] / df["B02"]
df["Red_Green"] = df["B04"] / df["B03"]
df["NDWI"]      = (df["B03"] - df["B08"]) / (df["B03"] + df["B08"])
indices = ["NIR_Blue", "Red_Green", "NDWI"]

# -------------------------------------------------------------
# 4 Â· MATRICES DE MODELADO
vars_candidatas = log_bands + indices
display(Markdown(f"**Total de variables candidatas:** {len(vars_candidatas)}"))

X = df[vars_candidatas]
y = df["log_sol_sus"]

# -------------------------------------------------------------
# 5 Â· HOLDâ€‘OUT TEMPORAL
last_date = df["fecha"].max()
mask_te   = df["fecha"] == last_date
mask_tr   = ~mask_te

X_tr, y_tr = X.loc[mask_tr], y.loc[mask_tr]
X_te, y_te = X.loc[mask_te], y.loc[mask_te]
groups_tr  = df.loc[mask_tr, "fecha"]

display(Markdown(f"**TRAIN campaÃ±as:** {groups_tr.nunique()}"))
display(Markdown(f"**TEST campaÃ±a:** {last_date.date()}  ({mask_te.sum()} muestras)"))

# -------------------------------------------------------------
# 6 Â· FORWARD SELECTION (âˆ†AIC â‰¥ {DELTA_AIC})
remaining = vars_candidatas.copy()
selected  = []

rss_null = np.sum((y_tr - y_tr.mean()) ** 2)
best_aic = aic_gauss(rss_null, len(y_tr), k=1)

hist, step = [], 0
while remaining:
    scores = []
    for var in remaining:
        cols = selected + [var]
        met  = fit_metrics(X_tr[cols].values, y_tr.values)
        scores.append((met["AIC"], var, met))
    scores.sort()
    new_aic, best_var, best_met = scores[0]

    if best_aic - new_aic >= DELTA_AIC:
        selected.append(best_var)
        remaining.remove(best_var)
        best_aic = new_aic
        step += 1
        hist.append({
            "Paso": step,
            "Variables": ", ".join(selected),
            "AIC": best_aic,
            "RMSE": best_met["RMSE"],
            "RÂ²": best_met["RÂ²"],
            "RÂ²aj": best_met["RÂ²aj"]
        })
    else:
        break

if not selected:
    best_var = min(scores, key=lambda t: t[0])[1]
    selected = [best_var]
    best_aic = min(scores)[0]
    best_met = min(scores)[2]
    hist.append({
        "Paso": 1,
        "Variables": best_var,
        **{k: best_met[k] for k in ("AIC","RMSE","RÂ²","RÂ²aj")}
    })

hist_df = pd.DataFrame(hist, columns=["Paso","Variables","AIC","RMSE","RÂ²","RÂ²aj"])
display(
    hist_df.style
    .format({"AIC":"{:.3f}","RMSE":"{:.3f}","RÂ²":"{:.3f}","RÂ²aj":"{:.3f}"})
    .set_caption("Historial de selecciÃ³n")
    .hide(axis="index")
)

display(Markdown(f"**Variables finales seleccionadas:** `{', '.join(selected)}`"))

# -------------------------------------------------------------
# 7 Â· VALIDACIÃ“NÂ Groupâ€‘KFold
gkf = GroupKFold(n_splits=min(5, groups_tr.nunique()))
rm_cv = []
for tr_idx, te_idx in gkf.split(X_tr[selected], y_tr, groups_tr):
    m = LinearRegression().fit(X_tr.iloc[tr_idx][selected], y_tr.iloc[tr_idx])
    rm_cv.append(rmse(y_tr.iloc[te_idx], m.predict(X_tr.iloc[te_idx][selected])))

display(Markdown(f"**GroupKFold CV (log) RMSE:** {np.mean(rm_cv):.3f} Â± {np.std(rm_cv):.3f}"))

# -------------------------------------------------------------
# 8 Â· MODELO FINAL Y MÃ‰TRICAS
mod = LinearRegression().fit(X_tr[selected], y_tr)

pred_tr_log = mod.predict(X_tr[selected])
pred_te_log = mod.predict(X_te[selected])

metrics_df = pd.DataFrame({
    "MÃ©trica": ["RMSE", "RÂ²"],
    "Train log": [rmse(y_tr, pred_tr_log), r2_score(y_tr, pred_tr_log)],
    "Test log": [rmse(y_te, pred_te_log), r2_score(y_te, pred_te_log)],
    "Train orig": [rmse(np.exp(y_tr), np.exp(pred_tr_log)), r2_score(np.exp(y_tr), np.exp(pred_tr_log))],
    "Test orig": [rmse(np.exp(y_te), np.exp(pred_te_log)), r2_score(np.exp(y_te), np.exp(pred_te_log))]
})

display(
    metrics_df.style
    .format({
        "Train log": "{:.3f}", "Test log": "{:.3f}",
        "Train orig": "{:.3f}", "Test orig": "{:.3f}"
    })
    .set_caption("MÃ©tricas finales")
    .hide(axis="index")
)

# -------------------------------------------------------------
# 9 Â· BOOTSTRAPÂ AGRUPADO (IC 95â€¯%)
rng   = np.random.default_rng(RNG_SEED)
dates = groups_tr.unique()
coef_bs=[]
for _ in range(N_BOOT):
    samp = rng.choice(dates, len(dates), replace=True)
    idx  = groups_tr.isin(samp)
    m_bs = LinearRegression().fit(X_tr.loc[idx, selected], y_tr.loc[idx])
    coef_bs.append(m_bs.coef_)

coef_bs = np.asarray(coef_bs)
ci_lo, ci_hi = np.percentile(coef_bs, [2.5, 97.5], axis=0)

bs_df = pd.DataFrame({
    "Variable"    : selected,
    "Media Î²"     : coef_bs.mean(axis=0),
    "IC 95% inf." : ci_lo,
    "IC 95% sup." : ci_hi
})

display(
    bs_df.style
    .format({"Media Î²":"{:.4f}","IC 95% inf.":"{:.4f}","IC 95% sup.":"{:.4f}"})
    .set_caption("Bootstrap (coeficientes, 95 % CI)")
    .hide(axis="index")
)

# -------------------------------------------------------------
# 10 Â· ECUACIONES
alpha     = np.exp(mod.intercept_)
expr_log  = " + ".join([f"{c:.4f}Â·{v}" for c, v in zip(mod.coef_, selected)])
expr_orig = " Â· ".join([f"{v}^{c:.4f}" for c, v in zip(mod.coef_, selected)])

display(Markdown("EcuaciÃ³n (log)"))
display(Markdown(f"`log(sol_sus) = {mod.intercept_:.4f} + {expr_log}`"))

display(Markdown("EcuaciÃ³n (original)"))
display(Markdown(f"`sol_sus = {alpha:.4f} Â· {expr_orig}`"))

# -------------------------------------------------------------
# 11 Â· GRÃFICAS DE PARIDAD (TRAIN + TEST) con estilo uniforme
plt.rcParams.update({
    "axes.titlesize":10, "axes.labelsize":8,
    "xtick.labelsize":7,"ytick.labelsize":7
})

TRAIN_CLR = "#9D50A6"
TEST_CLR  = "#FFA24B"
ID_CLR    = "#17A77E"

fig, ax = plt.subplots(1,2, figsize=(9,4))

# --- Escala log
ax[0].scatter(y_tr, pred_tr_log, alpha=.6, color=TRAIN_CLR, edgecolor='k', label="Train (â—)")
ax[0].scatter(y_te, pred_te_log, alpha=.6, color=TEST_CLR, marker='s', edgecolor='k', label="Test  (â– )")
lims = [min(y_tr.min(), y_te.min()), max(y_tr.max(), y_te.max())]
ax[0].plot(lims, lims, '--', color=ID_CLR, lw=2.5, label="y = x")
ax[0].set(xlabel="log(sol_sus) obs.", ylabel="log(sol_sus) pred.", title="Escala log")
ax[0].legend(fontsize=7, frameon=False)
ax[0].grid(ls=":")

# --- Escala original
y_tr_lin, y_te_lin = np.exp(y_tr), np.exp(y_te)
pred_tr_lin, pred_te_lin = np.exp(pred_tr_log), np.exp(pred_te_log)
ax[1].scatter(y_tr_lin, pred_tr_lin, alpha=.6, color=TRAIN_CLR, edgecolor='k', label="Train (â—)")
ax[1].scatter(y_te_lin, pred_te_lin, alpha=.6, color=TEST_CLR, marker='s', edgecolor='k', label="Test  (â– )")
lims_o = [min(y_tr_lin.min(), y_te_lin.min(), pred_tr_lin.min(), pred_te_lin.min()),
          max(y_tr_lin.max(), y_te_lin.max(), pred_tr_lin.max(), pred_te_lin.max())]
ax[1].plot(lims_o, lims_o, '--', color=ID_CLR, lw=2.5)
ax[1].set(xlabel="sol_sus obs. (mg/L)", ylabel="sol_sus pred. (mg/L)", title="Escala original")
ax[1].legend(fontsize=7, frameon=False)
ax[1].grid(ls=":")

fig.suptitle(f"Predicho vs Observado Â· Î”AIC â‰¥ {DELTA_AIC}", fontsize=11, y=1.05)
fig.tight_layout(pad=1.2)
plt.show()

# restaurar tamaÃ±o por defecto
plt.rcParams.update({"axes.titlesize":11,"axes.labelsize":9,
                     "xtick.labelsize":8,"ytick.labelsize":8})

```

::: {.callout-note title="ConclusiÃ³n del modelo seleccionado"}

La inclusiÃ³n de razones espectrales informadas, como `NIR_Blue`, permitiÃ³ ajustar un modelo con buen desempeÃ±o en el conjunto de entrenamiento (RÂ² = 0.80) y una estructura simple de solo dos variables. Sin embargo, al evaluarlo sobre una campaÃ±a futura, el modelo mostrÃ³ una caÃ­da significativa de desempeÃ±o (RÂ² = 0.02 en escala original), similar a modelos anteriores mÃ¡s simples.

El cociente `NIR_Blue` resultÃ³ la variable mÃ¡s informativa, con un coeficiente robusto y un intervalo de confianza estrecho. En contraste, la contribuciÃ³n de `log_B11` fue poco significativa, con un intervalo de coeficiente que incluye el cero, lo cual indica alta incertidumbre en su efecto.

Si bien estas razones espectrales permiten interpretar el modelo desde una base fÃ­sica, **no mejoran la capacidad de generalizaciÃ³n** respecto a modelos mÃ¡s simples basados en razones logarÃ­tmicas. Esto sugiere que el modelo estÃ¡ alcanzando un lÃ­mite explicativo con las bandas actuales, y que para mejorar la predicciÃ³n sobre nuevas campaÃ±as podrÃ­a ser necesario incorporar variables adicionales o utilizar modelos mÃ¡s flexibles.

:::





### SelecciÃ³n automÃ¡tica con AIC a partir de Ã­ndices espectrales clÃ¡sicos (NDVI,â€¯TurbI1,â€¯RE_NDVI yâ€¯NDMI)



```{python}
#|code-fold: true
import numpy as np
import pandas as pd
from pathlib import Path
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import GroupKFold
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
from IPython.display import display, Markdown

# -------------------------------------------------------------
# 1 Â· CONFIGURACIÃ“N
DATOS      = Path("datos/datos_sol_sus_acolite.csv")   # â† ajusta si hace falta
DELTA_AIC  = 2.0                                       # âˆ†AIC mÃ­nimo entre pasos
N_BOOT     = 2000                                      # rÃ©plicas bootstrap agrupado
RNG_SEED   = 42

# -------------------------------------------------------------
# 2 Â· FUNCIONES AUXILIARES
def aic_gauss(rss: float, n: int, k: int) -> float:
    return n * np.log(rss / n) + 2 * k

def fit_metrics(X: np.ndarray, y: np.ndarray):
    m = LinearRegression().fit(X, y)
    pred = m.predict(X)
    rss = np.sum((y - pred) ** 2)
    n, p = X.shape
    r2 = r2_score(y, pred)
    return {
        "AIC": aic_gauss(rss, n, p + 1),
        "RMSE": np.sqrt(mean_squared_error(y, pred)),
        "RÂ²": r2,
        "RÂ²aj": 1 - (1 - r2) * (n - 1) / (n - p - 1),
        "mod": m
    }

rmse = lambda a, b: np.sqrt(mean_squared_error(a, b))

# -------------------------------------------------------------
# 3 Â· CARGA Y PREPARACIÃ“N
df = pd.read_csv(DATOS)
df["fecha"] = pd.to_datetime(df["fecha"])

bandas = [c for c in df.columns if c.startswith("B")]
mask = (df["sol_sus"] > 0) & (df[bandas] > 0).all(axis=1)
df = df.loc[mask].copy()

df["log_sol_sus"] = np.log(df["sol_sus"])

log_bands = []
for b in bandas:
    col = f"log_{b}"
    df[col] = np.log(df[b])
    log_bands.append(col)

req = {"B03","B04","B05","B08","B11"}
faltan = req - set(df.columns)
if faltan:
    raise ValueError(f"Faltan bandas necesarias: {faltan}")

df["NDVI"]    = (df["B08"] - df["B04"]) / (df["B08"] + df["B04"])
df["TurbI1"]  = df["B03"] / df["B04"]
df["RE_NDVI"] = (df["B08"] - df["B05"]) / (df["B08"] + df["B05"])
df["NDMI"]    = (df["B08"] - df["B11"]) / (df["B08"] + df["B11"])

indices = ["NDVI", "TurbI1", "RE_NDVI", "NDMI"]

vars_candidatas = log_bands + indices
display(Markdown(f"**Total de variables candidatas:** {len(vars_candidatas)}"))

X = df[vars_candidatas]
y = df["log_sol_sus"]

# -------------------------------------------------------------
# 4 Â· HOLDâ€‘OUT TEMPORAL
last_date = df["fecha"].max()
mask_te = df["fecha"] == last_date
mask_tr = ~mask_te

X_tr, y_tr = X.loc[mask_tr], y.loc[mask_tr]
X_te, y_te = X.loc[mask_te], y.loc[mask_te]
groups_tr = df.loc[mask_tr, "fecha"]

display(Markdown(f"**TRAIN campaÃ±as:** {groups_tr.nunique()}"))
display(Markdown(f"**TEST campaÃ±a:** {last_date.date()}  ({mask_te.sum()} muestras)"))

# -------------------------------------------------------------
# 5 Â· FORWARD SELECTION guiado por AIC
remaining = vars_candidatas.copy()
selected = []

rss_null = np.sum((y_tr - y_tr.mean()) ** 2)
best_aic = aic_gauss(rss_null, len(y_tr), k=1)

hist = []
step = 0

while remaining:
    candidatos = []
    for v in remaining:
        cols = selected + [v]
        met = fit_metrics(X_tr[cols].values, y_tr.values)
        candidatos.append((met["AIC"], v, met))
    candidatos.sort(key=lambda t: t[0])

    new_aic, best_var, best_met = candidatos[0]
    if best_aic - new_aic >= DELTA_AIC:
        selected.append(best_var)
        remaining.remove(best_var)
        best_aic = new_aic
        step += 1
        hist.append({
            "Paso": step,
            "Variables": ", ".join(selected),
            "AIC": best_aic,
            "RMSE": best_met["RMSE"],
            "RÂ²": best_met["RÂ²"],
            "RÂ²aj": best_met["RÂ²aj"]
        })
    else:
        break

if not selected:
    best_aic, best_var, best_met = min(candidatos, key=lambda t: t[0])
    selected = [best_var]
    hist = [{
        "Paso": 1,
        "Variables": best_var,
        "AIC": best_aic,
        **{k: best_met[k] for k in ("RMSE", "RÂ²", "RÂ²aj")}
    }]

hist_df = pd.DataFrame(hist, columns=["Paso", "Variables", "AIC", "RMSE", "RÂ²", "RÂ²aj"])

display(
    hist_df.style
    .format({"AIC": "{:.3f}", "RMSE": "{:.3f}", "RÂ²": "{:.3f}", "RÂ²aj": "{:.3f}"})
    .set_caption("Historial de selecciÃ³n")
    .hide(axis="index")
)

display(Markdown(f"**Variables finales seleccionadas:** `{', '.join(selected)}`"))

# -------------------------------------------------------------
# 6 Â· VALIDACIÃ“N GROUPâ€‘KFOLD
gkf = GroupKFold(n_splits=min(5, groups_tr.nunique()))
rmse_cv = []
for tr_idx, te_idx in gkf.split(X_tr[selected], y_tr, groups_tr):
    m = LinearRegression().fit(X_tr.iloc[tr_idx][selected], y_tr.iloc[tr_idx])
    rmse_cv.append(rmse(y_tr.iloc[te_idx], m.predict(X_tr.iloc[te_idx][selected])))

display(Markdown(f"**GroupKFold CV (log) RMSE:** {np.mean(rmse_cv):.3f} Â± {np.std(rmse_cv):.3f}"))

# -------------------------------------------------------------
# 7 Â· MODELO FINAL Y MÃ‰TRICAS
mod = LinearRegression().fit(X_tr[selected], y_tr)

pred_tr_log = mod.predict(X_tr[selected])
pred_te_log = mod.predict(X_te[selected])

metrics_df = pd.DataFrame({
    "MÃ©trica": ["RMSE", "RÂ²"],
    "Train log": [rmse(y_tr, pred_tr_log), r2_score(y_tr, pred_tr_log)],
    "Test log": [rmse(y_te, pred_te_log), r2_score(y_te, pred_te_log)],
    "Train orig": [rmse(np.exp(y_tr), np.exp(pred_tr_log)), r2_score(np.exp(y_tr), np.exp(pred_tr_log))],
    "Test orig": [rmse(np.exp(y_te), np.exp(pred_te_log)), r2_score(np.exp(y_te), np.exp(pred_te_log))]
})

display(
    metrics_df.style
    .format({
        "Train log": "{:.3f}", "Test log": "{:.3f}",
        "Train orig": "{:.3f}", "Test orig": "{:.3f}"
    })
    .set_caption("MÃ©tricas finales")
    .hide(axis="index")
)

# -------------------------------------------------------------
# 8 Â· BOOTSTRAP AGRUPADO (IC 95â€¯%)
rng = np.random.default_rng(RNG_SEED)
dates = groups_tr.unique()
coef_bs = []

for _ in range(N_BOOT):
    samp = rng.choice(dates, len(dates), replace=True)
    idx = groups_tr.isin(samp)
    m_bs = LinearRegression().fit(X_tr.loc[idx, selected], y_tr.loc[idx])
    coef_bs.append(m_bs.coef_)

coef_bs = np.array(coef_bs)
mean_bs = coef_bs.mean(axis=0)
ci_bs = np.percentile(coef_bs, [2.5, 97.5], axis=0)

bs_df = pd.DataFrame({
    "Variable": selected,
    "Media Î²": mean_bs,
    "IC 95% inf.": ci_bs[0],
    "IC 95% sup.": ci_bs[1]
})

display(
    bs_df.style
    .format({
        "Media Î²": "{:.4f}",
        "IC 95% inf.": "{:.4f}",
        "IC 95% sup.": "{:.4f}"
    })
    .set_caption("Bootstrap (coeficientes, 95 % CI)")
    .hide(axis="index")
)

# -------------------------------------------------------------
# 9 Â· ECUACIONES
alpha = np.exp(mod.intercept_)
expr_log = " + ".join([f"{c:.4f}Â·{v}" for c, v in zip(mod.coef_, selected)])
expr_orig = " Â· ".join([f"{v}^{c:.4f}" for c, v in zip(mod.coef_, selected)])

display(Markdown("EcuaciÃ³n (log)"))
display(Markdown(f"`log(sol_sus) = {mod.intercept_:.4f} + {expr_log}`"))

display(Markdown("EcuaciÃ³n (original)"))
display(Markdown(f"`sol_sus = {alpha:.4f} Â· {expr_orig}`"))

# -------------------------------------------------------------
# 10 Â· GRÃFICAS DE PARIDAD (TRAIN + TEST) con estilo de colores y leyenda

plt.rcParams.update({
    "axes.titlesize": 10,
    "axes.labelsize": 8,
    "xtick.labelsize": 7,
    "ytick.labelsize": 7
})

TRAIN_CLR = "#9D50A6"
TEST_CLR = "#FFA24B"
ID_CLR = "#17A77E"

fig, ax = plt.subplots(1, 2, figsize=(9, 4))

# Escala log
ax[0].scatter(y_tr, pred_tr_log, alpha=0.6, color=TRAIN_CLR, edgecolor="k", label="Train (â—)")
ax[0].scatter(y_te, pred_te_log, alpha=0.6, color=TEST_CLR, marker="s", edgecolor="k", label="Test  (â– )")
lims = [min(y_tr.min(), y_te.min()), max(y_tr.max(), y_te.max())]
ax[0].plot(lims, lims, "--", color=ID_CLR, lw=2.5, label="y = x")
ax[0].set(xlabel="log(sol_sus) obs.", ylabel="log(sol_sus) pred.", title="Escala log")
ax[0].legend(fontsize=7, frameon=False)
ax[0].grid(ls=":")

# Escala original
y_tr_lin, y_te_lin = np.exp(y_tr), np.exp(y_te)
pred_tr_lin, pred_te_lin = np.exp(pred_tr_log), np.exp(pred_te_log)

ax[1].scatter(y_tr_lin, pred_tr_lin, alpha=0.6, color=TRAIN_CLR, edgecolor="k", label="Train (â—)")
ax[1].scatter(y_te_lin, pred_te_lin, alpha=0.6, color=TEST_CLR, marker="s", edgecolor="k", label="Test  (â– )")
lims_o = [min(y_tr_lin.min(), y_te_lin.min(), pred_tr_lin.min(), pred_te_lin.min()),
          max(y_tr_lin.max(), y_te_lin.max(), pred_tr_lin.max(), pred_te_lin.max())]
ax[1].plot(lims_o, lims_o, "--", color=ID_CLR, lw=2.5)
ax[1].set(xlabel="sol_sus obs. (mg/L)", ylabel="sol_sus pred. (mg/L)", title="Escala original")
ax[1].legend(fontsize=7, frameon=False)
ax[1].grid(ls=":")

fig.suptitle(f"Predicho vs Observado Â· Î”AIC â‰¥ {DELTA_AIC}", fontsize=11, y=1.05)
fig.tight_layout(pad=1.2)
plt.show()

# Restaurar configuraciÃ³n original para otras grÃ¡ficas
plt.rcParams.update({
    "axes.titlesize": 11,
    "axes.labelsize": 9,
    "xtick.labelsize": 8,
    "ytick.labelsize": 8
})

```





### todo junto



```{python}
#|code-fold: true
import numpy as np
import pandas as pd
from pathlib import Path
from itertools import combinations
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import GroupKFold
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
from IPython.display import display, Markdown

# -------------------------------------------------------------
# 1 Â· CONFIGURACIÃ“N
DATOS      = Path("datos/datos_sol_sus_acolite.csv")   
DELTA_AIC  = 4                  
N_BOOT     = 2000
RNG_SEED   = 42

# -------------------------------------------------------------
# 2 Â· FUNCIONES AUXILIARES
def aic_gauss(rss, n, k):               
    return n*np.log(rss/n) + 2*k

def fit_metrics(X, y):
    m = LinearRegression().fit(X, y)
    pred = m.predict(X)
    rss = np.sum((y - pred)**2)
    n, p = X.shape
    r2 = r2_score(y, pred)
    return {
        "AIC": aic_gauss(rss, n, p+1),
        "RMSE": np.sqrt(mean_squared_error(y, pred)),
        "RÂ²": r2,
        "RÂ²aj": 1 - (1 - r2) * (n - 1) / (n - p - 1),
        "mod": m
    }

rmse = lambda a,b: np.sqrt(mean_squared_error(a,b))

# -------------------------------------------------------------
# 3 Â· LECTURA Y PREâ€‘PROCESADO
df = pd.read_csv(DATOS)
df["fecha"] = pd.to_datetime(df["fecha"])

bandas = [c for c in df.columns if c.startswith("B")]
df = df.loc[(df["sol_sus"] > 0) & (df[bandas] > 0).all(axis=1)].copy()

df["log_sol_sus"] = np.log(df["sol_sus"])

# -------------------------------------------------------------
# 3.1 Â· log(Bx) y potencias
log_cols, poly_cols = [], []
for b in bandas:
    lb = f"log_{b}"
    df[lb] = np.log(df[b])
    df[f"{lb}^2"] = df[lb]**2
    df[f"{lb}^3"] = df[lb]**3
    log_cols.append(lb)
    poly_cols.extend([f"{lb}^2", f"{lb}^3"])

# -------------------------------------------------------------
# 3.2 Â· razones generales log(Bi/Bj)
ratio_cols = []
for i, b1 in enumerate(bandas):
    for b2 in bandas[i+1:]:
        col = f"log({b1}/{b2})"
        df[col] = df[f"log_{b1}"] - df[f"log_{b2}"]
        ratio_cols.append(col)

# -------------------------------------------------------------
# 3.3 Â· cocientes y Ã­ndices espectrales
df["log_NIR_Blue"]  = df["log_B08"] - df["log_B02"]   
df["log_Red_Green"] = df["log_B04"] - df["log_B03"]   
cq_cols = ["log_NIR_Blue", "log_Red_Green"]

eps = 1e-10
df["NDVI"]   = (df["B08"] - df["B04"]) / (df["B08"] + df["B04"] + eps)
df["TurbI1"] = df["B04"] / (df["B03"] + eps)
df["RE_NDVI"]= (df["B08"] - df["B06"]) / (df["B08"] + df["B06"] + eps)
df["NDMI"]   = (df["B08"] - df["B11"]) / (df["B08"] + df["B11"] + eps)
df["NDWI"]   = (df["B03"] - df["B08"]) / (df["B03"] + df["B08"] + eps)
idx_cols = ["NDVI", "TurbI1", "RE_NDVI", "NDMI", "NDWI"]

# -------------------------------------------------------------
# 3.4 Â· conjunto total de candidatos
cand_cols = log_cols + poly_cols + ratio_cols + cq_cols + idx_cols

display(Markdown(f"**Total variables candidatas:** {len(cand_cols)}"))

X = df[cand_cols]
y = df["log_sol_sus"]

# -------------------------------------------------------------
# 4 Â· HOLDâ€‘OUT TEMPORAL
last = df["fecha"].max()
m_te = df["fecha"] == last
m_tr = ~m_te

X_tr, y_tr = X.loc[m_tr], y.loc[m_tr]
X_te, y_te = X.loc[m_te], y.loc[m_te]
groups_tr  = df.loc[m_tr, "fecha"]

display(Markdown(f"**TRAIN campaÃ±as:** {groups_tr.nunique()}"))
display(Markdown(f"**TEST campaÃ±a:** {last.date()}  ({m_te.sum()} muestras)"))

# -------------------------------------------------------------
# 5 Â· FORWARDâ€‘AIC (Î” â‰¥ {DELTA_AIC})
remaining, selected = cand_cols.copy(), []

rss0 = np.sum((y_tr - y_tr.mean())**2)
best_aic = aic_gauss(rss0, len(y_tr), 1)

hist, step = [], 0
while remaining:
    scores = []
    for col in remaining:
        cols = selected + [col]
        mtr = fit_metrics(X_tr[cols].values, y_tr.values)
        scores.append((mtr["AIC"], col, mtr))
    scores.sort()
    new_aic, best_col, m_info = scores[0]

    if best_aic - new_aic >= DELTA_AIC:
        selected.append(best_col)
        remaining.remove(best_col)
        best_aic = new_aic
        step += 1
        hist.append({
            "Paso": step,
            "Variables": ", ".join(selected),
            "AIC": best_aic,
            "RMSE": m_info["RMSE"],
            "RÂ²": m_info["RÂ²"],
            "RÂ²aj": m_info["RÂ²aj"]
        })
    else:
        break

if not selected:
    best_col = min(scores, key=lambda t: t[0])[1]
    selected = [best_col]
    hist.append({
        "Paso": 1,
        "Variables": best_col,
        **{k: v for k, v in scores[0][2].items() if k != "mod"}
    })

hist_df = pd.DataFrame(hist, columns=["Paso", "Variables", "AIC", "RMSE", "RÂ²", "RÂ²aj"])

display(
    hist_df.style
    .format({"AIC": "{:.3f}", "RMSE": "{:.3f}", "RÂ²": "{:.3f}", "RÂ²aj": "{:.3f}"})
    .set_caption("Historial de selecciÃ³n")
    .hide(axis="index")
)

display(Markdown(f"**Variables finales seleccionadas:** `{', '.join(selected)}`"))

# -------------------------------------------------------------
# 6 Â· VALIDACIÃ“N Groupâ€‘KFold
gkf = GroupKFold(n_splits=min(5, groups_tr.nunique()))
rm = []
for tr_idx, te_idx in gkf.split(X_tr[selected], y_tr, groups_tr):
    m = LinearRegression().fit(X_tr.iloc[tr_idx][selected], y_tr.iloc[tr_idx])
    rm.append(rmse(y_tr.iloc[te_idx], m.predict(X_tr.iloc[te_idx][selected])))

display(Markdown(f"**GroupKFold CV (log) RMSE:** {np.mean(rm):.3f} Â± {np.std(rm):.3f}"))

# -------------------------------------------------------------
# 7 Â· MODELO FINAL Y MÃ‰TRICAS
mod = LinearRegression().fit(X_tr[selected], y_tr)

pred_tr = mod.predict(X_tr[selected])
pred_te = mod.predict(X_te[selected])

metrics_df = pd.DataFrame({
    "MÃ©trica": ["RMSE", "RÂ²"],
    "Train log": [rmse(y_tr, pred_tr), r2_score(y_tr, pred_tr)],
    "Test log": [rmse(y_te, pred_te), r2_score(y_te, pred_te)],
    "Train orig": [rmse(np.exp(y_tr), np.exp(pred_tr)), r2_score(np.exp(y_tr), np.exp(pred_tr))],
    "Test orig": [rmse(np.exp(y_te), np.exp(pred_te)), r2_score(np.exp(y_te), np.exp(pred_te))]
})

display(
    metrics_df.style
    .format({
        "Train log": "{:.3f}", "Test log": "{:.3f}",
        "Train orig": "{:.3f}", "Test orig": "{:.3f}"
    })
    .set_caption("MÃ©tricas finales")
    .hide(axis="index")
)

# -------------------------------------------------------------
# 8 Â· BOOTSTRAP AGRUPADO (IC 95%)
rng = np.random.default_rng(RNG_SEED)
dates = groups_tr.unique()
coef_bs = []

for _ in range(N_BOOT):
    samp = rng.choice(dates, len(dates), replace=True)
    idx = groups_tr.isin(samp)
    m_bs = LinearRegression().fit(X_tr.loc[idx, selected], y_tr.loc[idx])
    coef_bs.append(m_bs.coef_)

coef_bs = np.array(coef_bs)
ci_lo, ci_hi = np.percentile(coef_bs, [2.5, 97.5], axis=0)

bs_df = pd.DataFrame({
    "Variable": selected,
    "Media Î²": coef_bs.mean(axis=0),
    "IC 95% inf.": ci_lo,
    "IC 95% sup.": ci_hi
})

display(
    bs_df.style
    .format({
        "Media Î²": "{:.4f}",
        "IC 95% inf.": "{:.4f}",
        "IC 95% sup.": "{:.4f}"
    })
    .set_caption("Bootstrap (coeficientes, 95 % CI)")
    .hide(axis="index")
)

# -------------------------------------------------------------
# 9 Â· ECUACIÃ“N DEL MODELO
alpha = np.exp(mod.intercept_)
expr_log = " + ".join([f"{c:.4f}Â·{v}" for c, v in zip(mod.coef_, selected)])
expr_orig = " Â· ".join([f"{v}^{c:.4f}" for c, v in zip(mod.coef_, selected)])

display(Markdown("EcuaciÃ³n (log)"))
display(Markdown(f"`log(sol_sus) = {mod.intercept_:.4f} + {expr_log}`"))

display(Markdown("EcuaciÃ³n (original)"))
display(Markdown(f"`sol_sus = {alpha:.4f} Â· {expr_orig}`"))

# -------------------------------------------------------------
# 10 Â· PARIDAD TRAIN + TEST (log y mg/L) con estilo colores y leyenda
plt.rcParams.update({
    "axes.titlesize": 10,
    "axes.labelsize": 8,
    "xtick.labelsize": 7,
    "ytick.labelsize": 7
})

TRAIN_CLR = "#9D50A6"
TEST_CLR = "#FFA24B"
ID_CLR = "#17A77E"

fig, ax = plt.subplots(1, 2, figsize=(9, 4))

# Escala log
ax[0].scatter(y_tr, pred_tr, alpha=0.6, color=TRAIN_CLR, edgecolor="k", label="Train (â—)")
ax[0].scatter(y_te, pred_te, alpha=0.6, color=TEST_CLR, marker="s", edgecolor="k", label="Test  (â– )")
lims = [min(y_tr.min(), y_te.min()), max(y_tr.max(), y_te.max())]
ax[0].plot(lims, lims, "--", color=ID_CLR, lw=2.5, label="y = x")
ax[0].set(xlabel="log(sol_sus) obs.", ylabel="log(sol_sus) pred.", title="Escala log")
ax[0].legend(fontsize=7, frameon=False)
ax[0].grid(ls=":")

# Escala original
y_tr_lin, y_te_lin = np.exp(y_tr), np.exp(y_te)
pred_tr_lin, pred_te_lin = np.exp(pred_tr), np.exp(pred_te)

ax[1].scatter(y_tr_lin, pred_tr_lin, alpha=0.6, color=TRAIN_CLR, edgecolor="k", label="Train (â—)")
ax[1].scatter(y_te_lin, pred_te_lin, alpha=0.6, color=TEST_CLR, marker="s", edgecolor="k", label="Test  (â– )")
lims_o = [min(y_tr_lin.min(), y_te_lin.min(), pred_tr_lin.min(), pred_te_lin.min()),
          max(y_tr_lin.max(), y_te_lin.max(), pred_tr_lin.max(), pred_te_lin.max())]
ax[1].plot(lims_o, lims_o, "--", color=ID_CLR, lw=2.5)
ax[1].set(xlabel="sol_sus obs. (mg/L)", ylabel="sol_sus pred. (mg/L)", title="Escala original")
ax[1].legend(fontsize=7, frameon=False)
ax[1].grid(ls=":")

fig.suptitle(f"Predicho vs Observado Â· Î”AIC â‰¥ {DELTA_AIC}", fontsize=11, y=1.05)
fig.tight_layout(pad=1.2)
plt.show()

plt.rcParams.update({
    "axes.titlesize": 11,
    "axes.labelsize": 9,
    "xtick.labelsize": 8,
    "ytick.labelsize": 8
})

```